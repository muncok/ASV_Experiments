{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# incremental_enrollment-score_normalization\n",
    "-------------\n",
    "\n",
    "z-norm과 s-norm을 구현하였다.\n",
    "\n",
    "사용된 trial embed와 언제 enroll이 일어났는지 정보가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from plot_ROC import plot_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/host/projects/sv_experiments/sv_system/')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key2df(keys, delimeter=\"-\"):\n",
    "    key_df = pd.DataFrame(keys, columns=['key'])\n",
    "    key_df['spk'] = key_df.key.apply(lambda x: x.split(delimeter)[0])\n",
    "    key_df['label'] = key_df.groupby('spk').ngroup()\n",
    "    key_df['origin'] = key_df.spk.apply(lambda x: 'voxc2' if x.startswith('id') else 'voxc1')\n",
    "    key_df = key_df.set_index('key')\n",
    "    \n",
    "    return key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = pickle.load(open(\"./voxc2_fbank64_embeds/sv_keys.pkl\", \"rb\"))\n",
    "key_df = key2df(keys)\n",
    "key2id = {k:v for v, k in enumerate(keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uttrkey_to_id(uttr_keys):\n",
    "    return [key2id[key] for key in uttr_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds_precise = torch.from_numpy(np.load(\"./voxc2_fbank64_precise_untied_embeds/sv_embeds.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing trace then score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./figs/untiedPrecise_untiedPrecise_fixed_length_pos40/700f_50f/meanCos_posNeg_v0/\"\n",
    "enroll_id_sets = pickle.load(open(base_dir+\"enroll_id_sets.pkl\", \"rb\"))\n",
    "trials_id_sets = pickle.load(open(base_dir+\"trials_id_sets.pkl\", \"rb\"))\n",
    "trials_label_sets = pickle.load(open(base_dir+\"trials_label_sets.pkl\", \"rb\"))\n",
    "result_df = pd.read_pickle(base_dir + \"result_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imposter set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_trial = pickle.load(open(\"./cases/fixed_length_pos40/700f_50f/validation/val_thresh_trials.pkl\", 'rb'))\n",
    "imposter_set = validation_trial.enroll_idx.unique()[:10000]\n",
    "imposter_tensor = embeds_precise[uttrkey_to_id(imposter_set)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_enroll_used = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from inc_utils import compute_eer\n",
    "\n",
    "cos_base_pos_score_records = []\n",
    "cos_base_neg_score_records = []\n",
    "\n",
    "cos_inc_pos_score_records = []\n",
    "cos_inc_neg_score_records = []\n",
    "\n",
    "for trial_idx in range(len(enroll_id_sets)):\n",
    "    enroll_id = enroll_id_sets[trial_idx]\n",
    "    enroll_spk = key_df.iloc[enroll_id].spk\n",
    "    trials_id = trials_id_sets[trial_idx]\n",
    "    trials_label = trials_label_sets[trial_idx]\n",
    "    trial_df = result_df[(result_df.spk == enroll_spk.values[0]) & (result_df.n_neg == len(trials_id)-40)]\n",
    "    enroll_timestamp = np.nonzero(np.array(trial_df.inc_enroll.values[0]) > -1)\n",
    "\n",
    "    init_enroll_tensor = embeds_precise[enroll_id]\n",
    "    test_tensor = embeds_precise[trials_id]\n",
    "\n",
    "    inc_enroll_tensor = test_tensor[enroll_timestamp]\n",
    "    all_enroll_tensor = torch.cat([init_enroll_tensor, inc_enroll_tensor], dim=0)\n",
    "\n",
    "    base_trial_score = cosine_similarity(init_enroll_tensor.unsqueeze(1), \n",
    "                                         test_tensor.unsqueeze(0), dim=2).numpy()\n",
    "    \n",
    "    inc_trial_score = cosine_similarity(all_enroll_tensor.unsqueeze(1), \n",
    "                                     test_tensor.unsqueeze(0), dim=2).numpy()\n",
    "        \n",
    "#     trial_len = len(trials_id)\n",
    "#     n_enroll = all_enroll_tensor.shape[0]\n",
    "#     t_stamps = [-1] + enroll_timestamp[0].tolist() + [trial_len-1]\n",
    "# #     t_stamps.reverse()\n",
    "# # =================== base ===================\n",
    "#     base_pos_score_records += [base_trial_score[:, trials_label == 1].mean(0)]\n",
    "#     base_neg_score_records += [base_trial_score[:, trials_label == 0].mean(0)]\n",
    "    \n",
    "# # =================== inc ===================\n",
    "#     trial_score_ = np.zeros(trial_len,)\n",
    "#     for i in range(len(t_stamps)-1):\n",
    "# #         print(t_stamps[i]+1, t_stamps[i+1]+1)\n",
    "# #         print(max(0, (i+1)-10), i+1)\n",
    "#         trial_score_[t_stamps[i]+1:t_stamps[i+1]+1] = \\\n",
    "#         inc_trial_score[max(0, (i+1)-10):i+1,t_stamps[i]+1:t_stamps[i+1]+1].mean(0)\n",
    "        \n",
    "#     inc_pos_score_records += [trial_score_[trials_label == 1]]\n",
    "#     inc_neg_score_records += [trial_score_[trials_label == 0]]\n",
    "\n",
    "\n",
    "    trial_len = len(trials_id)\n",
    "    n_enroll = all_enroll_tensor.shape[0]\n",
    "    t_stamps = enroll_timestamp[0].tolist() + [trial_len]\n",
    "    t_stamps.reverse()\n",
    "# =================== base ===================\n",
    "    cos_base_pos_score_records += [base_trial_score[:, trials_label == 1].mean(0)]\n",
    "    cos_base_neg_score_records += [base_trial_score[:, trials_label == 0].mean(0)]\n",
    "    \n",
    "# =================== inc ===================\n",
    "    trial_score_ = np.zeros(trial_len,)\n",
    "    for i, t in enumerate(t_stamps):\n",
    "        trial_score_[:t] = inc_trial_score[max(0, (n_enroll-i)-n_enroll_used):n_enroll-i,:t].mean(0)\n",
    "#         trial_score_[:t] = inc_trial_score[0:n_enroll-i,:t].mean(0)\n",
    "        \n",
    "    cos_inc_pos_score_records += [trial_score_[trials_label == 1]]\n",
    "    cos_inc_neg_score_records += [trial_score_[trials_label == 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_scores(imposter_scores, scores):\n",
    "    z_mu = imposter_scores.mean(dim=1, keepdim=True)\n",
    "    z_std = imposter_scores.std(dim=1, keepdim=True)\n",
    "    \n",
    "    return (scores - z_mu) / z_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inc_utils import compute_eer\n",
    "\n",
    "z_base_pos_score_records = []\n",
    "z_base_neg_score_records = []\n",
    "\n",
    "z_inc_pos_score_records = []\n",
    "z_inc_neg_score_records = []\n",
    "\n",
    "for trial_idx in range(len(enroll_id_sets)): \n",
    "    enroll_id = enroll_id_sets[trial_idx]\n",
    "    enroll_spk = key_df.iloc[enroll_id].spk\n",
    "    trials_id = trials_id_sets[trial_idx]\n",
    "    trials_label = trials_label_sets[trial_idx]\n",
    "    trial_df = result_df[(result_df.spk == enroll_spk.values[0]) & (result_df.n_neg == len(trials_id)-40)]\n",
    "    enroll_timestamp = np.nonzero(np.array(trial_df.inc_enroll.values[0]) > -1)\n",
    "\n",
    "    init_enroll_tensor = embeds_precise[enroll_id]\n",
    "    test_tensor = embeds_precise[trials_id]\n",
    "\n",
    "    inc_enroll_tensor = test_tensor[enroll_timestamp]\n",
    "    all_enroll_tensor = torch.cat([init_enroll_tensor, inc_enroll_tensor], dim=0)\n",
    "\n",
    "    # z_score\n",
    "    base_z_imp_scores = cosine_similarity(init_enroll_tensor.unsqueeze(1), \n",
    "                                     imposter_tensor.unsqueeze(0), dim=2)\n",
    "    base_trial_score = cosine_similarity(init_enroll_tensor.unsqueeze(1), \n",
    "                                         test_tensor.unsqueeze(0), dim=2)\n",
    "    base_trial_score = z_scores(base_z_imp_scores, base_trial_score).numpy()\n",
    "    \n",
    "    inc_z_imp_scores = cosine_similarity(all_enroll_tensor.unsqueeze(1), \n",
    "                                     imposter_tensor.unsqueeze(0), dim=2)\n",
    "    inc_trial_score = cosine_similarity(all_enroll_tensor.unsqueeze(1), \n",
    "                                     test_tensor.unsqueeze(0), dim=2)\n",
    "    inc_trial_score = z_scores(inc_z_imp_scores, inc_trial_score).numpy()\n",
    "\n",
    "\n",
    "    trial_len = len(trials_id)\n",
    "    n_enroll = all_enroll_tensor.shape[0]\n",
    "    t_stamps = enroll_timestamp[0].tolist() + [trial_len]\n",
    "    t_stamps.reverse()\n",
    "# =================== base ===================\n",
    "    z_base_pos_score_records += [base_trial_score[:, trials_label == 1].mean(0)]\n",
    "    z_base_neg_score_records += [base_trial_score[:, trials_label == 0].mean(0)]\n",
    "    \n",
    "# =================== inc ===================\n",
    "    trial_score_ = np.zeros(trial_len,)\n",
    "    for i, t in enumerate(t_stamps):\n",
    "        trial_score_[:t] = inc_trial_score[max(0, (n_enroll-i)-n_enroll_used):n_enroll-i,:t].mean(0)\n",
    "#         trial_score_[:t] = inc_trial_score[0:n_enroll-i,:t].mean(0)\n",
    "        \n",
    "    z_inc_pos_score_records += [trial_score_[trials_label == 1]]\n",
    "    z_inc_neg_score_records += [trial_score_[trials_label == 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### s-norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_imp_tensor = imposter_tensor / imposter_tensor.norm(dim=1, keepdim=True)\n",
    "imp_mean = u_imp_tensor.mean(dim=0, keepdim=True)\n",
    "imp_dig_cov = torch.std(u_imp_tensor, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized cos similarity\n",
    "def s_scores(target_tensor, test_tensor):   \n",
    "    u_target = target_tensor / target_tensor.norm(dim=1, keepdim=True) \n",
    "    u_test = test_tensor / test_tensor.norm(dim=1, keepdim=True)\n",
    "\n",
    "    target_mean = (u_target - imp_mean)\n",
    "    test_mean = (u_test - imp_mean)\n",
    "    target_std = u_target.matmul(imp_dig_cov)\n",
    "    test_std = u_test.matmul(imp_dig_cov)\n",
    "    \n",
    "    s_score = target_mean.matmul(test_mean.t())\\\n",
    "                        / target_std.view(-1,1)\\\n",
    "                        / test_std.view(1,-1)\n",
    "    \n",
    "    return s_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inc_utils import compute_eer\n",
    "\n",
    "s_base_pos_score_records = []\n",
    "s_base_neg_score_records = []\n",
    "\n",
    "s_inc_pos_score_records = []\n",
    "s_inc_neg_score_records = []\n",
    "\n",
    "for trial_idx in range(len(enroll_id_sets)):\n",
    "    enroll_id = enroll_id_sets[trial_idx]\n",
    "    enroll_spk = key_df.iloc[enroll_id].spk\n",
    "    trials_id = trials_id_sets[trial_idx]\n",
    "    trials_label = trials_label_sets[trial_idx]\n",
    "    trial_df = result_df[(result_df.spk == enroll_spk.values[0]) & (result_df.n_neg == len(trials_id)-40)]\n",
    "    enroll_timestamp = np.nonzero(np.array(trial_df.inc_enroll.values[0]) > -1)\n",
    "\n",
    "    init_enroll_tensor = embeds_precise[enroll_id]\n",
    "    test_tensor = embeds_precise[trials_id]\n",
    "\n",
    "    inc_enroll_tensor = test_tensor[enroll_timestamp]\n",
    "    all_enroll_tensor = torch.cat([init_enroll_tensor, inc_enroll_tensor], dim=0)\n",
    "\n",
    "    base_trial_score = s_scores(init_enroll_tensor, test_tensor).numpy()\n",
    "    inc_trial_score = s_scores(all_enroll_tensor, test_tensor).numpy()\n",
    "        \n",
    "    trial_len = len(trials_id)\n",
    "    n_enroll = all_enroll_tensor.shape[0]\n",
    "    t_stamps = enroll_timestamp[0].tolist() + [trial_len]\n",
    "    t_stamps.reverse()\n",
    "# =================== base ===================\n",
    "    s_base_pos_score_records += [base_trial_score[:, trials_label == 1].mean(0)]\n",
    "    s_base_neg_score_records += [base_trial_score[:, trials_label == 0].mean(0)]\n",
    "    \n",
    "# =================== inc ===================\n",
    "    trial_score_ = np.zeros(trial_len,)\n",
    "    for i, t in enumerate(t_stamps):\n",
    "        trial_score_[:t] = inc_trial_score[max(0, (n_enroll-i)-n_enroll_used):n_enroll-i,:t].mean(0)\n",
    "#         trial_score_[:t] = inc_trial_score[0:n_enroll-i,:t].mean(0)\n",
    "        \n",
    "    s_inc_pos_score_records += [trial_score_[trials_label == 1]]\n",
    "    s_inc_neg_score_records += [trial_score_[trials_label == 0]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "0.0275\n",
      "0.0297\n",
      "0.0295\n",
      "0.02\n",
      "0.025\n",
      "0.0269\n",
      "0.027\n",
      "0.0\n",
      "0.015\n",
      "0.0225\n",
      "0.0225\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(cos_base_pos_score_records[idx:idx+10], axis=0),\n",
    "            np.concatenate(cos_base_neg_score_records[idx:idx+10], axis=0)))\n",
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(z_base_pos_score_records[idx:idx+10], axis=0),\n",
    "                    np.concatenate(z_base_neg_score_records[idx:idx+10], axis=0)))\n",
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(s_base_pos_score_records[idx:idx+10], axis=0),\n",
    "                    np.concatenate(s_base_neg_score_records[idx:idx+10], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.0075\n",
      "0.0114\n",
      "0.0125\n",
      "0.01\n",
      "0.0075\n",
      "0.0125\n",
      "0.0104\n",
      "0.0\n",
      "0.0025\n",
      "0.005\n",
      "0.0045\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(cos_inc_pos_score_records[idx:idx+10], axis=0),\n",
    "            np.concatenate(cos_inc_neg_score_records[idx:idx+10], axis=0)))\n",
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(z_inc_pos_score_records[idx:idx+10], axis=0),\n",
    "            np.concatenate(z_inc_neg_score_records[idx:idx+10], axis=0)))\n",
    "for idx in range(0,40,10):\n",
    "    print(compute_eer(np.concatenate(s_inc_pos_score_records[idx:idx+10], axis=0),\n",
    "            np.concatenate(s_inc_neg_score_records[idx:idx+10], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
