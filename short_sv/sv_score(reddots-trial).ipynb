{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/muncok/DL/projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_default_loader\n",
    "from sv_system.utils.parser import get_sv_parser\n",
    "from sv_system.train.si_train import set_seed\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_sv_parser().parse_args(args=[])\n",
    "options.n_dct_filters = 40\n",
    "options.n_mels = 40\n",
    "options.timeshift_ms = 100\n",
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets\"\n",
    "options.window_size= 0.025\n",
    "options.window_stride= 0.010\n",
    "options.cache_size = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils import secToFrames, secToSample\n",
    "options.input_format = \"fbank\"\n",
    "options.input_clip = True\n",
    "options.input_length = secToSample(3) # if input_clip is false, it doesn't affect anything\n",
    "options.splice_frames = secToFrames(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from models/reddots/simplecnn/si_reddots_0.2s_fbank.pt\n"
     ]
    }
   ],
   "source": [
    "from sv_system.model.AuxModels import LongCNN, SimpleCNN\n",
    "from sv_system.model.SpeechModel import SpeechResModel\n",
    "import pickle\n",
    "model = SimpleCNN(46, options.splice_frames)\n",
    "# model = SpeechResModel('res15', 1260)\n",
    "model.load(\"models/reddots/simplecnn/si_reddots_0.2s_fbank.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4120612ff5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msv_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTDNN\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTdnnModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTdnnModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1260\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplice_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/reddots/si_train/si_reddots_tdnn_3s_0.1s_mean.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/projects/sv_system/model/TDNN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, n_labels, embed_mode)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membed_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTdnnCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [-4, +4] 9 frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mfeat_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtdnn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTDNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/projects/sv_system/model/TDNN.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, n_labels, embed_mode)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplice_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"splice_frames\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mhid_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeat_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sv_system.model.TDNN import TdnnModel\n",
    "import pickle\n",
    "model = TdnnModel(1260, options.splice_frames)\n",
    "model.load(\"models/reddots/si_train/si_reddots_tdnn_3s_0.1s_mean.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reddots Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def lda_on_tensor(tensor, lda):\n",
    "    return torch.from_numpy(lda.transform(tensor.numpy()).astype(np.float32))\n",
    "\n",
    "def embeds(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt.splice_frames\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in tqdm_notebook(val_iter, total=len(val_iter)):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, 1)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if opt.cuda:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_ndx = pd.read_pickle(\"trials/reddots/m_part1/m_part1_ndx.pkl\")\n",
    "m_part1_trn = pd.read_pickle('trials/reddots/m_part1/m_part1_trn.pkl')\n",
    "# m_part4_ndx = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_ndx.pkl\")\n",
    "# m_part4_trn = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_trn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = m_part1_trn\n",
    "ndx = m_part1_ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type = {0:'TC', 1:'TW', 2:'IC', 3:'IW'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enrollment (trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataset import SpeechDataset\n",
    "dataset = SpeechDataset.read_df(vars(options), trn, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e799cae9e94a6eb487c4c44c9160b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = init_default_loader(dataset, shuffle=False)\n",
    "trn_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SV Scoring (ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_files = pd.read_pickle('trials/reddots/m_part1/m_part1_files.pkl')\n",
    "dataset = SpeechDataset.read_df(vars(options), m_part1_files, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b82ee030dda4a55b2eb1ef7c4b897e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=76), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = init_default_loader(dataset, shuffle=False) \n",
    "ndx_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "# torch.save(ndx_embeddings, 'trials/reddots/m_part1/{}_embeds.pkl'.format(model_name))\n",
    "# ndx_embeddings = torch.load('trials/reddots/m_part1/{}_embeds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5221d9b952c43d8bce533b5f508089c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_trials = ndx.id.unique().tolist()\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    scores[t] = []\n",
    "    \n",
    "for trial_id in tqdm(all_trials):\n",
    "    trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "    trial_embed_idx = np.nonzero(m_part1_files.file.isin(trial_ndx.file))\n",
    "    trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "    sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id])\n",
    "    for t in range(4):\n",
    "        trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "        scores[t].append(sim[trial_type_idx])\n",
    "        \n",
    "# [TC, TW, IC, IW]\n",
    "for t in range(4):\n",
    "    scores[t] = torch.cat(scores[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC mean:0.90, std:0.071\n",
      "TW mean:0.89, std:0.069\n",
      "IC mean:0.72, std:0.102\n",
      "IW mean:0.71, std:0.101\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "     print(\"{} mean:{:.2f}, std:{:.3f}\".format(err_type[t], scores[t].mean(), scores[t].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TW] eer: 0.43, thres: 0.91566\n",
      "[IC] eer: 0.12, thres: 0.84023\n",
      "[IW] eer: 0.11, thres: 0.83466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TI] eer: 0.13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score_vector = np.concatenate((scores[0], scores[1],\n",
    "                              scores[2], scores[3]))\n",
    "label_vector = np.concatenate((np.ones(len(scores[0]) + len(scores[1])), \n",
    "                           np.zeros(len(scores[2]) + len(scores[3]))))\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.2f}\".format(eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   664.,   8689.,  37181., 101276., 188708., 263555., 291475.,\n",
       "        241638.,  91663.,   8431.]),\n",
       " array([0.23244454, 0.30890191, 0.38535928, 0.46181664, 0.53827401,\n",
       "        0.61473138, 0.69118875, 0.76764611, 0.84410348, 0.92056085,\n",
       "        0.99701822]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f286cddc748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = m_part1_trn\n",
    "ndx = m_part1_ndx\n",
    "\n",
    "val_dataloader = init_embed_loaders(options, trn) \n",
    "trn_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)\n",
    "\n",
    "all_trials = ndx.id.unique().tolist()\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    scores[t] = []\n",
    "\n",
    "trial_id = all_trials[99]\n",
    "print(trial_id)\n",
    "trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "trial_embed_idx = np.nonzero(m_part1_files.file.isin(trial_ndx.file))\n",
    "trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id])\n",
    "for t in range(4):\n",
    "    trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "    scores[t].append(sim[trial_type_idx])\n",
    "        \n",
    "# [TC, TW, IC, IW]\n",
    "for t in range(4):\n",
    "    scores[t] = torch.cat(scores[t])\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))\n",
    "\n",
    "enroll_df = trn[trn.id == trial_id] \n",
    "enroll_df['trial_type'] = -1\n",
    "\n",
    "# row scores in pos_test\n",
    "t_type = 0\n",
    "n_test = 5\n",
    "hard_pos_test = np.argsort(scores[t_type])[:n_test]\n",
    "pos_test_df = trial_ndx[trial_ndx.trial_type == t_type].iloc[hard_pos_test]\n",
    "\n",
    "t_type = 2\n",
    "hard_neg_test = np.argsort(scores[t_type])[-n_test:]\n",
    "neg_test_df =trial_ndx[trial_ndx.trial_type == t_type].iloc[hard_neg_test]\n",
    "\n",
    "from shutil import copyfile\n",
    "trial_folder = \"trials/human_perf/reddots/{}\".format(trial_id)\n",
    "if not os.path.isdir(trial_folder):\n",
    "    os.makedirs(trial_folder)\n",
    "\n",
    "test_df = pd.concat([pos_test_df, neg_test_df])\n",
    "perm_idxs = np.random.permutation(np.arange(len(test_df)))\n",
    "\n",
    "i = 0\n",
    "for idx, row in enroll_df.iterrows():\n",
    "    copyfile(os.path.join(options.data_folder, row.file), \n",
    "             os.path.join(trial_folder, \"e_{}.wav\".format(i)))\n",
    "    i+=1\n",
    "\n",
    "i = 0\n",
    "random_idx = np.random.permutation(np.arange(len(test_df)))\n",
    "save_file_names = []\n",
    "for _, row in test_df.iterrows():\n",
    "    save_file_names.append(\"t_{}.wav\".format(perm_idxs[i]))\n",
    "    copyfile(os.path.join(options.data_folder, row.file), \n",
    "             os.path.join(trial_folder, save_file_names[-1]))\n",
    "    i+=1\n",
    "\n",
    "test_df['to_file'] = save_file_names\n",
    "\n",
    "with open(os.path.join(trial_folder, \"test_labels.txt\"), \"w\") as f:\n",
    "    for _, row in test_df.iterrows():\n",
    "        if row.trial_type == 0:\n",
    "            f.write(\"{}\\t{}\\n\".format(row.to_file, \"1\"))\n",
    "        else:\n",
    "            f.write(\"{}}\\t{}\\n\".format(row_to_file, \"0\"))\n",
    "\n",
    "test_df.to_pickle(os.path.join(trial_folder, \"test_audios.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m0001_39\n"
     ]
    }
   ],
   "source": [
    "all_trials = ndx.id.unique().tolist()\n",
    "scores = dict()\n",
    "for t in [0, 2]:\n",
    "    scores[t] = []\n",
    "\n",
    "print(trial_id)\n",
    "trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "trial_embed_idx = np.nonzero(m_part1_files.file.isin(trial_ndx.file))\n",
    "trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id])\n",
    "for t in [0, 2]:\n",
    "    trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "    scores[t].append(sim[trial_type_idx])\n",
    "        \n",
    "# [TC, TW, IC, IW]\n",
    "for t in [0, 2]:\n",
    "    scores[t] = torch.cat(scores[t])\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(2,3):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
