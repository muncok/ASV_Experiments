{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import sys\n",
    "import pickle\n",
    "# sys.setrecursionlimit(10000) # 10000 is an example, try with different values\n",
    "sys.path.append(\"/home/muncok/DL/projects/sv_system/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.si_train import set_seed\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.train.model import init_protonet, init_resnet\n",
    "from dnn.data.dataloader import init_sv_loaders\n",
    "from dnn.sv_score import similarities\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_in_feature(config, sound_files, in_feature='mfcc'):\n",
    "    t = len(sound_files)\n",
    "    plt.figure(figsize=(12, 4*t))\n",
    "    for i, sound_file in enumerate(sound_files):\n",
    "        feature = preprocess_from_path(config, sound_file, in_feature)\n",
    "        plt.subplot(t,1,i+1)\n",
    "        librosa.display.specshow(feature.numpy().T, \n",
    "                                 x_axis='time', y_axis='mel',\n",
    "                                 sr=16000, hop_length=160, \n",
    "                                 fmin=20, fmax=4000)\n",
    "        plt.colorbar()\n",
    "        word = sound_file.split(\"/\")[-2]\n",
    "        file = sound_file.split(\"/\")[-1]\n",
    "        plt.title(\"{}, {}, {}\".format(in_feature, word, file))\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secToSample(sec):\n",
    "    return int(16000 * sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eer(pos_scores, neg_scores):\n",
    "    score_vector = np.concatenate([pos_scores, neg_scores])\n",
    "    label_vector = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = np.min([fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))], \n",
    "                 1-tpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]])\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"eer:{:.4f}, thres:{:.4f}\".format(eer, thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/speech_commands/vad/'\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Command_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.parser import get_sv_parser\n",
    "options = get_sv_parser().parse_args(args=[])\n",
    "options.n_dct_filters = 40\n",
    "options.n_mels = 40\n",
    "options.timeshift_ms = 100\n",
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets\"\n",
    "options.window_size= 0.025\n",
    "options.window_stride= 0.010\n",
    "options.cache_size = 32768\n",
    "options.input_format = \"mfcc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.input_format = 'mfcc'\n",
    "# options.input_length = secToSample(1)\n",
    "options.splice_frame = secToSample(0.1)//160+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from dnn.data.dataloader import init_embed_loaders\n",
    "options.data_folder= \"/home/muncok/DL/dataset/SV_sets/speech_commands/vad\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'use_dilation': True, 'n_layers': 13, 'n_feature_maps': 45}\n",
      "models/voxc/si_train/full_train/si_voxc_res15_0.1s_full.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/voxc/si_train/full_train/si_voxc_res15_0.1s_full.pt\"\n",
    "options.model = \"res15\"\n",
    "model = init_resnet(options)\n",
    "lda = pickle.load(open(\"models/lda/si_voxc_res15_0.1s_full_lda_1.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/commands/up_from_scratch.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/commands/up_from_scratch.pt\"\n",
    "model = init_protonet(options, small=True)\n",
    "lda = pickle.load(open(\"models/lda/up_from_scratch_lda.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities From Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_on_thres(pos_scores, neg_scores, thres):\n",
    "    fa_count = np.count_nonzero(neg_scores > thres)\n",
    "    fr_count = np.count_nonzero(pos_scores < thres)\n",
    "    print(fa_count, fr_count)\n",
    "    fpr = fa_count / len(neg_scores)\n",
    "    fnr = fr_count / len(pos_scores)\n",
    "    return fpr, fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.num_query_val = 3\n",
    "options.num_support_val = 3\n",
    "options.classes_per_it_val = 1\n",
    "options.iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop', 'seven', 'yes', 'zero', 'up', 'no', 'two', 'four', 'go', 'one']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(data_df.sent.value_counts().index[:10])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n",
      "eer:0.0833, thres:0.5139\n",
      "seven\n",
      "eer:0.0333, thres:0.4702\n",
      "yes\n",
      "eer:0.0600, thres:0.4643\n",
      "zero\n",
      "eer:0.0567, thres:0.4706\n",
      "up\n",
      "eer:0.1833, thres:0.2466\n",
      "no\n",
      "eer:0.0467, thres:0.5501\n",
      "two\n",
      "eer:0.0133, thres:0.4405\n",
      "four\n",
      "eer:0.0233, thres:0.5538\n",
      "go\n",
      "eer:0.0333, thres:0.4877\n",
      "one\n",
      "eer:0.0467, thres:0.4074\n",
      "uni\n",
      "eer:0.0570, thres:0.4544\n"
     ]
    }
   ],
   "source": [
    "pos_scores_list = []\n",
    "neg_scores_list = []\n",
    "for word in ['stop', 'seven', 'yes', 'zero', 'up', 'no', 'two', 'four', 'go', 'one']:\n",
    "    options.val_manifest = \"manifests/commands/words/sv/sv_{}_manifest.csv\".format(word)\n",
    "    val_dataloader = init_sv_loaders(options)\n",
    "    pos_scores, neg_scores = similarities(options, val_dataloader, model, lda) # embeddings: sample x emb_size\n",
    "    pos_scores_list.append(pos_scores)\n",
    "    neg_scores_list.append(neg_scores)\n",
    "    print(word)\n",
    "    compute_eer(pos_scores, neg_scores)\n",
    "    \n",
    "pos_scores = np.array(pos_scores_list).flatten()\n",
    "neg_scores = np.array(neg_scores_list).flatten()\n",
    "print(\"uni\")\n",
    "compute_eer(pos_scores, neg_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-78751fa95de5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_manifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"manifests/commands/words/sv/sv_{}_manifest.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_sv_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# embeddings: sample x emb_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "word = \"stop\"\n",
    "options.val_manifest = \"manifests/commands/words/sv/sv_{}_manifest.csv\".format(word)\n",
    "val_dataloader = init_sv_loaders(options)\n",
    "pos_scores, neg_scores = similarities(options, val_dataloader, model) # embeddings: sample x emb_size\n",
    "\n",
    "decision_on_thres(pos_scores, neg_scores, 0.4497)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Not Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.num_query_val = 2\n",
    "options.num_support_val = 4\n",
    "options.classes_per_it_val = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[uni] eer:0.1350, thres:0.5927\n"
     ]
    }
   ],
   "source": [
    "options.val_manifest = \"manifests/commands/words/sv/sv_uni_manifest.csv\"\n",
    "val_dataloader = init_sv_loaders(options)\n",
    "\n",
    "pos_scores, neg_scores = similarities(options, val_dataloader, model) # embeddings: sample x emb_size\n",
    "score_vector = np.concatenate([pos_scores, neg_scores])\n",
    "label_vector = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = 1-tpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[uni] eer:{:.4f}, thres:{:.4f}\".format(eer, thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarities From Defined Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def embeds(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt.splice_frame\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, splice_dim//2)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if opt.cuda:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        else:\n",
    "            model_output = model_output.cpu().data\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"up\"\n",
    "sv_df = data_df[data_df.sent == word]\n",
    "spk_counts = sv_df.spk.value_counts()\n",
    "enroll_candidate = list(spk_counts[spk_counts > 5].index)\n",
    "enroll_spks = np.random.choice(enroll_candidate,size=(5,), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c120e80e\n",
      "eer:0.0000, thres:0.8331\n",
      "c1d39ce8\n",
      "eer:0.0769, thres:0.6132\n",
      "9a7c1f83\n",
      "eer:0.0000, thres:0.5213\n",
      "cb2929ce\n",
      "eer:0.0000, thres:0.7194\n",
      "28ce0c58\n",
      "eer:0.0000, thres:0.4437\n",
      "uni\n",
      "eer:0.0462, thres:0.4479\n"
     ]
    }
   ],
   "source": [
    "spk_models = dict()\n",
    "pos_scores = dict()\n",
    "neg_scores = dict()\n",
    "n_enroll = 3\n",
    "n_query = 10\n",
    "for spk in enroll_spks:\n",
    "    enroll_df = sv_df[sv_df.spk == spk][:n_enroll+n_query]\n",
    "    val_dataloader = init_embed_loaders(options, enroll_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    spk_models[spk] = embeddings.mean(0, keepdim=True)\n",
    "       \n",
    "    val_dataloader = init_embed_loaders(options, enroll_df[n_enroll:])\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    pos_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "    \n",
    "    neg_test_df = sv_df[~sv_df.spk.isin(enroll_spks)].sample(n=n_enroll+n_query)\n",
    "    val_dataloader = init_embed_loaders(options, neg_test_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    neg_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "\n",
    "for spk in enroll_spks:\n",
    "    print(spk)\n",
    "    compute_eer(pos_scores[spk], neg_scores[spk])\n",
    "print(\"uni\")\n",
    "compute_eer(torch.cat([v for v in pos_scores.values()]), torch.cat([v for v in neg_scores.values()]))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spk</th>\n",
       "      <th>sent</th>\n",
       "      <th>file</th>\n",
       "      <th>set</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>up4c8417710</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_0.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up4c8417711</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_1.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up4c8417712</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_2.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up4c8417714</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_4.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up4c8417713</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_3.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>up4c8417715</th>\n",
       "      <td>4c841771</td>\n",
       "      <td>up</td>\n",
       "      <td>4c841771_nohash_5.wav</td>\n",
       "      <td>test</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  spk sent                   file   set  label\n",
       "up4c8417710  4c841771   up  4c841771_nohash_0.wav  test    116\n",
       "up4c8417711  4c841771   up  4c841771_nohash_1.wav  test    116\n",
       "up4c8417712  4c841771   up  4c841771_nohash_2.wav  test    116\n",
       "up4c8417714  4c841771   up  4c841771_nohash_4.wav  test    116\n",
       "up4c8417713  4c841771   up  4c841771_nohash_3.wav  test    116\n",
       "up4c8417715  4c841771   up  4c841771_nohash_5.wav  test    116"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enroll_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Not Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "uttrs_counts = data_df.spk.value_counts()\n",
    "valid_spks = list(uttrs_counts[uttrs_counts > 20].index)\n",
    "enroll_spks = np.random.choice(valid_spks, size=(5,), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0e17f595\n",
      "eer:0.0000, thres:0.4552\n",
      "65c73b55\n",
      "eer:0.0000, thres:0.4584\n",
      "364f979f\n",
      "eer:0.0000, thres:0.5204\n",
      "50ed8a7b\n",
      "eer:0.0000, thres:0.6277\n",
      "cab100c9\n",
      "eer:0.0000, thres:0.7718\n",
      "uni\n",
      "eer:0.0600, thres:0.4778\n"
     ]
    }
   ],
   "source": [
    "spk_models = dict()\n",
    "pos_scores = dict()\n",
    "neg_scores = dict()\n",
    "n_enroll = 10\n",
    "n_query = 10\n",
    "for spk in enroll_spks:\n",
    "    enroll_df = data_df[data_df.spk == spk].sample(n=n_enroll+n_query)\n",
    "    val_dataloader = init_embed_loaders(options, enroll_df[:n_enroll])\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    spk_models[spk] = embeddings.mean(0, keepdim=True)\n",
    "       \n",
    "    val_dataloader = init_embed_loaders(options, enroll_df[n_enroll:])\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    pos_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "    \n",
    "    neg_test_df = data_df[~data_df.spk.isin(enroll_spks)].sample(n=n_enroll+n_query)\n",
    "    val_dataloader = init_embed_loaders(options, neg_test_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    neg_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "\n",
    "for spk in enroll_spks:\n",
    "    print(spk)\n",
    "    compute_eer(pos_scores[spk], neg_scores[spk])\n",
    "print(\"uni\")\n",
    "compute_eer(torch.cat([v for v in pos_scores.values()]), torch.cat([v for v in neg_scores.values()])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Recognization Fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### speaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"stop\"\n",
    "sv_df = data_df[data_df.sent == word]\n",
    "spk_counts = sv_df.spk.value_counts()\n",
    "enroll_candidate = list(spk_counts[spk_counts > 3].index)\n",
    "enroll_spks = np.random.choice(enroll_candidate,size=(10,), replace=False)\n",
    "test_spks = np.random.choice(list(set(enroll_candidate)-set(enroll_spks)),size=(10,), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_models = dict()\n",
    "for spk in enroll_spks:\n",
    "    enroll_df = sv_df[sv_df.spk == spk][:2]\n",
    "    val_dataloader = init_embed_loaders(options, enroll_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    spk_models[spk] = embeddings.mean(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test with other word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"right\"\n",
    "test_df = data_df[data_df.sent == word]\n",
    "test_spks = np.random.choice(list(set(test_df.spk.unique())-set(enroll_spks)),size=(10,), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "seq can't be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-119845a3c2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpos_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mspk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_embed_loaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_test_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpos_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspk_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-483946e2cdb6>\u001b[0m in \u001b[0;36membeds\u001b[0;34m(opt, val_dataloader, model, lda)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: seq can't be empty"
     ]
    }
   ],
   "source": [
    "pos_scores = dict()\n",
    "neg_scores = dict()\n",
    "for spk in enroll_spks:\n",
    "    pos_test_df = test_df[test_df.spk == spk]    \n",
    "    val_dataloader = init_embed_loaders(options, pos_test_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    pos_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "    \n",
    "    neg_test_df = test_df[test_df.spk.isin(test_spks)].sample(n=2*len(pos_test_df))\n",
    "    val_dataloader = init_embed_loaders(options, neg_test_df)\n",
    "    embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "    neg_scores[spk] = F.cosine_similarity(embeddings, spk_models[spk])\n",
    "\n",
    "for spk in enroll_spks:\n",
    "    print(spk)\n",
    "    compute_eer(pos_scores[spk], neg_scores[spk])\n",
    "print(\"uni\")\n",
    "compute_eer(torch.cat([v for v in pos_scores.values()]), torch.cat([v for v in neg_scores.values()]))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <audio controls>\n",
       "                        <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\"/>\n",
       "                        Your browser does not support the audio element.\n",
       "                    </audio>\n",
       "                  "
      ],
      "text/plain": [
       "<pydub.audio_segment.AudioSegment at 0x7f872f481c50>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AudioSegment.from_wav(\"/home/muncok/DL/dataset/SV_sets/speech_commands/vad/up/c1d39ce8_nohash_2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <audio controls>\n",
       "                        <source src=\"data:audio/mpeg;base64,SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU2LjQwLjEwMQAAAAAAAAAAAAAA//NYwAAAAAAAAAAAAEluZm8AAAAPAAAABgAAAzwAWVlZWVlZWVlZWVlZWVlZWXp6enp6enp6enp6enp6enp6m5ubm5ubm5ubm5ubm5ubm729vb29vb29vb29vb29vb293t7e3t7e3t7e3t7e3t7e3t7/////////////////////AAAAAExhdmM1Ni42MAAAAAAAAAAAAAAAACQAAAAAAAAAAAM8Bbav+QAAAAAAAAAAAAAA//M4xAAPKLqYH0ZIAA9bruLu7uz7uIIECCERF3esYQAAADYrFZOjbnOcIQQIEBIgYbB8Hz/DH4f/z/KO7//g+//+H+BHd/+D4PptRGN4OUf7/f3+8AAcjUBDROPIGDFuAgGQuTkkXglDskuH//M4xCIdslL2P4lYAnnxDPn75BoEYEICMhpOHD5u680JT6phlXj6CaNpsXDqIap80SRcy0TU1NR4KkmzaIyWWvOJCotY9qLnOlrXXfPfDL/79Z0U2oh31ubVTFf+95/Txy6XkKkmoAHxnSMt//M4xAoWwgblf89YA/KZHiy+MXvWZEk5fRVnta3OY9tRMm7CMtoEEIE1O0Ta4ML/v+aqpW/jvhedhrHZutFpAnsq/+Y/q9iCN643nL2F9eaIuJwVmiz4Xq4Nu+MxAgJJDbAAMNe6DB73adpj//M4xA4Y2eK9X1hoAFG+7Das6jKX6VwQVrTUUgj1lAbFHiHAlxRvWNwFFHCSQoAZw8h3hgCbgSJGSSWZMpzyRspJdknqTNWuy7K/7LWpI+kjZeiip1XVqXSXe6S+yLGLoBK1AQMs888AAi4H//M4xAkXMUKc1Zh4AHKrgKNXgAKTUTsUxy08y+H4dftUhSEDHFyBsobXErkoBck65dkNjOoUI33kW2CuiW1vev/9V+KahwN1p///NGt7b1FDwER91R8KINHvA8LdTksGpeDyAKAUfUwNhGVM//M4xAsRuMHIA8xIAJ0dLnmVq12hyJJ6mEIDxaKoIiZUUiklxYVCqAWBImshJWcihQhIGniIOrDUSu1B3leo90f/+4q7UHf/0ExBTUUzLjk5LjWqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqqq\" type=\"audio/mpeg\"/>\n",
       "                        Your browser does not support the audio element.\n",
       "                    </audio>\n",
       "                  "
      ],
      "text/plain": [
       "<pydub.audio_segment.AudioSegment at 0x7f873032e6d8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AudioSegment.from_wav(\"/home/muncok/DL/dataset/SV_sets/speech_commands/vad/up/c1d39ce8_nohash_0.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
