{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.data.dataloader import init_embed_loaders\n",
    "from dnn.parser import get_sv_parser\n",
    "from dnn.train.model import init_seed\n",
    "from dnn.train.model import init_speechnet\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (4096, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secToSample(sec):\n",
    "    return int(16000 * sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_sv_parser().parse_args(args=[])\n",
    "options.n_dct_filters = 40\n",
    "options.n_mels = 40\n",
    "options.timeshift_ms = 100\n",
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets\"\n",
    "options.window_size= 0.025\n",
    "options.window_stride= 0.010\n",
    "options.cache_size = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.input_format = \"mfcc\"\n",
    "options.input_clip = True\n",
    "options.input_length = secToSample(3) # if input_clip is false, it doesn't affect anything\n",
    "options.splice_frames = secToSample(0.1)//160+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\"\n",
    "options.model = \"res15\"\n",
    "model = init_speechnet(options)\n",
    "lda = None# None means not using lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/reddots/simplecnn/si_reddots_0.2s_random_2.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/reddots/simplecnn/si_reddots_0.2s_random_2.pt\"\n",
    "options.model = \"SimpleCNN\"\n",
    "model =  init_speechnet(options)\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/commands/word_aligned.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/commands/word_aligned.pt\"\n",
    "options.model = \"SimpleCNN\"\n",
    "model = init_speechnet(options)\n",
    "lda = pickle.load(open(\"models/lda/word_aligned_lda.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reddots Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def lda_on_tensor(tensor, lda):\n",
    "    return torch.from_numpy(lda.transform(tensor.numpy()).astype(np.float32))\n",
    "\n",
    "def embeds(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt.splice_frames\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, splice_dim)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if opt.cuda:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_ndx = pd.read_pickle(\"trials/reddots/m_part1/m_part1_ndx.pkl\")\n",
    "m_part1_trn = pd.read_pickle('trials/reddots/m_part1/m_part1_trn.pkl')\n",
    "# m_part4_ndx = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_ndx.pkl\")\n",
    "# m_part4_trn = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_trn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = m_part1_trn\n",
    "ndx = m_part1_ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type = {0:'TC', 1:'TW', 2:'IC', 3:'IW'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enrollment (trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_embed_loaders(options, trn) \n",
    "trn_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SV Scoring (ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_files = pd.read_pickle('trials/reddots/m_part1/m_part1_files.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_embed_loaders(options, m_part1_files) \n",
    "ndx_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "# torch.save(ndx_embeddings, 'trials/reddots/m_part1/{}_embeds.pkl'.format(model_name))\n",
    "# ndx_embeddings = torch.load('trials/reddots/m_part1/{}_embeds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2141cc4cd73a4dff80fa12b31c3436c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_trials = ndx.id.unique().tolist()\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    scores[t] = []\n",
    "    \n",
    "for trial_id in tqdm(all_trials):\n",
    "    trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "    trial_embed_idx = np.nonzero(m_part1_files.file.isin(trial_ndx.file))\n",
    "    trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "    sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id])\n",
    "    for t in range(4):\n",
    "        trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "        scores[t].append(sim[trial_type_idx])\n",
    "        \n",
    "# [TC, TW, IC, IW]\n",
    "for t in range(4):\n",
    "    scores[t] = torch.cat(scores[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC mean:1.00, std:0.000\n",
      "TW mean:1.00, std:0.000\n",
      "IC mean:1.00, std:0.000\n",
      "IW mean:1.00, std:0.000\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "     print(\"{} mean:{:.2f}, std:{:.3f}\".format(err_type[t], scores[t].mean(), scores[t].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TW] eer: 0.42, thres: 0.99989\n",
      "[IC] eer: 0.31, thres: 0.99985\n",
      "[IW] eer: 0.29, thres: 0.99984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TI] eer: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score_vector = np.concatenate((scores[0], scores[1],\n",
    "                              scores[2], scores[3]))\n",
    "label_vector = np.concatenate((np.ones(len(scores[0]) + len(scores[1])), \n",
    "                           np.zeros(len(scores[2]) + len(scores[3]))))\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.2f}\".format(eer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
