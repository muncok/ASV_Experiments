{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe style looks better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dir = '/home/muncok/DL/dataset/SV_sets/dataframes/'\n",
    "data_dir = '/home/muncok/DL/dataset/SV_sets/speech_commands' # to concatenate audios\n",
    "data_df = pd.read_pickle('/home/muncok/DL/dataset/SV_sets/dataframes/Command_Dataframe.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spks = list(data_df.spk.unique())\n",
    "all_words = list(data_df.sent.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifest For Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common word를 정한다.  \n",
    "common word는 등록된 command set이고,  (i.e., \"ok\", \"google\")  \n",
    "나머지 unknown words는 등록되지 않은 set이라고 생각하면 된다. (따라서 si_train에 보이지 않는다.) (i.e., \"seoul\", \"incheon\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'nine', 'off', 'one', 'seven', 'up', 'yes', 'eight', 'four',\n",
       "       'three', 'right', 'left', 'two', 'five', 'down', 'zero', 'on',\n",
       "       'stop', 'six', 'go'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_common_words = 20 # <= 20\n",
    "common_words = np.random.choice(data_df.sent.value_counts().index[:20], 20, replace=False)\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house',\n",
       " 'wow',\n",
       " 'sheila',\n",
       " 'cat',\n",
       " 'happy',\n",
       " 'tree',\n",
       " 'dog',\n",
       " 'marvin',\n",
       " 'bird',\n",
       " 'bed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown_words = list(set(all_words) - set(common_words))\n",
    "unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_df = data_df[data_df.sent.isin(common_words)]\n",
    "unknown_words_df = data_df[data_df.sent.isin(unknown_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enroll DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_candidate = common_words_df.spk.value_counts().index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 common words를 4개 이상 가진 스피커를 enroll speaker로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_spks = []\n",
    "for spk in enroll_candidate:\n",
    "    word_counts = common_words_df[common_words_df.spk == spk].groupby(['sent']).size()\n",
    "    if np.count_nonzero(word_counts > 3) == len(common_words):\n",
    "        enroll_spks.append(spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of enroll spks: 146\n"
     ]
    }
   ],
   "source": [
    "print(\"number of enroll spks: {}\".format(len(enroll_spks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 word의 몇 개의 발화를 enroll에 쓸건지 정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_enroll_uttrs = 2\n",
    "positive_df = common_words_df[common_words_df.spk.isin(enroll_spks)] # utterances from enroll spks\n",
    "grouped = positive_df.groupby(['spk', 'sent'], as_index=False, group_keys=False)\n",
    "enroll_df = grouped.apply(lambda x: x.sample(n=n_enroll_uttrs)) # enroll utterances for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial이 저장될 폴더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"trials/commands/{}word_{}uttrs\".format(len(common_words), n_enroll_uttrs)\n",
    "if not os.path.isdir(dir_name):\n",
    "    os.makedirs(dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_df.to_pickle(\"{}/enroll.pkl\".format(dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EnrollSpeaker's Test Utterance DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_idx = [idx[-1] for idx in enroll_df.index]\n",
    "pos_test_df = data_df[data_df.spk.isin(enroll_spks)].drop(index=enroll_df.index) # test_uttrs contain unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_test_df.to_pickle(\"{}/posTest.pkl\".format(dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imposter's Test Utterance DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_enroll_df = data_df[~data_df.spk.isin(enroll_spks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imposter_df는 오히려 uttrs를 적게 가지고 있는 spk들을 중심으로 뽑았다.  \n",
    "그리고 word는 common이랑 unknown을 모두 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imposter_spks = not_enroll_df.spk.value_counts().index[-300:]\n",
    "imposter_df = not_enroll_df[not_enroll_df.spk.isin(imposter_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imposter_df.to_pickle(\"{}/negTest.pkl\".format(dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For KWS or SI DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposter와 겹치면 안된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_df = not_enroll_df.drop(index=imposter_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kws_df.to_pickle(\"{}/kws.pkl\".format(dir_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(enroll_df.index) & set(pos_test_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(imposter_df.index) & set(pos_test_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(set(imposter_df.index) | set(pos_test_df.index) | set(enroll_df.index)) & (set(kws_df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enroll을 제외한 (pos|neg) test utterances만 concat하면 된다.  \n",
    "e.g. \"yes\" + \"one\" + \"left\" --> \"yes one left\"  \n",
    "차라리 vad를 써서 중간에 공백을 적당히 넣는게 낫지않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words_in_uttr = 3\n",
    "grouped = pos_test_df.groupby(['spk'], as_index=True, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uttrs_per_spk = grouped "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
