{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_home_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/'\n",
    "rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "rDots_infos_dir = os.path.join(rDots_home_dir, 'infos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = 'm'\n",
    "part_n = 1\n",
    "prefix = \"{}_part{}\".format(gender, str(part_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_ndx(ndx_dir, gender, part_num):\n",
    "    assert (gender in ['f', 'm'])\n",
    "    assert (part_num in [1,2,3,4])\n",
    "    spk_sent_ID, file_names, trial_types = [], [], []\n",
    "    \n",
    "    with open(ndx_dir + gender + '_part_0' + str(part_num) + '.ndx', 'r') as ndx:\n",
    "        lines = ndx.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            [spk_sent, utterance, TC, TW, IC, IW] = line.split(',')\n",
    "            file_names.append(utterance+\".wav\")\n",
    "            spk_sent_ID.append(spk_sent)\n",
    "\n",
    "            if TC=='Y': trial_types.append(0) \n",
    "            elif TW=='Y': trial_types.append(1) \n",
    "            elif IC=='Y': trial_types.append(2) \n",
    "            elif IW=='Y': trial_types.append(3) \n",
    "    return [spk_sent_ID, file_names,  trial_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "spk_sent_ID, file_names,trial_types = rDots_parse_ndx(rDots_ndx_dir, gender, part_n)\n",
    "ndx_dict = dict(id=spk_sent_ID, file=file_names, trial_type=trial_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx = pd.DataFrame.from_dict(ndx_dict)\n",
    "manifest_dir = \"manifests/reddots/trial/{}/\".format(prefix)\n",
    "if not os.path.isdir(manifest_dir):\n",
    "    os.makedirs(manifest_dir)\n",
    "ndx.to_pickle(os.path.join(manifest_dir, \"{}_ndx.pkl\".format(prefix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text-independent\n",
    "if part_n == 4:\n",
    "    part_n = '4_tp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_trn(trn_dir, gender, part_num):\n",
    "    assert (gender in ['f', 'm'])\n",
    "    assert (part_num in [1,2,3,'4_tp', '4_td'])\n",
    "    spk_sent_ID, file_names = [], []\n",
    "\n",
    "    with open(trn_dir + gender + '_part_0' + str(part_num) + '.trn', 'r') as trn:\n",
    "        lines = trn.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            [spk_sent, utters] = line.split(' ')\n",
    "            utters = utters.split(',')\n",
    "            for uttr in utters:\n",
    "                spk_sent_ID.append(spk_sent)\n",
    "                file_names.append(uttr+\".wav\")\n",
    "    assert(len(spk_sent_ID) == len(file_names))\n",
    "    return [spk_sent_ID, file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_trn_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "[spk_sent, file_names] = rDots_parse_trn(rDots_trn_dir, gender, part_n)\n",
    "trn_dict = dict(id=spk_sent, file=file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.DataFrame.from_dict(trn_dict)\n",
    "trn.to_pickle(os.path.join(manifest_dir,\"{}_trn.pkl\".format(prefix)))\n",
    "trn_id = list(trn.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_ndx = pd.read_pickle(\"manifests/reddots/trial/m_part1/m_part1_ndx.pkl\")\n",
    "m_part1_trn = pd.read_pickle(\"manifests/reddots/trial/m_part1/m_part1_trn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_trn_files = m_part1_trn.file.unique().tolist()\n",
    "m_part1_ndx_files = m_part1_ndx.file.unique().tolist()\n",
    "m_part1_files = m_part1_trn_files + m_part1_ndx_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(m_part1_files, open(\"./trials/reddots/m_part1/m_part1_files.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/token/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict()\n",
    "for file in m_part1_files:\n",
    "    uttr_name = file.split('/')[1][:-4]\n",
    "    tokens[uttr_name] = os.listdir(os.path.join(data_dir, file[:-4]))\n",
    "\n",
    "rows = []\n",
    "for k,v in tokens.items():\n",
    "    for v_i in v:\n",
    "        _, spk, phrase, _ = v_i.split('_')\n",
    "        rows.append([spk, phrase, k, v_i])\n",
    "\n",
    "m_part1_token = pd.DataFrame(rows, columns=['spk', 'sent', 'utterance', 'token_file'])\n",
    "\n",
    "# m_part1_token.to_pickle(\"./trials/reddots/m_part1_token_files.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
