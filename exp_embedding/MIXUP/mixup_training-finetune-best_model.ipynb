{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mix-up training\n",
    "\n",
    "paper: https://arxiv.org/abs/1710.09412  \n",
    "code: https://github.com/facebookresearch/mixup-cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_fbank_xvector\",\n",
    "                              input_frames=800, splice_frames=[300, 800], stride_frames=1, \n",
    "                              input_format='fbank',\n",
    "                              cuda=True,\n",
    "                              lrs=[0.001, 0.001], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False,\n",
    "                              batch_size=128,\n",
    "                              arch=\"ResNet34_v4\", loss=\"softmax\",\n",
    "                              n_epochs=10\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.data_utils import find_dataset, find_trial\n",
    "\n",
    "_, datasets = find_dataset(config, basedir='../')\n",
    "trial = find_trial(config, basedir='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_loaders\n",
    "\n",
    "dataloaders = init_loaders(config, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.model.model_utils import find_model\n",
    "model = find_model(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "saved_model = torch.load(\"../best_models/voxc1/ResNet34_v4_softmax/ResNet34_v4_softmax_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "model_state = model.state_dict()\n",
    "for k1, k2 in zip(saved_model['state_dict'], model_state):\n",
    "#     print(k1, k2)\n",
    "    assert saved_model['state_dict'][k1].shape == model_state[k2].shape\n",
    "    model_state[k2] = saved_model['state_dict'][k1]\n",
    "    \n",
    "\n",
    "model.load_state_dict(model_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.train.train_utils import set_seed, find_optimizer\n",
    "\n",
    "criterion, optimizer = find_optimizer(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_eer']:\n",
    "    train_loader, val_loader, test_loader, sv_loader = dataloaders\n",
    "else:\n",
    "    train_loader, val_loader, test_loader = dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from sv_system.train.train_utils import print_eval\n",
    "\n",
    "alpha = 0.1\n",
    "def train(config, train_loader, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    print_steps = (np.array([0.25, 0.5, 0.75, 1.0]) \\\n",
    "                    * len(train_loader)).astype(np.int64)\n",
    "\n",
    "    splice_frames = config['splice_frames']\n",
    "    if len(splice_frames) > 1:\n",
    "        splice_frames_ = np.random.randint(splice_frames[0], splice_frames[1])\n",
    "    else:\n",
    "        splice_frames_ = splice_frames[-1]\n",
    "\n",
    "    for batch_idx, (X, y) in tqdm_notebook(enumerate(train_loader), ncols=300,\n",
    "            total=len(train_loader)):\n",
    "        # X.shape is (batch, channel, time, bank)\n",
    "        X = X.narrow(2, 0, splice_frames_)\n",
    "        X, y_a, y_b, lam = mixup_data(x=X, y=y, alpha=alpha, use_cuda=False)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            X = X.cuda()\n",
    "            y_a = y_a.cuda()\n",
    "            y_b = y_b.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(X)\n",
    "        loss = mixup_criterion(criterion, scores, y_a, y_b, lam)\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        # learning rate change\n",
    "        optimizer.step()\n",
    "        # schedule over iteration\n",
    "        predicted = torch.argmax(scores, dim=1)\n",
    "        corrects += (lam * predicted.eq(y_a).cpu().sum().float()\n",
    "                    + (1 - lam) * predicted.eq(y_b).cpu().sum().float())\n",
    "        total += y_a.size(0)\n",
    "        if batch_idx in print_steps:\n",
    "            print(\"train loss, acc: {:.4f}, {:.5f} \".format(corrects/total, loss_sum))\n",
    "            \n",
    "    return loss_sum, corrects/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha value: 0.1\n",
      "------------------------------\n",
      "curr_lr: 0.001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f717387c8f46d99753f88c52e9b411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, layout=Layout(flex='2'), max=1042), HTML(value='')), layout=Layout(displayâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss, acc: 0.8992, 488.82143 \n",
      "train loss, acc: 0.9019, 891.48855 \n"
     ]
    }
   ],
   "source": [
    "from sv_system.train.si_train import val, sv_test\n",
    "\n",
    "print(\"alpha value: {}\".format(alpha))\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    idx = 0\n",
    "    while(epoch_idx >= config['lr_schedule'][idx]):\n",
    "    # use new lr from schedule epoch not a next epoch\n",
    "        idx += 1\n",
    "        if idx == len(config['lr_schedule']):\n",
    "            break\n",
    "    curr_lr = config['lrs'][idx]\n",
    "    optimizer.state_dict()['param_groups'][0]['lr'] = curr_lr\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "\n",
    "#     train code\n",
    "    train_loss, train_acc = train(config, train_loader, model, optimizer, criterion)\n",
    "\n",
    "#     validation code\n",
    "    val_loss, val_acc = val(config, val_loader, model, criterion, tqdm=tqdm_notebook)\n",
    "    print(\"epoch #{}, val accuracy: {}\".format(epoch_idx, val_acc))\n",
    "\n",
    "#     evaluate best_metric\n",
    "    if not config['no_eer']:\n",
    "        # eer validation code\n",
    "        eer, label, score = sv_test(config, sv_loader, model, trial, tqdm=tqdm_notebook)\n",
    "        print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
