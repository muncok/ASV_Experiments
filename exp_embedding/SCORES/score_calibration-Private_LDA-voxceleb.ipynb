{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score_calibration\n",
    "------------------------\n",
    "\n",
    "화자의 추가 정보를 이용해서 score를 조정하여 특정 화자에 대해 성능이 좋아지게하려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private_LDA\n",
    "------------------------\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/host/projects/sv_experiments/sv_system/')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key2df(keys, delimeter=\"-\"):\n",
    "    key_df = pd.DataFrame(keys, columns=['key'])\n",
    "    key_df['spk'] = key_df.key.apply(lambda x: x.split(delimeter)[0])\n",
    "    key_df['label'] = key_df.groupby('spk').ngroup()\n",
    "    key_df['origin'] = key_df.spk.apply(lambda x: 'voxc2' if x.startswith('id') else 'voxc1')\n",
    "    \n",
    "    return key_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local LDA  implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "def euc_dist(a, b):\n",
    "    return ((a * a) + (b * b) - b * a).sum(1)\n",
    "\n",
    "def cos_dist(a, b):\n",
    "    a = a / np.linalg.norm(a, axis=1, keepdims=True)\n",
    "    b = b / np.linalg.norm(b, axis=1, keepdims=True)\n",
    "    return -(a*b).sum(1)\n",
    "\n",
    "def cos_sim_batch(a, b, axis=2):\n",
    "    a = torch.from_numpy(a)\n",
    "    b = torch.from_numpy(b)\n",
    "    \n",
    "    return cosine_similarity(a, b, dim=axis).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## centering embeds\n",
    "\n",
    "def train_lda_model(key_df, embeds, lda_dim=200):\n",
    "    spks = sorted(key_df.spk.unique().tolist())\n",
    "    overall_mean = embeds.mean(0)\n",
    "#     embeds_centered = embeds - overall_mean\n",
    "    embeds_centered = embeds\n",
    "\n",
    "    mean_vectors = []\n",
    "    for spk in spks:\n",
    "        mean_vectors.append(embeds_centered[key_df[key_df.spk == spk].index].mean(0))\n",
    "\n",
    "    # within-class scatter matrix Sw\n",
    "    S_W = np.zeros([512, 512])\n",
    "\n",
    "    for spk, cl_mean in zip(spks, mean_vectors):\n",
    "        cl_embeds = embeds_centered[key_df[key_df.spk == spk].index]\n",
    "        x_m = cl_embeds - cl_mean.reshape(1, 512)\n",
    "        x_m = np.expand_dims(x_m, -1)\n",
    "        cl_sc = np.matmul(x_m, x_m.transpose([0,2,1])).sum(0)\n",
    "        S_W += cl_sc\n",
    "\n",
    "    # between-class scatter matrix SB\n",
    "    S_B = np.zeros([512, 512])\n",
    "\n",
    "    for spk, cl_mean in zip(spks, mean_vectors):\n",
    "        ovm_m = np.expand_dims(cl_mean, -1) - np.expand_dims(overall_mean, -1)\n",
    "        ns = len(key_df[key_df.spk == spk])\n",
    "        S_B += ns*ovm_m.dot(ovm_m.T)\n",
    "    \n",
    "    eig_vals, eig_vecs = np.linalg.eig(np.linalg.inv(S_W).dot(S_B))\n",
    "    # Make a list of (eigenvalue, eigenvector) tuples\n",
    "    eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "    # Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "    eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True)\n",
    "    W = np.hstack([eig_pairs[i][1].reshape(512,1) for i in range(lda_dim)])\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # local LDA\n",
    "# # modify the bewenn-class scatter matrix SB --> PSB\n",
    "\n",
    "# imposter_means = dict()\n",
    "\n",
    "# for spk, cl_mean in zip(si_spks, mean_vectors):\n",
    "#     cl_embeds = si_embeds_centered[si_key_df[si_key_df.spk == spk].index]\n",
    "#     out_embeds = si_embeds_centered[si_key_df[si_key_df.spk != spk].index]\n",
    "#     out_distances = cos_dist(cl_mean.reshape(1,512), out_embeds)\n",
    "#     max_dist_in_samples = cos_dist(cl_mean.reshape(1,512), cl_embeds).max()\n",
    "#     out_embeds = out_embeds[out_distances < max_dist_in_samples]\n",
    "#     if len(out_embeds) > 1000:\n",
    "#         imposter_mean = out_embeds.mean(0)\n",
    "#     else:\n",
    "#         imposter_mean = si_overall_mean\n",
    "#     imposter_means[spk] = imposter_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PS_B = np.zeros([512, 512])\n",
    "# for spk, cl_mean in zip(si_spks, mean_vectors):    \n",
    "#     ovm_m = cl_mean.reshape(512, 1) - imposter_means[spk].reshape(512, 1)\n",
    "#     ns = len(si_key_df[si_key_df.spk == spk])\n",
    "#     PS_B += ns*ovm_m.dot(ovm_m.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_embeds(key_df, spks, embeds):\n",
    "    key_df_for_spks = key_df[key_df.spk.isin(spks)]\n",
    "    embeds_for_spks = embeds[key_df_for_spks.index]\n",
    "    \n",
    "    return key_df_for_spks.reset_index(), embeds_for_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_keys = pickle.load(open(\"/host/projects/sv_experiments/sv_system/embeddings/voxc1/voxc1_mfcc30_best/si_keys.pkl\", \"rb\"))\n",
    "si_embeds = np.load(\"/host/projects/sv_experiments/sv_system/embeddings/voxc1/voxc1_mfcc30_best/si_embeds.npy\")\n",
    "\n",
    "sv_keys = pickle.load(open(\"/host/projects/sv_experiments/sv_system/embeddings/voxc1/voxc1_mfcc30_best/sv_keys.pkl\", \"rb\"))\n",
    "sv_embeds = np.load(\"/host/projects/sv_experiments/sv_system/embeddings/voxc1//voxc1_mfcc30_best/sv_embeds.npy\")\n",
    " \n",
    "trial = pd.read_pickle(\"/dataset/SV_sets/voxceleb12/dataframes/voxc12_test_trial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key_df = key2df(si_keys)\n",
    "sv_key_df = key2df(sv_keys)\n",
    "\n",
    "si_spks = sorted(si_key_df.spk.unique().tolist())\n",
    "sv_spks = sorted(sv_key_df.spk.unique().tolist())\n",
    "\n",
    "si_spks_array = np.array(si_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embed_mean for each speaker\n",
    "si_spk_embed_means = []\n",
    "for spk in si_spks:\n",
    "    spk_embed =  si_embeds[si_key_df[si_key_df.spk == spk].index]\n",
    "    spk_embed_mean  = spk_embed.mean(0)\n",
    "    si_spk_embed_means.append(spk_embed_mean)\n",
    "\n",
    "si_spk_embed_means = np.array(si_spk_embed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_mean for each speaker\n",
    "sv_spk_embed_means = []\n",
    "for spk in sv_spks:\n",
    "    spk_embed =  sv_embeds[sv_key_df[sv_key_df.spk == spk].index]\n",
    "    spk_embed_mean  = spk_embed.mean(0)\n",
    "    sv_spk_embed_means.append(spk_embed_mean)\n",
    "\n",
    "sv_spk_embed_means = np.array(sv_spk_embed_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_si_sim = cos_sim_batch(np.expand_dims(sv_spk_embed_means, 1), np.expand_dims(si_spk_embed_means, 0), axis=2)\n",
    "sorted_close_spks = np.argsort(sv_si_sim, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_inner_lowest_sim = []\n",
    "\n",
    "for spk in sv_spks:\n",
    "    spk_embed = sv_embeds[sv_key_df[sv_key_df.spk == spk].index]\n",
    "    spk_embed_mean = spk_embed.mean(0, keepdims=True)\n",
    "    inner_sim = cos_sim_batch(spk_embed_mean, \n",
    "                              spk_embed, axis=1)\n",
    "    sv_inner_lowest_sim.append(inner_sim.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_close_si_spks = dict()\n",
    "\n",
    "for i, spk in enumerate(sv_spks):\n",
    "    close_spks = si_spks_array[sv_si_sim[i] > sv_inner_lowest_sim[i]]\n",
    "    sv_close_si_spks[spk] = close_spks.tolist()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=200, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "clf = LDA(solver='svd', n_components=200)\n",
    "clf.fit(si_embeds, si_key_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_LDA = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_embeds = overall_LDA.transform(sv_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer:8.282% at threshold 0.1341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08282078472958643, 0.1340561357874964)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval.score_utils import compute_eer\n",
    "scores = cos_sim_batch(lda_embeds[trial.enrolment_id], lda_embeds[trial.test_id], axis=1)\n",
    "compute_eer(scores[trial.label == 1], scores[trial.label == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline - average enrolled embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_spks_df = sv_key_df.groupby('spk').apply(lambda x: x.sample(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled_uttrs = dict()\n",
    "enrolled_aveg_embeds = []\n",
    "for spk in sv_spks:\n",
    "    enrolled_uttrs[spk] = enrolled_spks_df.loc[spk].key.tolist()\n",
    "    enrolled_aveg_embeds.append(lda_embeds[sv_key_df[sv_key_df.key.isin(enrolled_uttrs[spk])].index].mean(0))\n",
    "enrolled_aveg_embeds = np.array(enrolled_aveg_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_enrolled_uttrs = np.array([v for v in enrolled_uttrs.values()]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trial = trial[~trial.test_idx.isin(all_enrolled_uttrs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "filtered_trial['enrolment_id'] = filtered_trial.enroll_spk.apply(lambda x: sv_spks.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer:1.618% at threshold 0.2766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.016183283619978422, 0.2765653736591283)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval.score_utils import compute_eer\n",
    "scores = cos_sim_batch(enrolled_aveg_embeds[filtered_trial.enrolment_id], \n",
    "                       lda_embeds[filtered_trial.test_id], axis=1)\n",
    "compute_eer(scores[filtered_trial.label == 1], scores[filtered_trial.label == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer:8.282% at threshold 0.1341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.08282078472958643, 0.1340561357874964)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from eval.score_utils import compute_eer\n",
    "scores = cos_sim_batch(lda_embeds[trial.enrolment_id], lda_embeds[trial.test_id], axis=1)\n",
    "compute_eer(scores[trial.label == 1], scores[trial.label == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
