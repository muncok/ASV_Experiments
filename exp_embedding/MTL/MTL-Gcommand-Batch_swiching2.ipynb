{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 sent label로 같이 MTL을 하면\n",
    "\n",
    "같은 sent일 때는 좀더 성능이 좋아질지?\n",
    "\n",
    "혹은 positive도 강화되지만 negative도 강화될지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "sys.path.append('../sv_system/')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "args = easydict.EasyDict(dict(dataset=\"gcommand_equal30_wav\",\n",
    "                              input_frames=100, splice_frames=[20, 100], stride_frames=1, input_format='fbank',\n",
    "                              cuda=True,\n",
    "                              lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False,\n",
    "                              batch_size=128,\n",
    "                              arch=\"ResNet34\", loss=\"softmax\",\n",
    "                              n_epochs=50,\n",
    "                              lamb=0.3\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_si_df = pd.read_pickle(\"../dataset/dataframes/gcommand/equal_num_30spk/equal_num_30spk_si.pkl\")\n",
    "gc_sv_df = pd.read_pickle(\"../dataset/dataframes/gcommand/equal_num_30spk/equal_num_30spk_sv.pkl\")\n",
    "\n",
    "unique_spks = gc_si_df.spk.unique().tolist()\n",
    "unique_sents = gc_si_df.sent.unique().tolist()\n",
    "\n",
    "gc_si_df['sent_label'] = gc_si_df.sent.apply(lambda x: unique_sents.index(x))\n",
    "gc_sv_df['sent_label'] = gc_sv_df.sent.apply(lambda x: unique_sents.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.data_utils import find_dataset, find_trial\n",
    "\n",
    "\n",
    "_, datasets = find_dataset(config, basedir='../')\n",
    "trial = find_trial(config, basedir='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataset import mtlSpeechDataset\n",
    "\n",
    "train_dataset = mtlSpeechDataset.read_df(config, gc_si_df, \"train\")\n",
    "datasets[2] = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_loaders\n",
    "\n",
    "dataloaders = init_loaders(config, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.model.ResNet34 import ResNet34\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet34_v1(ResNet34):\n",
    "    \"\"\"\n",
    "        additional fc layer before output layer\n",
    "    \"\"\"\n",
    "    def __init__(self, config, inplanes=16, n_labels1=1000, n_labels2=1000, fc_dims=None):\n",
    "        super().__init__(config, inplanes, 10)\n",
    "\n",
    "        extractor_output_dim = 8*inplanes\n",
    "        if not fc_dims:\n",
    "            fc_dims = extractor_output_dim\n",
    "\n",
    "        fc = [nn.Linear(extractor_output_dim,fc_dims),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "\n",
    "        self.fc = nn.Sequential(*fc)\n",
    "        \n",
    "        self.classifier_1 = nn.Linear(fc_dims, n_labels1) # for spks\n",
    "        self.classifier_2 = nn.Linear(fc_dims, n_labels2) # for sents\n",
    "    \n",
    "    def extract(self, x):\n",
    "        x = self.extractor(x)\n",
    "        x = F.avg_pool2d(x,x.shape[-2:])\n",
    "        x = x.view(x.size(0), -1)\n",
    "        feat = self.fc(x)\n",
    "        \n",
    "        return feat\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.spk_out(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def joint_forward(self, x):\n",
    "        feat = self.extract(x)\n",
    "        \n",
    "        out1 = self.classifier_1(feat)\n",
    "        out2 = self.classifier_2(feat)\n",
    "        \n",
    "        return out1, out2\n",
    "        \n",
    "    def spk_out(self, x):\n",
    "        feat = self.extract(x)\n",
    "        out1 = self.classifier_1(feat)\n",
    "        \n",
    "        return out1\n",
    "    \n",
    "    def sent_out(self, x):\n",
    "        feat = self.extract(x)\n",
    "        out2 = self.classifier_2(feat)\n",
    "        \n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.model.tdnnModel import gTDNN, st_pool_layer\n",
    "\n",
    "class tdnn_xvector(gTDNN):\n",
    "    \"\"\"xvector architecture\"\"\"\n",
    "    def __init__(self, config, n_labels_spk, n_labels_sent):\n",
    "        super(tdnn_xvector, self).__init__(config, n_labels_spk)\n",
    "        inDim = config['input_dim']\n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Conv1d(inDim, 512, stride=1, dilation=1, kernel_size=5),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=3, kernel_size=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=4, kernel_size=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.spk_seg = nn.Sequential(\n",
    "            nn.Conv1d(512, 1500, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.BatchNorm1d(1500),\n",
    "            nn.ReLU(True),\n",
    "            st_pool_layer(),\n",
    "            nn.Linear(3000, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            ####################\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, n_labels_spk),\n",
    "        )\n",
    "        \n",
    "        self.sent_seg = nn.Sequential(\n",
    "            nn.Conv1d(512, 1500, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.BatchNorm1d(1500),\n",
    "            nn.ReLU(True),\n",
    "            st_pool_layer(),\n",
    "            nn.Linear(3000, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            ##################3333333##\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, n_labels_sent),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def embed(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        # (batch, time, freq) -> (batch, freq, time)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.extractor(x)\n",
    "        x = self.spk_seg(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def sent_out(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        x = x.permute(0,2,1)\n",
    "        feat = self.extractor(x)\n",
    "        out_sent = self.sent_seg(feat)\n",
    "        \n",
    "        return out_sent\n",
    "    \n",
    "    def spk_out(self, x):\n",
    "        feat = self.embed(x)\n",
    "        out_spk = self.classifier(feat)\n",
    "\n",
    "        return out_spk\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spk_out(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def joint_forward(self, x):\n",
    "        out_spk = self.spk_out(x)\n",
    "        out_sent = self.sent_out(x)\n",
    "        \n",
    "        return out_spk, out_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tdnn_xvector(config,  len(unique_spks), len(unique_sents))\n",
    "# model = ResNet34_v1(config, n_labels1=len(unique_spks), n_labels2=len(unique_sents), fc_dims=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config[\"no_cuda\"]:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model = model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sv_system.train.train_utils import set_seed, find_optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion, joint_optimizer = find_optimizer(config, model)\n",
    "\n",
    "sent_optimizer = torch.optim.SGD([{'params':model.extractor.parameters()}, \n",
    "                                  {'params':model.sent_seg.parameters()}], \n",
    "                                lr=0.01,\n",
    "                                momentum=config['momentum'],\n",
    "                                weight_decay=config['weight_decay'],\n",
    "                                nesterov=config['use_nesterov'])\n",
    "\n",
    "spk_optimizer = torch.optim.SGD([{'params':model.extractor.parameters()}, \n",
    "                                 {'params':model.spk_seg.parameters()},\n",
    "                                 {'params':model.classifier.parameters()}],\n",
    "                                lr=0.01,\n",
    "                                momentum=config['momentum'],\n",
    "                                weight_decay=config['weight_decay'],\n",
    "                                nesterov=config['use_nesterov'])\n",
    "\n",
    "# sent_optimizer = torch.optim.SGD([{'params':model.extractor.parameters()}, \n",
    "#                                   {'params':model.classifier_2.parameters()}], \n",
    "#                                 lr=0.01,\n",
    "#                                 momentum=config['momentum'],\n",
    "#                                 weight_decay=config['weight_decay'],\n",
    "#                                 nesterov=config['use_nesterov'])\n",
    "\n",
    "# spk_optimizer = torch.optim.SGD([{'params':model.extractor.parameters()}, \n",
    "#                                  {'params':model.classifier_1.parameters()}],\n",
    "#                                 lr=0.1,\n",
    "#                                 momentum=config['momentum'],\n",
    "#                                 weight_decay=config['weight_decay'],\n",
    "#                                 nesterov=config['use_nesterov'])\n",
    "\n",
    "\n",
    "scheduler = ReduceLROnPlateau(spk_optimizer, 'min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['seed'] = 13\n",
    "set_seed(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_eer']:\n",
    "    train_loader, val_loader, joint_loader, sv_loader = dataloaders\n",
    "else:\n",
    "    train_loader, val_loader, joint_loader = dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl trai\n",
    "from tqdm import tqdm_notebook\n",
    "from sv_system.train.train_utils import print_eval\n",
    "\n",
    "def train(config, train_loader, model, optimizer_spk, criterion):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    print_steps = (np.arange(1,11)*0.1 \\\n",
    "                    * len(train_loader)).astype(np.int64)\n",
    "\n",
    "    splice_frames = config['splice_frames']\n",
    "    if len(splice_frames) > 1:\n",
    "        splice_frames_ = np.random.randint(splice_frames[0], splice_frames[1])\n",
    "    else:\n",
    "        splice_frames_ = splice_frames[-1]\n",
    "\n",
    "    for batch_idx, (X, y_spk) in enumerate(train_loader):\n",
    "        # X.shape is (batch, channel, time, bank)\n",
    "        X = X.narrow(2, 0, splice_frames_)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            X = X.cuda()\n",
    "            y_spk = y_spk.cuda()\n",
    "            \n",
    "        logit_spk = model(X)\n",
    "        loss_spk = criterion(logit_spk, y_spk)\n",
    "\n",
    "        optimizer_spk.zero_grad()           \n",
    "        loss_sum += loss_spk.item()\n",
    "        loss_spk.backward()\n",
    "        optimizer_spk.step()\n",
    "        predicted = torch.argmax(logit_spk, dim=1)\n",
    "        corrects += predicted.eq(y_spk).cpu().sum().float()\n",
    "        total += y_spk.size(0)\n",
    "        if batch_idx in print_steps:\n",
    "            print(\"train loss: {:.4f}, acc: {:.5f} \" \\\n",
    "                  .format(loss_sum/total, corrects/total))\n",
    "            \n",
    "    return loss_sum, corrects/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mtl trai\n",
    "from tqdm import tqdm_notebook\n",
    "from sv_system.train.train_utils import print_eval\n",
    "\n",
    "def batch_switch_train(config, train_loader, model, optimizer_spk, \n",
    "                       optimizer_sent, criterion):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    print_steps = (np.arange(1,11)*0.1 \\\n",
    "                    * len(train_loader)).astype(np.int64)\n",
    "\n",
    "    splice_frames = config['splice_frames']\n",
    "    if len(splice_frames) > 1:\n",
    "        splice_frames_ = np.random.randint(splice_frames[0], splice_frames[1])\n",
    "    else:\n",
    "        splice_frames_ = splice_frames[-1]\n",
    "\n",
    "    for batch_idx, (X, y_spk, y_sent) in enumerate(train_loader):\n",
    "        # X.shape is (batch, channel, time, bank)\n",
    "        X = X.narrow(2, 0, splice_frames_)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            X = X.cuda()\n",
    "            y_spk = y_spk.cuda()\n",
    "            y_sent = y_sent.cuda()\n",
    "            \n",
    "        logit_spk, logit_sent = model.joint_forward(X)\n",
    "        loss_spk = criterion(logit_spk, y_spk)\n",
    "        loss_sent = criterion(logit_sent, y_sent)\n",
    "        \n",
    "        if batch_idx % 2 == 0:\n",
    "            loss = loss_spk\n",
    "            optimizer = optimizer_spk\n",
    "        else:\n",
    "            loss = loss_sent\n",
    "            optimizer = optimizer_sent\n",
    "        optimizer.zero_grad()           \n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        predicted = torch.argmax(logit_spk, dim=1)\n",
    "        corrects += predicted.eq(y_spk).cpu().sum().float()\n",
    "        total += y_spk.size(0)\n",
    "        if batch_idx in print_steps:\n",
    "            print(\"train loss: {:.4f}, acc: {:.5f} \" \\\n",
    "                  .format(loss_sum/total, corrects/total))\n",
    "            \n",
    "    return loss_sum, corrects/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb: 0.3\n",
      "------------------------------\n",
      "train loss: 0.0440, acc: 0.00326 \n",
      "train loss: 0.0473, acc: 0.00583 \n",
      "train loss: 0.0476, acc: 0.00700 \n",
      "train loss: 0.0469, acc: 0.00765 \n",
      "train loss: 0.0461, acc: 0.00897 \n",
      "train loss: 0.0456, acc: 0.00974 \n",
      "train loss: 0.0452, acc: 0.01061 \n",
      "train loss: 0.0449, acc: 0.01126 \n",
      "train loss: 0.0448, acc: 0.01085 \n",
      "epoch #0, train accuracy: 0.009777718223631382\n",
      "epoch #0, val accuracy: 0.002008928684517741\n",
      "epoch #0, sv eer: 0.30195555555555553\n",
      "------------------------------\n",
      "train loss: 0.0440, acc: 0.00000 \n",
      "train loss: 0.0429, acc: 0.00187 \n",
      "train loss: 0.0420, acc: 0.00391 \n",
      "train loss: 0.0418, acc: 0.00659 \n",
      "train loss: 0.0414, acc: 0.00972 \n",
      "train loss: 0.0410, acc: 0.01226 \n",
      "train loss: 0.0408, acc: 0.01534 \n",
      "train loss: 0.0406, acc: 0.01740 \n",
      "train loss: 0.0405, acc: 0.01652 \n",
      "epoch #1, train accuracy: 0.01487816870212555\n",
      "epoch #1, val accuracy: 0.0066964286379516125\n",
      "epoch #1, sv eer: 0.2922777777777778\n",
      "------------------------------\n",
      "train loss: 0.0430, acc: 0.00022 \n",
      "train loss: 0.0424, acc: 0.00231 \n",
      "train loss: 0.0420, acc: 0.00442 \n",
      "train loss: 0.0415, acc: 0.00693 \n",
      "train loss: 0.0412, acc: 0.00861 \n",
      "train loss: 0.0411, acc: 0.01018 \n",
      "train loss: 0.0409, acc: 0.01188 \n",
      "train loss: 0.0408, acc: 0.01354 \n",
      "train loss: 0.0404, acc: 0.01256 \n",
      "epoch #2, train accuracy: 0.01131453551352024\n",
      "epoch #2, val accuracy: 0.00747767835855484\n",
      "epoch #2, sv eer: 0.27947777777777777\n",
      "------------------------------\n",
      "train loss: 0.0419, acc: 0.00065 \n",
      "train loss: 0.0411, acc: 0.00627 \n",
      "train loss: 0.0406, acc: 0.01069 \n",
      "train loss: 0.0404, acc: 0.01435 \n",
      "train loss: 0.0401, acc: 0.01727 \n",
      "train loss: 0.0400, acc: 0.01948 \n",
      "train loss: 0.0398, acc: 0.02150 \n",
      "train loss: 0.0396, acc: 0.02316 \n",
      "train loss: 0.0394, acc: 0.02156 \n",
      "epoch #3, train accuracy: 0.01942180097103119\n",
      "epoch #3, val accuracy: 0.0075892857275903225\n",
      "epoch #3, sv eer: 0.2689888888888889\n",
      "------------------------------\n",
      "train loss: 0.0407, acc: 0.00564 \n",
      "train loss: 0.0400, acc: 0.01684 \n",
      "train loss: 0.0395, acc: 0.02270 \n",
      "train loss: 0.0392, acc: 0.02781 \n",
      "train loss: 0.0389, acc: 0.03169 \n",
      "train loss: 0.0387, acc: 0.03462 \n",
      "train loss: 0.0385, acc: 0.03754 \n",
      "train loss: 0.0384, acc: 0.03962 \n",
      "train loss: 0.0381, acc: 0.03691 \n",
      "epoch #4, train accuracy: 0.033253151923418045\n",
      "epoch #4, val accuracy: 0.010275057516992092\n",
      "epoch #4, sv eer: 0.2677555555555556\n",
      "------------------------------\n",
      "train loss: 0.0407, acc: 0.00608 \n",
      "train loss: 0.0397, acc: 0.01761 \n",
      "train loss: 0.0389, acc: 0.02432 \n",
      "train loss: 0.0387, acc: 0.02892 \n",
      "train loss: 0.0384, acc: 0.03245 \n",
      "train loss: 0.0382, acc: 0.03432 \n",
      "train loss: 0.0380, acc: 0.03630 \n",
      "train loss: 0.0379, acc: 0.03803 \n",
      "train loss: 0.0376, acc: 0.03548 \n",
      "epoch #5, train accuracy: 0.03198360651731491\n",
      "epoch #5, val accuracy: 0.0062500000931322575\n",
      "epoch #5, sv eer: 0.24834444444444445\n",
      "------------------------------\n",
      "train loss: 0.0391, acc: 0.01497 \n",
      "train loss: 0.0380, acc: 0.03598 \n",
      "train loss: 0.0373, acc: 0.04363 \n",
      "train loss: 0.0371, acc: 0.04843 \n",
      "train loss: 0.0368, acc: 0.05220 \n",
      "train loss: 0.0366, acc: 0.05487 \n",
      "train loss: 0.0364, acc: 0.05831 \n",
      "train loss: 0.0362, acc: 0.06016 \n",
      "train loss: 0.0361, acc: 0.05597 \n",
      "epoch #6, train accuracy: 0.05046995356678963\n",
      "epoch #6, val accuracy: 0.011765553615987301\n",
      "epoch #6, sv eer: 0.2670111111111111\n",
      "------------------------------\n",
      "train loss: 0.0384, acc: 0.02604 \n",
      "train loss: 0.0373, acc: 0.04368 \n",
      "train loss: 0.0369, acc: 0.04960 \n",
      "train loss: 0.0367, acc: 0.05297 \n",
      "train loss: 0.0363, acc: 0.05584 \n",
      "train loss: 0.0361, acc: 0.05813 \n",
      "train loss: 0.0358, acc: 0.06136 \n",
      "train loss: 0.0356, acc: 0.06342 \n",
      "train loss: 0.0354, acc: 0.05906 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-703:\n",
      "Process Process-690:\n",
      "Process Process-689:\n",
      "Process Process-704:\n",
      "Process Process-693:\n",
      "Process Process-691:\n",
      "Process Process-699:\n",
      "Process Process-692:\n",
      "Process Process-700:\n",
      "Process Process-694:\n",
      "Process Process-697:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b63f67bc9ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#     validation code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch #{}, train accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/host/projects/sv_experiments/sv_system/train/si_train.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(config, val_loader, model, criterion)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"no_cuda\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader timed out after {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-698:\n",
      "Process Process-701:\n",
      "Process Process-702:\n",
      "Process Process-695:\n",
      "Process Process-696:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../sv_system/data/dataset.py\", line 124, in preprocess\n",
      "    input_feature = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../sv_system/data/dataset.py\", line 175, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.audio_files[index])), self.audio_labels[index]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"../sv_system/data/dataset.py\", line 124, in preprocess\n",
      "    input_feature = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "  File \"../sv_system/data/dataset.py\", line 124, in preprocess\n",
      "    input_feature = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "  File \"../sv_system/data/dataset.py\", line 111, in preprocess\n",
      "    data = np.pad(data, (0, max(0, in_len - len(data))), \"constant\")\n",
      "  File \"../sv_system/data/dataset.py\", line 124, in preprocess\n",
      "    input_feature = preprocess_audio(data, self.n_mels, self.filters, self.input_format)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../sv_system/data/manage_audio.py\", line 22, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../sv_system/data/dataset.py\", line 99, in preprocess\n",
      "    data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"../sv_system/data/manage_audio.py\", line 22, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"../sv_system/data/manage_audio.py\", line 22, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"../sv_system/data/manage_audio.py\", line 22, in preprocess_audio\n",
      "    data = librosa.feature.melspectrogram(data, sr=16000, n_mels=n_mels, hop_length=160, n_fft=480, fmin=20, fmax=4000)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1494, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/core/audio.py\", line 112, in load\n",
      "    with audioread.audio_open(os.path.realpath(path)) as input_file:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1494, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1494, in melspectrogram\n",
      "    mel_basis = filters.mel(sr, n_fft, **kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/feature/spectral.py\", line 1491, in melspectrogram\n",
      "    power=power)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1080, in _validate_lengths\n",
      "    normshp = _normalize_shape(narray, number_elements)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/filters.py\", line 270, in mel\n",
      "    lower = -ramps[i] / fdiff[i]\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/posixpath.py\", line 389, in realpath\n",
      "    return abspath(path)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/filters.py\", line 271, in mel\n",
      "    upper = ramps[i+2] / fdiff[i+1]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/filters.py\", line 270, in mel\n",
      "    lower = -ramps[i] / fdiff[i]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 1531, in _spectrogram\n",
      "    S = np.abs(stft(y, n_fft=n_fft, hop_length=hop_length))**power\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/arraypad.py\", line 1043, in _normalize_shape\n",
      "    shape_arr = np.round(shape_arr).astype(int)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/posixpath.py\", line 378, in abspath\n",
      "    return normpath(path)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/librosa/core/spectrum.py\", line 164, in stft\n",
      "    y = np.pad(y, int(n_fft // 2), mode=pad_mode)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 2851, in round_\n",
      "    return around(a, decimals=decimals, out=out)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/posixpath.py\", line 355, in normpath\n",
      "    if comp in (empty, dot):\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 2837, in around\n",
      "    return _wrapfunc(a, 'round', decimals=decimals, out=out)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 50, in _wrapfunc\n",
      "    def _wrapfunc(obj, method, *args, **kwds):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "### import torch\n",
    "from sv_system.train.si_train import val, sv_test\n",
    "\n",
    "print(\"lamb: {}\".format(config['lamb']))\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    \n",
    "#     train code\n",
    "    train_loss, train_acc = batch_switch_train(config, joint_loader, model, spk_optimizer,\n",
    "                                                   sent_optimizer, criterion)\n",
    "#     validation code\n",
    "    val_loss, val_acc = val(config, val_loader, model, criterion)\n",
    "    \n",
    "    print(\"epoch #{}, train accuracy: {}\".format(epoch_idx, train_acc))\n",
    "    print(\"epoch #{}, val accuracy: {}\".format(epoch_idx, val_acc))\n",
    "\n",
    "#     evaluate best_metric\n",
    "    if not config['no_eer']:\n",
    "        # eer validation code\n",
    "        eer, label, score = sv_test(config, sv_loader, model, trial)\n",
    "        print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))\n",
    "    \n",
    "    scheduler.step(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), open(\"gcommand_ResNet34_v1_mtl_lamb0.3.pt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV_Test\n",
    "\n",
    "equal_sent and diff_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.sv_score.score_utils import embeds_utterance\n",
    "\n",
    "def sv_test(config, sv_loader, model, trial):\n",
    "    embeddings, _ = embeds_utterance(config, sv_loader, model, lda=None)\n",
    "    sim_matrix = F.cosine_similarity(\n",
    "            embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "    cord = [trial.enrolment_id.tolist(), trial.test_id.tolist()]\n",
    "    score_vector = sim_matrix[cord].numpy()\n",
    "    label_vector = np.array(trial.label)\n",
    "    fpr, tpr, thres = roc_curve(\n",
    "            label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "    return eer, label_vector, score_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_sent_trial = trial[trial.equal_command]\n",
    "diff_sent_trial = trial[~trial.equal_command]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "equal_sent_eer, _, _ = sv_test(config, sv_loader, model, equal_sent_trial)\n",
    "diff_sent_eer, _, _ = sv_test(config, sv_loader, model, diff_sent_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcommand_ResNet34_v1_mtl_lamb0.1.pt\n",
    "print(f\"equal: {equal_sent_eer}\\ndiff: {diff_sent_eer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['lamb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
