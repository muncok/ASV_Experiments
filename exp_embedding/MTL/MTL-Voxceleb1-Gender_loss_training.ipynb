{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gender dependent training\n",
    "---------------------------\n",
    "\n",
    "Gender loss를 붙여서 각 gender 안에서 잘 구분할 수 있는 feature를 만들 수 있을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../sv_system/')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parser import set_train_config\n",
    "import easydict\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_mfcc30\", data_folder=\"/dataset/SV_sets/voxceleb12/feats/mfcc30/\",\n",
    "                              input_frames=800, splice_frames=[200, 800], stride_frames=1, input_format='mfcc',\n",
    "                              input_dim=30,\n",
    "                              cuda=True,\n",
    "                              lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=True,\n",
    "                              batch_size=256, num_workers=8,\n",
    "                              arch=\"tdnn_xvector\", loss=\"softmax\",\n",
    "                              n_epochs=50, n_labels=1211,\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_si_df = pd.read_pickle(\"/dataset/SV_sets/voxceleb12/dataframes/voxc1_si_train_dataframe.pkl\")\n",
    "voxc1_sv_df = pd.read_pickle(\"/dataset/SV_sets/voxceleb12/dataframes/voxc12_sv_test_dataframe.pkl\")\n",
    "\n",
    "si_spks = voxc1_si_df.spk.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "from collections  import OrderedDict\n",
    "\n",
    "class MTLfeatDataset(data.Dataset):\n",
    "    def __init__(self, data, set_type, config):\n",
    "        super().__init__()\n",
    "        self.set_type = set_type\n",
    "        # data\n",
    "        self.files = list(data.keys())\n",
    "        self.labels = list(data.values())\n",
    "        self.data_folder = config[\"data_folder\"]\n",
    "        # input audio config\n",
    "        self.input_frames = config[\"input_frames\"]\n",
    "        self.input_clip = config[\"input_clip\"]\n",
    "        self.input_dim = config[\"input_dim\"]\n",
    "\n",
    "        if set_type == \"train\":\n",
    "            self.random_clip = False\n",
    "        else:\n",
    "            self.random_clip = False\n",
    "\n",
    "    def preprocess(self, example):\n",
    "        # file_data = self._file_cache.get(example)\n",
    "        data = np.load(example)\n",
    "        # self._file_cache[example] = data\n",
    "\n",
    "        # clipping\n",
    "        in_len = self.input_frames\n",
    "        if self.input_clip:\n",
    "            if len(data) > in_len:\n",
    "                if self.random_clip:\n",
    "                    start_sample = np.random.randint(0, len(data) - in_len)\n",
    "                else:\n",
    "                    start_sample = 0\n",
    "                data = data[start_sample:start_sample+in_len]\n",
    "            else:\n",
    "                gap = max(0, in_len - len(data))\n",
    "\n",
    "                # # zero-padding\n",
    "                # data = np.pad(data, (0, gap), \"constant\")\n",
    "\n",
    "                # repeat, it shows better result\n",
    "                repeat = int(np.floor(gap / len(data)))\n",
    "                residual = gap % len(data)\n",
    "                # print(f\"in_len: {in_len}, data: {len(data)}, repeat: {repeat}, residual: {residual}\")\n",
    "                data = np.concatenate([np.tile(data, (repeat+1, 1)), data[:residual]], axis=0)\n",
    "\n",
    "        #TODO why do they have diffrent input dimension?\n",
    "        data = data[:,:self.input_dim] # first dimension could be energy term\n",
    "        # expand a singleton dimension standing for a channel dimension\n",
    "        data = torch.from_numpy(data).unsqueeze(0).float()\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def read_df(cls, config, df, set_type):\n",
    "        files = df.feat.tolist()\n",
    "        if \"label\" in df.columns:\n",
    "            labels = df.label.tolist()\n",
    "        else:\n",
    "            labels = [-1] * len(df)\n",
    "\n",
    "        gender = df.gender.apply(lambda x: 1 if x=='m' else 0).values\n",
    "        samples = OrderedDict(zip(files, zip(labels, gender)))\n",
    "        dataset = cls(samples, set_type, config)\n",
    "        return dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.preprocess(os.path.join(self.data_folder, self.files[index])), self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loaded trial: voxc12_test_trial\n"
     ]
    }
   ],
   "source": [
    "from data.data_utils import find_dataset, find_trial\n",
    "\n",
    "trial = find_trial(config, basedir='../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import featDataset\n",
    "\n",
    "train_dataset = MTLfeatDataset.read_df(config, voxc1_si_df[voxc1_si_df.set == 'train'], \"train\")\n",
    "val_dataset = MTLfeatDataset.read_df(config, voxc1_si_df[voxc1_si_df.set == 'val'], \"val\")\n",
    "sv_dataset = featDataset.read_df(config, voxc1_sv_df, 'sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mtl_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    collate_fn for multi labels\n",
    "    \"\"\"\n",
    "    data, label = list(zip(*batch))\n",
    "    data = torch.cat(data)\n",
    "    y1, y2 = list(zip(*label))\n",
    "    \n",
    "    return data, torch.LongTensor(y1), torch.LongTensor(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "batch_size = config[\"batch_size\"]\n",
    "num_workers = config[\"num_workers\"]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=True,\n",
    "        pin_memory=False,\n",
    "        collate_fn=_mtl_collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=_mtl_collate_fn)\n",
    "\n",
    "sv_loader = torch.utils.data.DataLoader(sv_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=default_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from model.tdnnModel import st_pool_layer\n",
    "\n",
    "class tdnn_xvector(nn.Module):\n",
    "    \"\"\"xvector architecture\"\"\"\n",
    "    def __init__(self, config, n_spk_labels, n_gender_labels):\n",
    "        super(tdnn_xvector, self).__init__()\n",
    "        \n",
    "        inDim = config['input_dim']\n",
    "        self.extractor = nn.Sequential(\n",
    "            nn.Conv1d(inDim, 512, stride=1, dilation=1, kernel_size=5),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=3, kernel_size=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=4, kernel_size=3),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(512, 1500, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.BatchNorm1d(1500),\n",
    "            nn.ReLU(True),\n",
    "            st_pool_layer(),\n",
    "            nn.Linear(3000, 512),\n",
    "        )\n",
    "\n",
    "        self.spk_classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, n_spk_labels)\n",
    "        )\n",
    "        \n",
    "        self.gender_classifier = nn.Sequential(\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, n_gender_labels),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "                \n",
    "    def embed(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        # (batch, time, freq) -> (batch, freq, time)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.extractor(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        x_ = self.embed(x)\n",
    "        x1 = self.spk_classifier(x_)\n",
    "        x2 = self.gender_classifier(x_)\n",
    "\n",
    "        return x1, x2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tdnn_xvector(config,  len(si_spks), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config[\"no_cuda\"]:\n",
    "    model.cuda()\n",
    "else:\n",
    "    model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from train.train_utils import set_seed, find_optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion, optimizer = find_optimizer(config, model)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamb: 0.3\n",
      "------------------------------\n",
      "curr_lr: 0.00010000000000000003\n",
      "train loss: 0.0000, spk_loss: 0.0000, gender_loss: 0.0000, acc: 1.00000 \n",
      "train loss: 0.0000, spk_loss: 0.0000, gender_loss: 0.0000, acc: 1.00000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-679:\n",
      "Process Process-678:\n",
      "Process Process-680:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-673:\n",
      "Process Process-677:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-676:\n",
      "Process Process-675:\n",
      "Process Process-674:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"<ipython-input-5-aaf9c1e1a26d>\", line 68, in __getitem__\n",
      "    return self.preprocess(os.path.join(self.data_folder, self.files[index])), self.labels[index]\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"<ipython-input-5-aaf9c1e1a26d>\", line 24, in preprocess\n",
      "    data = np.load(example)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 421, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/format.py\", line 635, in read_array\n",
      "    shape, fortran_order, dtype = _read_array_header(fp, version)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/format.py\", line 497, in _read_array_header\n",
      "    header = _filter_header(header)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/format.py\", line 459, in _filter_header\n",
      "    for token in tokenize.generate_tokens(StringIO(string).readline):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/tokenize.py\", line 601, in _tokenize\n",
      "    start, end = pseudomatch.span(1)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-52-fe2429cd3edd>\", line 42, in <module>\n",
      "    loss_sum += loss.item()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2980, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1866, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1373, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1281, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1133, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1070, in format_exception_as_a_whole\n",
      "    head = self.prepare_header(etype, self.long_header)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1021, in prepare_header\n",
      "    colorsnormal = colors.Normal  # used a lot\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/utils/ipstruct.py\", line 125, in __getattr__\n",
      "    def __getattr__(self, key):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 30003) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/inspect.py\", line 1445, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 165, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 35363) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 30003) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1866\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1373\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1281\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             )\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1133\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mtb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb_offset\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtb_offset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m         \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mprepare_header\u001b[0;34m(self, etype, long_version)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0mcolorsnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m  \u001b[0;31m# used a lot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorsnormal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_terminal_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/IPython/utils/ipstruct.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         \"\"\"Get an attr by calling :meth:`dict.__getitem__`.\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 30003) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from train.si_train import val\n",
    "from eval.sv_test import sv_test\n",
    "\n",
    "config['lamb'] = 0.3\n",
    "print(\"lamb: {}\".format(config['lamb']))\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "\n",
    "#==============================train code==============================\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    loss_spk_sum = 0\n",
    "    loss_gender_sum = 0\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    lamb = config['lamb']\n",
    "    print_steps = (np.arange(0, 1, 0.1) \\\n",
    "                    * len(train_loader)).astype(np.int64)\n",
    "\n",
    "    splice_frames = config['splice_frames']\n",
    "    if len(splice_frames) > 1:\n",
    "        splice_frames_ = np.random.randint(splice_frames[0], splice_frames[1])\n",
    "    else:\n",
    "        splice_frames_ = splice_frames[-1]\n",
    "\n",
    "    for batch_idx, (X, y_spk, y_gender) in enumerate(train_loader):\n",
    "        # X.shape is (batch, channel, time, bank)\n",
    "        X = X.narrow(1, 0, splice_frames_)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            X = X.cuda()\n",
    "            y_spk = y_spk.cuda()\n",
    "            y_gender = y_gender.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        logit_spk, logit_gender = model(X)\n",
    "        \n",
    "        loss_spk = criterion(logit_spk, y_spk) \n",
    "        loss_gender = criterion(logit_gender, y_gender)\n",
    "        loss = loss_spk * (1-lamb) + loss_gender  * (lamb)\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        loss_spk_sum += loss_spk.item()\n",
    "        loss_gender_sum += loss_gender.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        predicted = torch.argmax(logit_spk, dim=1)\n",
    "        corrects += predicted.eq(y_spk).cpu().sum().float()\n",
    "        total += y_spk.size(0)\n",
    "        \n",
    "        if batch_idx in print_steps:\n",
    "            print(\"train loss: {:.4f}, spk_loss: {:.4f}, gender_loss: {:.4f}, acc: {:.5f} \" \\\n",
    "                  .format(loss_sum/total, loss_spk_sum/total, loss_gender_sum/total, corrects/total)\n",
    "                 )\n",
    "    train_acc = corrects/total\n",
    "    train_loss = loss_sum/total\n",
    "    print(\"epoch #{}, train accuracy: {}\".format(epoch_idx, train_acc))\n",
    "    \n",
    "    scheduler.step(train_loss)\n",
    "#==============================validation code==============================\n",
    "    total = 0\n",
    "    corrects = 0\n",
    "    for batch_idx, (X, y_spk, y_gender) in enumerate(val_loader):\n",
    "        # X.shape is (batch, channel, time, bank)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            X = X.cuda()\n",
    "            y_spk = y_spk.cuda()\n",
    "            y_gender = y_gender.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        logit_spk, logit_gender = model(X)\n",
    "        predicted = torch.argmax(logit_spk, dim=1)\n",
    "        corrects += predicted.eq(y_spk).cpu().sum().float()\n",
    "        total += y_spk.size(0)\n",
    "        \n",
    "    val_acc = corrects/total\n",
    "\n",
    "    \n",
    "    print(\"epoch #{}, val accuracy: {}\".format(epoch_idx, val_acc))\n",
    "\n",
    "#==============================evaluate best_metric==============================\n",
    "    if not config['no_eer']:\n",
    "        # eer validation code\n",
    "        eer, label, score = sv_test(config, sv_loader, model, trial)\n",
    "        print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV_Test\n",
    "\n",
    "equal_sent and diff_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.sv_test import embeds_utterance\n",
    "\n",
    "si_dataset = featDataset.read_df(config, voxc1_si_df, \"train\")\n",
    "si_loader = torch.utils.data.DataLoader(si_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=False,\n",
    "        collate_fn=default_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_embeddings, _ = embeds_utterance(config, si_loader, model, lda=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_embeddings, _ = embeds_utterance(config, sv_loader, model, lda=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eer:50.000% at threshold 0.8963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5, 0.89626014)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "scores = cosine_similarity(sv_embeddings[trial.enrolment_id], \n",
    "                       sv_embeddings[trial.test_id], dim=1)\n",
    "compute_eer(scores[trial.label == 1], scores[trial.label == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_sent_trial = trial[trial.equal_command]\n",
    "diff_sent_trial = trial[~trial.equal_command]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "equal_sent_eer, _, _ = sv_test(config, sv_loader, model, equal_sent_trial)\n",
    "diff_sent_eer, _, _ = sv_test(config, sv_loader, model, diff_sent_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gcommand_ResNet34_v1_mtl_lamb0.1.pt\n",
    "print(f\"equal: {equal_sent_eer}\\ndiff: {diff_sent_eer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['lamb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
