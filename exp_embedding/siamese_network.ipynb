{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network\n",
    "------------------------------\n",
    "\n",
    "Constrastive loss: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "\n",
    "Siamese Network for one shot learning: https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_embeds = np.load(\"xvector_embeds/sv_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class EmbedDataset(data.Dataset):\n",
    "    def __init__(self, embeds, labels):\n",
    "        super().__init__()\n",
    "        self.embeds = embeds\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.embeds[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.embeds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def gen_pairs(data, enr_idx):\n",
    "    labels = data.label\n",
    "    label2idx= data.groupby('label').apply(lambda x: x.idx.tolist()).to_dict()\n",
    "    # 1: enrolled, 0: imposter\n",
    "    label2idx[1] += enr_idx\n",
    "    positive_pairs = np.array(list(itertools.combinations(label2idx[1], 2)))\n",
    "    negative_pairs = np.array(list(itertools.product(label2idx[0], label2idx[1])))\n",
    "    \n",
    "    return positive_pairs, negative_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_idx = np.load(\"enroll_idx.npy\").tolist()\n",
    "adapt_data = pd.read_csv(\"adapt_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "ood_data = pd.read_csv(\"ood_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs, negative_pairs = gen_pairs(adapt_data, enr_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, in_dims, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(in_dims, 1*in_dims),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        \n",
    "        hidden_layer = [nn.Linear(1*in_dims, 1*in_dims),\n",
    "            nn.BatchNorm1d(1*in_dims),\n",
    "            nn.PReLU()] * n_layers\n",
    "        \n",
    "        self.hidden_layer = nn.Sequential(*hidden_layer)\n",
    "    \n",
    "        self.embedding_layer = nn.Sequential(\n",
    "            nn.Linear(1*in_dims, 1),\n",
    "        )\n",
    "        \n",
    "    def embed(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def score(self, embed1, embed2):\n",
    "        dist = embed1.sub(embed2).abs()\n",
    "        dist = torch.clamp(dist, min=1e-16) # for numerical stability\n",
    "        weighted_dist = self.embedding_layer(dist)\n",
    "        \n",
    "        return weighted_dist.squeeze(1)\n",
    "        \n",
    "    def forward(self, x1, x2):           \n",
    "        embed1 = self.embed(x1)\n",
    "        embed2 = self.embed(x2)\n",
    "        p = torch.sigmoid(self.score(embed1, embed2))\n",
    "        \n",
    "        return p\n",
    "        \n",
    "    def batch_score(self, x1, x2):\n",
    "        embed1 = self.embed(x1)\n",
    "        embed2 = self.embed(x2)\n",
    "\n",
    "        dist = embed1.unsqueeze(1).sub(embed2.unsqueeze(0)).abs()\n",
    "        dist = dist.mean(dim=0)\n",
    "        dist = torch.clamp(dist, min=1e-16) # for numerical stability\n",
    "        weighted_dist = self.embedding_layer(dist)\n",
    "        p = torch.sigmoid(weighted_dist.squeeze(1))\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrastive_loss(n1, n2, label, margin):\n",
    "    dist_square = (n1 - n2).pow(2).sum(1)\n",
    "    dist_square = torch.clamp(dist_square, min=1e-16)\n",
    "    dist = dist_square.sqrt()\n",
    "\n",
    "    loss = torch.mean(\n",
    "        (1.0-label)*dist_square + (label)*torch.pow(torch.clamp(margin-dist, min=0.0), 2)\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseNet(512, 3)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] loss: 18.17130588076543, acc: 0.9891197643979057\n",
      "[epoch 1] loss: 0.7616312809986994, acc: 1.0\n",
      "[epoch 2] loss: 0.4748801965615712, acc: 1.0\n",
      "[epoch 3] loss: 0.38172781449975446, acc: 1.0\n",
      "[epoch 4] loss: 0.31972661372856237, acc: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-2b8589a27f8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "model.train()\n",
    "batch_size = 32\n",
    "n_epochs = 100\n",
    "min_n_pairs = min(len(positive_pairs), len(negative_pairs))\n",
    "for epoch_i in range(n_epochs):\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    np.random.shuffle(positive_pairs)\n",
    "    np.random.shuffle(negative_pairs)\n",
    "    for batch_i in range(min_n_pairs//batch_size):\n",
    "        p_pairs = random.choices(positive_pairs, k=batch_size//2)\n",
    "        n_pairs = random.choices(negative_pairs, k=batch_size//2)\n",
    "        x1_idx, x2_idx = np.concatenate([p_pairs, n_pairs], axis=0).T\n",
    "        x1 = torch.from_numpy(sv_embeds[x1_idx]).float()\n",
    "        x2 = torch.from_numpy(sv_embeds[x2_idx]).float()\n",
    "        y = torch.from_numpy(np.concatenate(\n",
    "            [np.ones(len(p_pairs)), np.zeros(len(n_pairs))], \n",
    "            axis=0)).float()\n",
    "        if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "            x1 = x1.cuda()\n",
    "            x2 = x2.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        score = model(x1, x2)\n",
    "        loss = criterion(score, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        pred = score > 0.5\n",
    "        n_corrects += pred.eq(y.byte()).sum().item()\n",
    "        total += y.size(0)\n",
    "    print(\"[epoch {}] loss: {}, acc: {}\".format(epoch_i, loss_sum, n_corrects/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enrollment uttrs를 고려해서 실험해야한다.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_embeds = sv_embeds[enr_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = sv_embeds[test_data.idx]\n",
    "test_label = np.array(test_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeds = sv_embeds[ood_data.idx]\n",
    "test_label = np.array(ood_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2150e488a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mn_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menr_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "n_corrects = 0\n",
    "x1 = torch.from_numpy(enr_embeds)\n",
    "x2 = torch.from_numpy(test_embeds)\n",
    "y = torch.from_numpy((test_label))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    x1 = x1.cuda()\n",
    "    x2 = x2.cuda()\n",
    "    y = y.cuda()\n",
    "\n",
    "# 현재 구현은 sigmoid 값을 score로 삼는데 실제로는 embedding 뽑아서 scosre를 계산해야 한다.\n",
    "score = model.batch_score(x1, x2)\n",
    "pred = score > 0.5\n",
    "n_corrects = pred.eq(y.byte()).sum().item()\n",
    "acc = n_corrects / len(y)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3728, 0.3401, 0.3068, 0.2819, 0.3569, 0.3860, 0.3967, 0.2959, 0.3875,\n",
       "        0.4198, 0.4520, 0.3975, 0.3651, 0.2991, 0.3065, 0.5325, 0.5283, 0.3490,\n",
       "        0.3703, 0.5249, 0.5270, 0.4470, 0.5232, 0.3937, 0.4858, 0.4193, 0.3550,\n",
       "        0.3313, 0.4034, 0.3678, 0.3551, 0.4013, 0.4269, 0.3869, 0.2983, 0.4207,\n",
       "        0.4489, 0.3804, 0.3793, 0.3216, 0.3897, 0.3475, 0.5300, 0.3641, 0.3853,\n",
       "        0.3620, 0.2916, 0.3063, 0.4578, 0.4046, 0.3386, 0.3514, 0.2563, 0.3537,\n",
       "        0.3338, 0.3369, 0.3602, 0.5782, 0.3968, 0.4460, 0.3332, 0.3262, 0.3202,\n",
       "        0.3816, 0.5368, 0.3954, 0.3534, 0.3281, 0.3347, 0.5427, 0.3015, 0.3931,\n",
       "        0.3744, 0.2921, 0.3277, 0.5374, 0.4065, 0.3495, 0.3786, 0.5245, 0.4406,\n",
       "        0.5372, 0.5214, 0.3841, 0.5277, 0.5282, 0.3963, 0.4472, 0.2991, 0.4222,\n",
       "        0.5574, 0.5415, 0.3005, 0.4028, 0.3845, 0.4371, 0.3874, 0.5367, 0.5259,\n",
       "        0.5311, 0.3478, 0.3845, 0.3594, 0.4211, 0.3881, 0.3907, 0.3717, 0.3910,\n",
       "        0.3703, 0.4068, 0.5335, 0.5789, 0.4388, 0.3881, 0.4737, 0.3306, 0.3657,\n",
       "        0.3581, 0.3128, 0.3621, 0.5234, 0.3693, 0.5425, 0.4512, 0.2886, 0.3094,\n",
       "        0.3541, 0.4238, 0.3221, 0.2888, 0.3496, 0.4200, 0.4254, 0.4891, 0.4588,\n",
       "        0.5580, 0.4110, 0.3260, 0.4241, 0.3684, 0.3620, 0.4384, 0.3478, 0.3652,\n",
       "        0.4084, 0.2886, 0.3922, 0.3911, 0.3005, 0.3975, 0.3238, 0.3427, 0.3375,\n",
       "        0.3523, 0.4052, 0.3146, 0.5260, 0.3103, 0.4096, 0.4517, 0.4353, 0.4252,\n",
       "        0.4137, 0.3786, 0.3123, 0.4371, 0.4404, 0.3958, 0.3873, 0.5318, 0.3943,\n",
       "        0.3917, 0.2740, 0.3741, 0.3565, 0.3525, 0.4017, 0.3218, 0.5220, 0.3452,\n",
       "        0.5130, 0.3902, 0.3571, 0.3176, 0.3265, 0.3341, 0.4410, 0.3812, 0.4386,\n",
       "        0.4117, 0.4177, 0.3777, 0.3202, 0.3491, 0.3406, 0.3822, 0.3600, 0.3097,\n",
       "        0.4043, 0.2886, 0.3948, 0.3555, 0.5272, 0.3690, 0.4003, 0.3369, 0.3658,\n",
       "        0.4218, 0.3792, 0.4292, 0.4192, 0.2940, 0.3073, 0.5597, 0.4068, 0.3225,\n",
       "        0.4543, 0.3377, 0.4012, 0.5336, 0.3930, 0.3528, 0.3969, 0.3923, 0.3221,\n",
       "        0.4032, 0.4217, 0.5368, 0.3650, 0.3893, 0.3122, 0.3987, 0.4257, 0.3747,\n",
       "        0.3957, 0.5452, 0.5390, 0.5293, 0.3240, 0.3020, 0.2947, 0.3989, 0.4175,\n",
       "        0.4088, 0.4106, 0.3487, 0.3073, 0.2884, 0.3234, 0.3793, 0.5307, 0.3124,\n",
       "        0.3555, 0.4383, 0.3341, 0.3608],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
