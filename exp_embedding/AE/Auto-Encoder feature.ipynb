{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Encoder\n",
    "---------------------------------\n",
    "\n",
    "경미의 [논문](https://drive.google.com/file/d/1RArk7z4NqY5HkwkUWx4cR2ApZNnAQxdF/view?usp=sharing)에 따르면 AE가 좀더 generalize한 feature를 뽑아준다고한다. 물론 image에 대해서 실험했고 (28x28, 32x32 의 작은...) task 간의 generalization에 대해 언급해서 조금 context가 다르다.\n",
    "\n",
    "그래서 일단 xvector의 feature를 가지고 간단한게 AE를 구현해보려고한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 xvector가 PLDA만 적용해서 성능이 월등히 높다.  \n",
    "다른 evaluation metric을 생각해야하지 않을까?\n",
    "\n",
    "> 지금 dataset간의 mismatch가 문제인데 해결해 볼 수 있지 않을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continual하게 speaker를 늘리는 것도 가능?  \n",
    "**이를 위해서는 AE자체를 sv_set으로 학습시켰을 때 성능이 좋아지는 것을 확인해야한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(512, 400),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(400, 300),\n",
    "            nn.ReLU(True), nn.Linear(300, 256), nn.ReLU(True), nn.Linear(256, 128))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300, 400),\n",
    "            nn.ReLU(True), nn.Linear(400, 512), nn.Tanh())\n",
    "        \n",
    "        self.latent_dim = 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def embed(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class embedDataset(data.Dataset):\n",
    "    def __init__(self, embeds, labels):\n",
    "        super().__init__()\n",
    "        self.embeds = embeds\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.embeds[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.embeds.shape[0]\n",
    "\n",
    "def embedToDataset(embeds, key_df):\n",
    "    labels = key_df.label.tolist()\n",
    "    dataset = embedDataset(embeds, labels)\n",
    "    \n",
    "    return dataset, embeds.shape[1], len(key_df.label.unique())\n",
    "\n",
    "def key2df(keys):\n",
    "    key_df = pd.DataFrame(keys, columns=['key'])\n",
    "    key_df['spk'] = key_df.key.apply(lambda x: x.split(\"-\")[0])\n",
    "    key_df['label'] = key_df.groupby('spk').ngroup()\n",
    "    key_df['origin'] = key_df.spk.apply(lambda x: 'voxc2' if x.startswith('id') else 'voxc1')\n",
    "    \n",
    "    return key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.read_pickle(\"../dataset/dataframes/voxc1/voxc_trial.pkl\")\n",
    "\n",
    "# si_set\n",
    "si_keys = pickle.load(open(\"../embeddings/voxc12/xvectors/xvectors_tdnn6b/train_feat/key.pkl\", \"rb\"))\n",
    "si_embeds = np.load(\"../embeddings/voxc12/xvectors/xvectors_tdnn6b/train_feat/feat.npy\")\n",
    "si_key_df = key2df(si_keys)\n",
    "\n",
    "# sv_set\n",
    "sv_keys = pickle.load(open(\"../embeddings/voxc12/xvectors/xvectors_tdnn6b/test_feat/key.pkl\", \"rb\"))\n",
    "sv_embeds = np.load(\"../embeddings/voxc12/xvectors/xvectors_tdnn6b/test_feat/feat.npy\")\n",
    "sv_key_df = key2df(sv_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_dataset, embed_dim, n_labels = embedToDataset(si_embeds, si_key_df)\n",
    "sv_dataset, _, _ = embedToDataset(sv_embeds, sv_key_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def embeds_utterance(val_dataloader, model):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    if torch.cuda.is_available():\n",
    "            model = model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            X, y = batch\n",
    "            if not no_cuda:\n",
    "                X = X.cuda()\n",
    "                model = model.cuda()\n",
    "                \n",
    "            model_output = model.embed(X).cpu().detach()\n",
    "            embeddings.append(model_output)\n",
    "            labels.append(y.numpy())\n",
    "        embeddings = torch.cat(embeddings)\n",
    "        labels = np.hstack(labels)\n",
    "    return embeddings, labels \n",
    "\n",
    "def sv_test(sv_loader, model, trial):\n",
    "    embeddings, _ = embeds_utterance(sv_loader, model)\n",
    "    trial_enroll = embeddings[trial.enrolment_id.tolist()]\n",
    "    trial_test = embeddings[trial.test_id.tolist()]\n",
    "\n",
    "    score_vector = F.cosine_similarity(trial_enroll, trial_test, dim=1)\n",
    "    label_vector = np.array(trial.label)\n",
    "    fpr, tpr, thres = roc_curve(\n",
    "            label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "    return eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "no_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = autoencoder().cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "si_loader = DataLoader(si_dataset, num_workers = 0, batch_size = batch_size, \n",
    "                           drop_last = True, pin_memory = True)\n",
    "\n",
    "sv_loader = DataLoader(sv_dataset, batch_size=128, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.8605\n",
      "sv loss: 0.8542, sv eer: 0.1851\n",
      "epoch [2/100], loss:0.6815\n",
      "sv loss: 0.6606, sv eer: 0.1815\n",
      "epoch [3/100], loss:0.6327\n",
      "sv loss: 0.5946, sv eer: 0.2147\n",
      "epoch [4/100], loss:0.6078\n",
      "sv loss: 0.5879, sv eer: 0.2803\n",
      "epoch [5/100], loss:0.6087\n",
      "sv loss: 0.5995, sv eer: 0.2362\n",
      "epoch [6/100], loss:0.6007\n",
      "sv loss: 0.5927, sv eer: 0.2738\n",
      "epoch [7/100], loss:0.6011\n",
      "sv loss: 0.5941, sv eer: 0.2712\n",
      "epoch [8/100], loss:0.6015\n",
      "sv loss: 0.5950, sv eer: 0.2755\n",
      "epoch [9/100], loss:0.6004\n",
      "sv loss: 0.5945, sv eer: 0.2664\n",
      "epoch [10/100], loss:0.5894\n",
      "sv loss: 0.5787, sv eer: 0.2706\n",
      "epoch [11/100], loss:0.5962\n",
      "sv loss: 0.5806, sv eer: 0.2635\n",
      "epoch [12/100], loss:0.5954\n",
      "sv loss: 0.5888, sv eer: 0.2482\n",
      "epoch [13/100], loss:0.6062\n",
      "sv loss: 0.5991, sv eer: 0.2227\n",
      "epoch [14/100], loss:0.6297\n",
      "sv loss: 0.6130, sv eer: 0.2334\n",
      "epoch [15/100], loss:0.6115\n",
      "sv loss: 0.6041, sv eer: 0.2362\n",
      "epoch [16/100], loss:0.6052\n",
      "sv loss: 0.5947, sv eer: 0.2452\n",
      "epoch [17/100], loss:0.6020\n",
      "sv loss: 0.5962, sv eer: 0.2265\n",
      "epoch [18/100], loss:0.6070\n",
      "sv loss: 0.6001, sv eer: 0.2242\n",
      "epoch [19/100], loss:0.6058\n",
      "sv loss: 0.5973, sv eer: 0.2186\n",
      "epoch [20/100], loss:0.6341\n",
      "sv loss: 0.6152, sv eer: 0.1980\n",
      "epoch [21/100], loss:0.6339\n",
      "sv loss: 0.6149, sv eer: 0.2131\n",
      "epoch [22/100], loss:0.6017\n",
      "sv loss: 0.5870, sv eer: 0.2021\n",
      "epoch [23/100], loss:0.6177\n",
      "sv loss: 0.5954, sv eer: 0.2097\n",
      "epoch [24/100], loss:0.6053\n",
      "sv loss: 0.5893, sv eer: 0.2021\n",
      "epoch [25/100], loss:0.6185\n",
      "sv loss: 0.5979, sv eer: 0.2128\n",
      "epoch [26/100], loss:0.5937\n",
      "sv loss: 0.5835, sv eer: 0.1910\n",
      "epoch [27/100], loss:0.5561\n",
      "sv loss: 0.5461, sv eer: 0.1938\n",
      "epoch [28/100], loss:0.5467\n",
      "sv loss: 0.5338, sv eer: 0.1991\n",
      "epoch [29/100], loss:0.5697\n",
      "sv loss: 0.5498, sv eer: 0.2199\n",
      "epoch [30/100], loss:0.5800\n",
      "sv loss: 0.5684, sv eer: 0.1846\n",
      "epoch [31/100], loss:0.5642\n",
      "sv loss: 0.5435, sv eer: 0.1924\n",
      "epoch [32/100], loss:0.5700\n",
      "sv loss: 0.5473, sv eer: 0.1874\n",
      "epoch [33/100], loss:0.5366\n",
      "sv loss: 0.5272, sv eer: 0.1899\n",
      "epoch [34/100], loss:0.5241\n",
      "sv loss: 0.5142, sv eer: 0.1795\n",
      "epoch [35/100], loss:0.5047\n",
      "sv loss: 0.4968, sv eer: 0.1849\n",
      "epoch [36/100], loss:0.5023\n",
      "sv loss: 0.4956, sv eer: 0.1785\n",
      "epoch [37/100], loss:0.5265\n",
      "sv loss: 0.5163, sv eer: 0.1861\n",
      "epoch [38/100], loss:0.5152\n",
      "sv loss: 0.5066, sv eer: 0.1786\n",
      "epoch [39/100], loss:0.5254\n",
      "sv loss: 0.5172, sv eer: 0.1760\n",
      "epoch [40/100], loss:0.5490\n",
      "sv loss: 0.5018, sv eer: 0.1782\n",
      "epoch [41/100], loss:0.5052\n",
      "sv loss: 0.4991, sv eer: 0.1807\n",
      "epoch [42/100], loss:0.5097\n",
      "sv loss: 0.4986, sv eer: 0.1771\n",
      "epoch [43/100], loss:0.5044\n",
      "sv loss: 0.4993, sv eer: 0.1613\n",
      "epoch [44/100], loss:0.4731\n",
      "sv loss: 0.4651, sv eer: 0.1709\n",
      "epoch [45/100], loss:0.5273\n",
      "sv loss: 0.4995, sv eer: 0.1739\n",
      "epoch [46/100], loss:0.4835\n",
      "sv loss: 0.4701, sv eer: 0.1647\n",
      "epoch [47/100], loss:0.4788\n",
      "sv loss: 0.4701, sv eer: 0.1626\n",
      "epoch [48/100], loss:0.4653\n",
      "sv loss: 0.4582, sv eer: 0.1657\n",
      "epoch [49/100], loss:0.4515\n",
      "sv loss: 0.4449, sv eer: 0.1668\n",
      "epoch [50/100], loss:0.4598\n",
      "sv loss: 0.4485, sv eer: 0.1605\n",
      "epoch [51/100], loss:0.4358\n",
      "sv loss: 0.4274, sv eer: 0.1640\n",
      "epoch [52/100], loss:0.4110\n",
      "sv loss: 0.4045, sv eer: 0.1586\n",
      "epoch [53/100], loss:0.3776\n",
      "sv loss: 0.3722, sv eer: 0.1578\n",
      "epoch [54/100], loss:0.4600\n",
      "sv loss: 0.4525, sv eer: 0.1551\n",
      "epoch [55/100], loss:0.3797\n",
      "sv loss: 0.3681, sv eer: 0.1594\n",
      "epoch [56/100], loss:0.3804\n",
      "sv loss: 0.3811, sv eer: 0.1597\n",
      "epoch [57/100], loss:0.3521\n",
      "sv loss: 0.3418, sv eer: 0.1499\n",
      "epoch [58/100], loss:0.3442\n",
      "sv loss: 0.3376, sv eer: 0.1562\n",
      "epoch [59/100], loss:0.3395\n",
      "sv loss: 0.3265, sv eer: 0.1577\n",
      "epoch [60/100], loss:0.3619\n",
      "sv loss: 0.3341, sv eer: 0.1563\n",
      "epoch [61/100], loss:0.3513\n",
      "sv loss: 0.3321, sv eer: 0.1727\n",
      "epoch [62/100], loss:0.3223\n",
      "sv loss: 0.3184, sv eer: 0.1573\n",
      "epoch [63/100], loss:0.3298\n",
      "sv loss: 0.3233, sv eer: 0.1519\n",
      "epoch [64/100], loss:0.3126\n",
      "sv loss: 0.3105, sv eer: 0.1457\n",
      "epoch [65/100], loss:0.3394\n",
      "sv loss: 0.3271, sv eer: 0.1501\n",
      "epoch [66/100], loss:0.3695\n",
      "sv loss: 0.3291, sv eer: 0.1421\n",
      "epoch [67/100], loss:0.3280\n",
      "sv loss: 0.3222, sv eer: 0.1547\n",
      "epoch [68/100], loss:0.3633\n",
      "sv loss: 0.3353, sv eer: 0.1476\n",
      "epoch [69/100], loss:0.4395\n",
      "sv loss: 0.4129, sv eer: 0.1450\n",
      "epoch [70/100], loss:0.3704\n",
      "sv loss: 0.3262, sv eer: 0.1611\n",
      "epoch [71/100], loss:0.3645\n",
      "sv loss: 0.3209, sv eer: 0.1454\n",
      "epoch [72/100], loss:0.3537\n",
      "sv loss: 0.3408, sv eer: 0.1370\n",
      "epoch [73/100], loss:0.3257\n",
      "sv loss: 0.3205, sv eer: 0.1456\n",
      "epoch [74/100], loss:0.3318\n",
      "sv loss: 0.3178, sv eer: 0.1362\n",
      "epoch [75/100], loss:0.3634\n",
      "sv loss: 0.3399, sv eer: 0.1444\n",
      "epoch [76/100], loss:0.3347\n",
      "sv loss: 0.3213, sv eer: 0.1364\n",
      "epoch [77/100], loss:0.3202\n",
      "sv loss: 0.3134, sv eer: 0.1331\n",
      "epoch [78/100], loss:0.3162\n",
      "sv loss: 0.3108, sv eer: 0.1399\n",
      "epoch [79/100], loss:0.3141\n",
      "sv loss: 0.3078, sv eer: 0.1358\n",
      "epoch [80/100], loss:0.3209\n",
      "sv loss: 0.3156, sv eer: 0.1366\n",
      "epoch [81/100], loss:0.3083\n",
      "sv loss: 0.3055, sv eer: 0.1318\n",
      "epoch [82/100], loss:0.3099\n",
      "sv loss: 0.3060, sv eer: 0.1335\n",
      "epoch [83/100], loss:0.3114\n",
      "sv loss: 0.3076, sv eer: 0.1375\n",
      "epoch [84/100], loss:0.3105\n",
      "sv loss: 0.3061, sv eer: 0.1345\n",
      "epoch [85/100], loss:0.3277\n",
      "sv loss: 0.3176, sv eer: 0.1352\n",
      "epoch [86/100], loss:0.3224\n",
      "sv loss: 0.3142, sv eer: 0.1328\n",
      "epoch [87/100], loss:0.3089\n",
      "sv loss: 0.3047, sv eer: 0.1329\n",
      "epoch [88/100], loss:0.3125\n",
      "sv loss: 0.3068, sv eer: 0.1324\n",
      "epoch [89/100], loss:0.3070\n",
      "sv loss: 0.3035, sv eer: 0.1285\n",
      "epoch [90/100], loss:0.3168\n",
      "sv loss: 0.3112, sv eer: 0.1337\n",
      "epoch [91/100], loss:0.3106\n",
      "sv loss: 0.3061, sv eer: 0.1396\n",
      "epoch [92/100], loss:0.3189\n",
      "sv loss: 0.3130, sv eer: 0.1347\n",
      "epoch [93/100], loss:0.3120\n",
      "sv loss: 0.3045, sv eer: 0.1303\n",
      "epoch [94/100], loss:0.3132\n",
      "sv loss: 0.3077, sv eer: 0.1238\n",
      "epoch [95/100], loss:0.2984\n",
      "sv loss: 0.2952, sv eer: 0.1243\n",
      "epoch [96/100], loss:0.3119\n",
      "sv loss: 0.3031, sv eer: 0.1317\n",
      "epoch [97/100], loss:0.3049\n",
      "sv loss: 0.3002, sv eer: 0.1316\n",
      "epoch [98/100], loss:0.3031\n",
      "sv loss: 0.2987, sv eer: 0.1322\n",
      "epoch [99/100], loss:0.2946\n",
      "sv loss: 0.2939, sv eer: 0.1354\n",
      "epoch [100/100], loss:0.3044\n",
      "sv loss: 0.2979, sv eer: 0.1266\n"
     ]
    }
   ],
   "source": [
    "if not no_cuda:\n",
    "    model = model.cuda()\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, _)  in enumerate(sv_loader):\n",
    "        if not no_cuda:\n",
    "            X = X.cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        total += X.size(0)\n",
    "#         if batch_idx % 1000 == 0:\n",
    "#             print(f\"train loss: {loss_sum/total}\")\n",
    " \n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))\n",
    "    \n",
    "    # =================sv_loss======================\n",
    "    for batch_idx, (X, _)  in enumerate(sv_loader):\n",
    "        if not no_cuda:\n",
    "                X = X.cuda()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, X)\n",
    "    eer = sv_test(sv_loader, model, trial)\n",
    "    print(\"sv loss: {:.4f}, sv eer: {:.4f}\".format(loss.item(), eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), open(\"saved_models/simple_ae_test.pt\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = autoencoder()\n",
    "# model.load_state_dict(torch.load(open(\"saved_models/simple_ae_test.pt\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
