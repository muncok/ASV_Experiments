{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDA (Deep Discriminant Analysis)\n",
    "\n",
    "기존의 DDA 학습은 classification base였다면 이번에는 Metric learning을 이용하여 DDA를 수행해보자.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various length\n",
    "-----\n",
    "\n",
    "input frames을 100f, 200f, 400f, 800f로 잘라놓고\n",
    "\n",
    "긴것을 앵커로 놓고 작은 것을 positive negative로 놓아 어떻게 되는지 보려고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../sv_system/')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.parser import set_train_config\n",
    "import easydict\n",
    "\n",
    "# datasets\n",
    "# voxc1_fbank_xvector\n",
    "# gcommand_fbank_xvector\n",
    "\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_fbank_xvector\",\n",
    "                              input_frames=100, splice_frames=[50, 100], stride_frames=1, input_format='fbank',\n",
    "                              cuda=True,\n",
    "                              lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False,\n",
    "                              batch_size=128,\n",
    "                              arch=\"tdnn_conv\", loss=\"softmax\",\n",
    "                              n_epochs=50\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class embedDataset(data.Dataset):\n",
    "    def __init__(self, embeds, labels):\n",
    "        super().__init__()\n",
    "        self.embeds = embeds\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.embeds[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.embeds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedToDataset(embeds, key_df):\n",
    "    labels = key_df.label.tolist()\n",
    "    dataset = embedDataset(embeds, labels)\n",
    "    \n",
    "    return dataset, embeds.shape[1], len(key_df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key2df(keys):\n",
    "    key_df = pd.DataFrame(keys, columns=['key'])\n",
    "    key_df['spk'] = key_df.key.apply(lambda x: x.split(\"-\")[0])\n",
    "    key_df['label'] = key_df.groupby('spk').ngroup()\n",
    "    key_df['origin'] = key_df.spk.apply(lambda x: 'voxc2' if x.startswith('id') else 'voxc1')\n",
    "    \n",
    "    return key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refeat_df(key_df, n_repeat, suffix):\n",
    "    repeat_key_df = key_df.loc[key_df.index.repeat(n_repeat)]\n",
    "    repeat_key_df = repeat_key_df.set_index('key')\n",
    "    repeat_key_df.index = repeat_key_df.index + '-' + suffix + '-' + \\\n",
    "                    repeat_key_df.groupby(level=0).cumcount().astype(str) \n",
    "    \n",
    "    return repeat_key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = pd.read_pickle(\"/dataset/SV_sets/voxceleb12/dataframes/voxc12_test_trial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_keys = pickle.load(open(\"./embeddings_for_dda/voxc1_mfcc30/100f_embeds/si_keys.pkl\", \"rb\"))\n",
    "sv_keys = pickle.load(open(\"./embeddings_for_dda/voxc1_mfcc30/100f_embeds/sv_keys.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_100f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/100f_embeds/si_embeds.npy\")\n",
    "sv_100f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/100f_embeds/sv_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_200f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/200f_embeds/si_embeds.npy\")\n",
    "sv_200f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/200f_embeds/sv_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_400f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/400f_embeds/si_embeds.npy\")\n",
    "sv_400f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/400f_embeds/sv_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_800f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/800f_embeds/si_embeds.npy\")\n",
    "sv_800f_embeds = np.load(\"./embeddings_for_dda/voxc1_mfcc30/800f_embeds/sv_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key_df = key2df(si_keys)\n",
    "sv_key_df = key2df(sv_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key_100f_df = refeat_df(si_key_df, 8, '100f')\n",
    "si_key_200f_df = refeat_df(si_key_df, 4, '200f')\n",
    "si_key_400f_df = refeat_df(si_key_df, 2, '400f')\n",
    "si_key_800f_df = refeat_df(si_key_df, 1, '800f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose a embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_key_df = si_key_800f_df\n",
    "si_embeds = si_800f_embeds\n",
    "sv_embeds = sv_800f_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA on embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=200, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "global_mean = si_embeds.mean(0)\n",
    "clf = LDA(solver='svd', n_components=200)\n",
    "clf.fit(si_embeds - global_mean, si_key_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_embeds = clf.transform(si_embeds - global_mean).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_embeds = clf.transform(sv_embeds - global_mean).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_dataset, embed_dim, n_labels = embedToDataset(si_embeds.reshape(-1,200), si_key_df)\n",
    "sv_dataset, _, _ = embedToDataset(sv_embeds, sv_key_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "def index_dataset(dataset):\n",
    "    return {c : [example_idx for example_idx, (_, class_label_ind) in \\\n",
    "                 enumerate(zip(dataset.embeds, dataset.labels)) if class_label_ind == c] for c in set(dataset.labels)}\n",
    "\n",
    "def sample_from_class(images_by_class, class_label_ind):\n",
    "    return images_by_class[class_label_ind][random.randrange(len(images_by_class[class_label_ind]))]\n",
    "\n",
    "def simple(batch_size, dataset, prob_other = 0.5):\n",
    "    '''lazy sampling, not like in lifted_struct. they add to the pool all postiive combinations, then compute the average number of positive pairs per image, then sample for every image the same number of negative pairs'''\n",
    "    images_by_class = index_dataset(dataset)\n",
    "    for batch_idx in range(int(math.ceil(len(dataset) * 1.0 / batch_size))):\n",
    "        example_indices = []\n",
    "        for i in range(0, batch_size, 2):\n",
    "            perm = random.sample(images_by_class.keys(), 2)\n",
    "            example_indices += [sample_from_class(images_by_class, perm[0]), sample_from_class(images_by_class, perm[0 if i == 0 or random.random() > prob_other else 1])]\n",
    "        yield example_indices[:batch_size]\n",
    "\n",
    "def triplet(batch_size, dataset, class2img=None):\n",
    "    if class2img is not None:\n",
    "        images_by_class = class2img\n",
    "    else:\n",
    "        images_by_class = index_dataset(dataset)\n",
    "        \n",
    "    for batch_idx in range(int(math.ceil(len(dataset) * 1.0 / batch_size))):\n",
    "        example_indices = []\n",
    "        for i in range(0, batch_size, 3):\n",
    "            perm = random.sample(images_by_class.keys(), 2)\n",
    "            example_indices += [sample_from_class(images_by_class, perm[0]), sample_from_class(images_by_class, perm[0]), sample_from_class(images_by_class, perm[1])]\n",
    "        yield example_indices[:batch_size]\n",
    "\n",
    "def npairs(batch_size, dataset, K = 4):\n",
    "    images_by_class = index_dataset(dataset)\n",
    "    for batch_idx in range(int(math.ceil(len(dataset) * 1.0 / batch_size))):\n",
    "        example_indices = [sample_from_class(images_by_class, class_label_ind) for k in range(int(math.ceil(batch_size * 1.0 / K))) for class_label_ind in [random.choice(images_by_class.keys())] for i in range(K)]\n",
    "        yield example_indices[:batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pairs_per_batch = 23\n",
    "batch_size = n_pairs_per_batch * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_sampler = lambda batch, dataset, sampler, **kwargs: \\\n",
    "type('', (torch.utils.data.sampler.Sampler,), \n",
    "     dict(__len__ = dataset.__len__, __iter__ = \\\n",
    "          lambda _: itertools.chain.from_iterable(sampler(batch, dataset, **kwargs))))(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use values to exclude unnecessary index\n",
    "si_key_df['num_id'] = range(len(si_key_df))\n",
    "class2idx = si_key_df.groupby('label').apply(lambda x: x.num_id.values).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "si_loader = torch.utils.data.DataLoader(\n",
    "    si_dataset, \n",
    "    sampler = adapt_sampler(batch_size, \n",
    "                           si_dataset, \n",
    "                           triplet, \n",
    "                           class2img=class2idx), \n",
    "    num_workers = 8, batch_size = batch_size, \n",
    "    drop_last = True, pin_memory = True\n",
    ")\n",
    "\n",
    "sv_loader = DataLoader(sv_dataset, batch_size=128, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class dda_model(nn.Module):\n",
    "    def __init__(self, in_dims, n_labels):\n",
    "        super().__init__()\n",
    "                \n",
    "        hid_dims = in_dims*2\n",
    "        out_dims = in_dims\n",
    "        \n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(in_dims, hid_dims),\n",
    "            nn.BatchNorm1d(hid_dims),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(hid_dims, hid_dims),\n",
    "            nn.BatchNorm1d(hid_dims),\n",
    "            nn.PReLU(),\n",
    "        )    \n",
    "    \n",
    "        self.embedding_layer = nn.Linear(hid_dims, out_dims)\n",
    "        \n",
    "    def embed(self, x):\n",
    "        x = self.hidden_layer(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):           \n",
    "        x = self.embed(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_mining(anchor, pos_egs, neg_egs, margin=1.0):\n",
    "    pos_dist = (anchor - pos_egs).pow(2).sum(1)\n",
    "    pos_dist = torch.clamp(pos_dist, min=1e-16)\n",
    "    pos_dist = pos_dist.sqrt()\n",
    "    \n",
    "    neg_dist = (anchor - neg_egs).pow(2).sum(1)\n",
    "    neg_dist = torch.clamp(neg_dist, min=1e-16)\n",
    "    neg_dist = neg_dist.sqrt()\n",
    "    \n",
    "    \n",
    "    hard_pos_dist = pos_dist.max()\n",
    "    hard_neg_dist = neg_dist.min()\n",
    "    \n",
    "#     print(f\"hard_pos:{hard_pos_dist}, hard_neg:{hard_neg_dist}\")\n",
    "    \n",
    "    triplet_loss = torch.clamp(hard_pos_dist - hard_neg_dist + margin, min=0)\n",
    "    triplet_loss = torch.sum(triplet_loss)\n",
    "    \n",
    "    return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dda_model(embed_dim, n_labels) \n",
    "\n",
    "if not config['no_cuda']:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002616\n",
      "Batch 2000/2154\t Loss 0.002812\n",
      "epoch #0, train loss: 0.002796055533546273\n",
      "epoch #0, sv eer: 0.10053022269353128\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002881\n",
      "Batch 2000/2154\t Loss 0.002982\n",
      "epoch #1, train loss: 0.0030098189624430745\n",
      "epoch #1, sv eer: 0.09379639448568398\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.003185\n",
      "Batch 2000/2154\t Loss 0.003285\n",
      "epoch #2, train loss: 0.003264187659026811\n",
      "epoch #2, sv eer: 0.0988865323435843\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.003650\n",
      "Batch 2000/2154\t Loss 0.003431\n",
      "epoch #3, train loss: 0.0033681340840181597\n",
      "epoch #3, sv eer: 0.09056203605514317\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.003021\n",
      "Batch 2000/2154\t Loss 0.003302\n",
      "epoch #4, train loss: 0.0032842543512307536\n",
      "epoch #4, sv eer: 0.09056203605514317\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.003059\n",
      "Batch 2000/2154\t Loss 0.003132\n",
      "epoch #5, train loss: 0.0030866371948355792\n",
      "epoch #5, sv eer: 0.09469777306468717\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002809\n",
      "Batch 2000/2154\t Loss 0.002779\n",
      "epoch #6, train loss: 0.002754530129762906\n",
      "epoch #6, sv eer: 0.09236479321314953\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002790\n",
      "Batch 2000/2154\t Loss 0.002902\n",
      "epoch #7, train loss: 0.0028779669584246196\n",
      "epoch #7, sv eer: 0.08780487804878048\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.003028\n",
      "Batch 2000/2154\t Loss 0.002934\n",
      "epoch #8, train loss: 0.002982967897634632\n",
      "epoch #8, sv eer: 0.08748674443266172\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002631\n",
      "Batch 2000/2154\t Loss 0.002622\n",
      "epoch #9, train loss: 0.0026367908390689644\n",
      "epoch #9, sv eer: 0.0852067868504772\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002875\n",
      "Batch 2000/2154\t Loss 0.002857\n",
      "epoch #10, train loss: 0.0028818785752591884\n",
      "epoch #10, sv eer: 0.08891834570519619\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002609\n",
      "Batch 2000/2154\t Loss 0.002686\n",
      "epoch #11, train loss: 0.002662541544363686\n",
      "epoch #11, sv eer: 0.08822905620360551\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002400\n",
      "Batch 2000/2154\t Loss 0.002589\n",
      "epoch #12, train loss: 0.002563257231929548\n",
      "epoch #12, sv eer: 0.08340402969247084\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002785\n",
      "Batch 2000/2154\t Loss 0.002616\n",
      "epoch #13, train loss: 0.002549637564298168\n",
      "epoch #13, sv eer: 0.08488865323435843\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002638\n",
      "Batch 2000/2154\t Loss 0.002514\n",
      "epoch #14, train loss: 0.002528234839133641\n",
      "epoch #14, sv eer: 0.09294803817603393\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002456\n",
      "Batch 2000/2154\t Loss 0.002520\n",
      "epoch #15, train loss: 0.0025082146900956893\n",
      "epoch #15, sv eer: 0.08748674443266172\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002805\n",
      "Batch 2000/2154\t Loss 0.002607\n",
      "epoch #16, train loss: 0.0025717722637725866\n",
      "epoch #16, sv eer: 0.08483563096500531\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002436\n",
      "Batch 2000/2154\t Loss 0.002533\n",
      "epoch #17, train loss: 0.0025340959487956394\n",
      "epoch #17, sv eer: 0.07910922587486745\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002204\n",
      "Batch 2000/2154\t Loss 0.002366\n",
      "epoch #18, train loss: 0.002348510894694562\n",
      "epoch #18, sv eer: 0.083881230116649\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002118\n",
      "Batch 2000/2154\t Loss 0.002178\n",
      "epoch #19, train loss: 0.002193106658469294\n",
      "epoch #19, sv eer: 0.08488865323435843\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002110\n",
      "Batch 2000/2154\t Loss 0.002247\n",
      "epoch #20, train loss: 0.002227889266967521\n",
      "epoch #20, sv eer: 0.08817603393425238\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002106\n",
      "Batch 2000/2154\t Loss 0.002265\n",
      "epoch #21, train loss: 0.002262032305665084\n",
      "epoch #21, sv eer: 0.09098621420996819\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002279\n",
      "Batch 2000/2154\t Loss 0.002401\n",
      "epoch #22, train loss: 0.0024085163618118204\n",
      "epoch #22, sv eer: 0.08515376458112407\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002269\n",
      "Batch 2000/2154\t Loss 0.002306\n",
      "epoch #23, train loss: 0.002326515140778692\n",
      "epoch #23, sv eer: 0.08223753976670202\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002102\n",
      "Batch 2000/2154\t Loss 0.002287\n",
      "epoch #24, train loss: 0.002341283308761271\n",
      "epoch #24, sv eer: 0.08849416755037115\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 1000/2154\t Loss 0.002556\n",
      "Batch 2000/2154\t Loss 0.002566\n",
      "epoch #25, train loss: 0.002531913306434348\n",
      "epoch #25, sv eer: 0.09183457051961824\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.002113\n",
      "Batch 2000/2154\t Loss 0.002059\n",
      "epoch #26, train loss: 0.002066379451762125\n",
      "epoch #26, sv eer: 0.09093319194061505\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.002131\n",
      "Batch 2000/2154\t Loss 0.002035\n",
      "epoch #27, train loss: 0.002020432366619548\n",
      "epoch #27, sv eer: 0.08669141039236479\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.001871\n",
      "Batch 2000/2154\t Loss 0.001854\n",
      "epoch #28, train loss: 0.001856427648936933\n",
      "epoch #28, sv eer: 0.08504772004241781\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.001723\n",
      "Batch 2000/2154\t Loss 0.001672\n",
      "epoch #29, train loss: 0.0016634501237459808\n",
      "epoch #29, sv eer: 0.08642629904559915\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.001884\n",
      "Batch 2000/2154\t Loss 0.001818\n",
      "epoch #30, train loss: 0.0018138443640185427\n",
      "epoch #30, sv eer: 0.08488865323435843\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 1000/2154\t Loss 0.001782\n",
      "Batch 2000/2154\t Loss 0.001704\n",
      "epoch #31, train loss: 0.0017188887348862842\n",
      "epoch #31, sv eer: 0.08451749734888653\n",
      "------------------------------\n",
      "curr_lr: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1961:\n",
      "Process Process-1960:\n",
      "Process Process-1958:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1957:\n",
      "Process Process-1959:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-1964:\n",
      "Process Process-1963:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-1962:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-a32b74450116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mn_sub_utter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0membeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#         embeds = embeds / embeds.norm(dim=1,keepdim=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-a4b5da5050b9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-a4b5da5050b9>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train.train_utils import set_seed, find_optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "config['lrs'] = [0.01]\n",
    "_, optimizer = find_optimizer(config, model)\n",
    "criterion = nn.TripletMarginLoss(margin=10, p=2)\n",
    "# criterion = hard_mining\n",
    "# criterion = nn.CosineEmbeddingLoss(margin=0.5)\n",
    "plateau_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "step_scheduler = MultiStepLR(optimizer, [30], 0.1)\n",
    "\n",
    "writer = SummaryWriter(\"logs/xvector_eucl_semi_hard_m0.4_lr0.01.tf.log\")\n",
    "\n",
    "best_eer = 1.0\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "    \n",
    "#=============== train code #===============\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(si_loader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        n_sub_utter = X.size(1)\n",
    "        embeds = model(X)\n",
    "#         embeds = embeds / embeds.norm(dim=1,keepdim=True)\n",
    "        anchor = embeds[0:batch_size:3]\n",
    "        pos_egs = embeds[1:batch_size:3]\n",
    "        neg_egs = embeds[2:batch_size:3]\n",
    "        loss = criterion(anchor, pos_egs, neg_egs)\n",
    "        \n",
    "#         loss_pos = criterion(anchor, pos_egs, torch.ones(len(anchor)).cuda())\n",
    "#         loss_neg = criterion(anchor, neg_egs, torch.zeros(len(anchor)).cuda())\n",
    "#         loss = loss_pos + loss_neg\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                        \n",
    "        loss_sum += loss.item()\n",
    "        total += y.size(0)\n",
    "        if (batch_idx+1) % 1000 == 0:\n",
    "            print(\"Batch {}/{}\\t Loss {:.6f}\" \\\n",
    "                  .format(batch_idx+1, len(si_loader), loss_sum / total))\n",
    "    train_loss = loss_sum / total\n",
    "    plateau_scheduler.step(train_loss)\n",
    "    \n",
    "    print(\"epoch #{}, train loss: {}\".format(epoch_idx, train_loss))\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch_idx+1)\n",
    "\n",
    "#=============== test code #===============\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in sv_loader:\n",
    "            X, _ = batch\n",
    "            if not config['no_cuda']:\n",
    "                X = X.cuda()\n",
    "                \n",
    "            model_output = model.embed(X).cpu().detach()\n",
    "            embeddings.append(model_output)\n",
    "        embeddings = torch.cat(embeddings)\n",
    "\n",
    "        score_vector = F.cosine_similarity(embeddings[trial.enrolment_id],\n",
    "                                      embeddings[trial.test_id], dim=1)\n",
    "    label_vector = np.array(trial.label)\n",
    "    fpr, tpr, thres = roc_curve(\n",
    "            label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    \n",
    "    if eer < best_eer:\n",
    "        best_eer = eer\n",
    "        print(\"best eer!\")\n",
    "        torch.save(model.state_dict(), open(\"best_model_metric.pt\", \"wb\"))\n",
    "        \n",
    "    print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))\n",
    "    writer.add_scalar(\"sv_test/eer\", eer, epoch_idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm((anchor - pos_egs), dim=1).sqrt() - torch.norm((anchor - neg_egs), dim=1).sqrt() + 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm((anchor_input - pos_input), dim=1) - torch.norm((anchor_input - neg_input), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_embeds = torch.from_numpy(sv_dataset.embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_vector = F.cosine_similarity(sv_embeds[trial.enrolment_id],\n",
    "                                  sv_embeds[trial.test_id], dim=1)\n",
    "label_vector = np.array(trial.label)\n",
    "fpr, tpr, thres = roc_curve(\n",
    "        label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 392,  392,  260, 1159, 1159,  937,  990,  990, 1082,  213,  213,  771,\n",
       "         650,  650,  381, 1075, 1075, 1141,  780,  780,  879,  568,  568,  355,\n",
       "         432,  432,  270,  132,  132, 1035,  199,  199,  650,  549,  549, 1156,\n",
       "         421,  421,  129,  621,  621,  964,  140,  140, 1153,  998,  998,  848,\n",
       "        1161, 1161, 1209,  769,  769,  495,   95,   95,  391,   77,   77,  753,\n",
       "          47,   47,  415, 1117, 1117,  752,  763,  763,  522],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
