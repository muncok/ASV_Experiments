{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_fbank_xvector\", \n",
    "                              data_folder=\"/dataset/SV_sets/voxceleb1/feats/mfcc30/\",\n",
    "                              input_frames=400, splice_frames=[200, 400], stride_frames=1, \n",
    "                              input_format='fbank', input_dim=30, random_clip=True,\n",
    "                              n_epochs=120, lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False, batch_size=128,\n",
    "                              gpu_no=[0], cuda=True, num_workers=8,\n",
    "                              arch=\"tdnn_conv\", loss=\"softmax\",\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_orig = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_si.csv\")\n",
    "dev_train_df = voxc1_orig[voxc1_orig.set == 'train']\n",
    "dev_val_df = voxc1_orig[voxc1_orig.set == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_df = dev_train_df.groupby('spk', group_keys=False).apply(lambda x: x.sample(n=100, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxceleb1\n",
    "# dev_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_dev.csv\")\n",
    "# dev_df = dev_df[dev_df.set != 'test']\n",
    "# dev_df['label'] = dev_df.groupby(\"spk\").ngroup()\n",
    "# spk_counts = dev_df.spk.value_counts()\n",
    "# dev_train_df = dev_df[dev_df.set == 'train']\n",
    "# dev_val_df = dev_df[dev_df.set == 'val']\n",
    "\n",
    "# eval_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_eval.csv\")\n",
    "# eval_df['label'] = eval_df.groupby('spk').ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxceleb2\n",
    "# dev_df = pd.read_csv(\"/dataset/SV_sets/voxceleb2/dataframes/voxc2_si.csv\")\n",
    "# dev_train_df = dev_df[dev_df.set == 'train']\n",
    "# dev_val_df = dev_df[dev_df.set == 'val']\n",
    "# eval_df = pd.read_csv(\"/dataset/SV_sets/voxceleb2/dataframes/voxc2_sv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.feat_dataset import FeatDataset\n",
    "\n",
    "dev_train_dataset = FeatDataset.read_df(config, dev_train_df, 'train')\n",
    "dev_val_dataset = FeatDataset.read_df(config, dev_val_df, 'test')\n",
    "# eval_dataset = FeatDataset.read_df(config, eval_df, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_default_loader \n",
    "dev_train_dataloader = init_default_loader(config, dev_train_dataset, shuffle=True, var_len=False) \n",
    "dev_val_dataloader = init_default_loader(config, dev_val_dataset, shuffle=False, var_len=False) \n",
    "# eval_dataloader = init_default_loader(config, eval_dataset, shuffle=False, var_len=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tdnn_models import tdnn_xvector_se\n",
    "from tdnn_models import tdnn_xvector\n",
    "\n",
    "model = tdnn_xvector(config, 512, n_labels=len(dev_train_df.label.unique()))\n",
    "# saved_model = torch.load(\"trained_models/voxc1_small_dev_time_reduction.pt\")\n",
    "# model.load_state_dict(saved_model)\n",
    "\n",
    "if not config['no_cuda']:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/562 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/562 [00:00<01:41,  5.55it/s]\u001b[A\n",
      "  0%|          | 2/562 [00:00<01:24,  6.61it/s]\u001b[A\n",
      "  1%|          | 3/562 [00:00<01:17,  7.22it/s]\u001b[A\n",
      "  1%|          | 4/562 [00:00<01:13,  7.62it/s]\u001b[A\n",
      "  1%|          | 5/562 [00:00<01:10,  7.86it/s]\u001b[A\n",
      "  1%|          | 6/562 [00:00<01:09,  8.03it/s]\u001b[A\n",
      "  1%|          | 7/562 [00:00<01:08,  8.14it/s]\u001b[A\n",
      "  1%|▏         | 8/562 [00:00<01:07,  8.23it/s]\u001b[A\n",
      "  2%|▏         | 9/562 [00:01<01:06,  8.29it/s]\u001b[A\n",
      "  2%|▏         | 10/562 [00:01<01:06,  8.33it/s]\u001b[A\n",
      "  2%|▏         | 11/562 [00:01<01:05,  8.38it/s]\u001b[A\n",
      "  2%|▏         | 12/562 [00:01<01:05,  8.43it/s]\u001b[A\n",
      "  2%|▏         | 13/562 [00:01<01:04,  8.47it/s]\u001b[A\n",
      "  2%|▏         | 14/562 [00:01<01:04,  8.50it/s]\u001b[A\n",
      "  3%|▎         | 15/562 [00:01<01:04,  8.52it/s]\u001b[A\n",
      "  3%|▎         | 16/562 [00:01<01:03,  8.55it/s]\u001b[A\n",
      "  3%|▎         | 17/562 [00:01<01:03,  8.56it/s]\u001b[A\n",
      "  3%|▎         | 18/562 [00:02<01:03,  8.58it/s]\u001b[A\n",
      "  3%|▎         | 19/562 [00:02<01:03,  8.59it/s]\u001b[A\n",
      "  4%|▎         | 20/562 [00:02<01:02,  8.61it/s]\u001b[A\n",
      "  4%|▎         | 21/562 [00:02<01:02,  8.62it/s]\u001b[A\n",
      "  4%|▍         | 22/562 [00:02<01:02,  8.64it/s]\u001b[A\n",
      "  4%|▍         | 23/562 [00:02<01:02,  8.64it/s]\u001b[A\n",
      "  4%|▍         | 24/562 [00:02<01:02,  8.65it/s]\u001b[A\n",
      "  4%|▍         | 25/562 [00:02<01:01,  8.66it/s]\u001b[A\n",
      "  5%|▍         | 26/562 [00:02<01:01,  8.67it/s]\u001b[A\n",
      "  5%|▍         | 27/562 [00:03<01:01,  8.67it/s]\u001b[A\n",
      "  5%|▍         | 28/562 [00:03<01:01,  8.69it/s]\u001b[A\n",
      "  5%|▌         | 29/562 [00:03<01:01,  8.69it/s]\u001b[A\n",
      "  5%|▌         | 30/562 [00:03<01:01,  8.70it/s]\u001b[A\n",
      "  6%|▌         | 31/562 [00:03<01:01,  8.70it/s]\u001b[A\n",
      "  6%|▌         | 32/562 [00:03<01:00,  8.71it/s]\u001b[A\n",
      "  6%|▌         | 33/562 [00:03<01:00,  8.71it/s]\u001b[A\n",
      "  6%|▌         | 34/562 [00:03<01:00,  8.72it/s]\u001b[A\n",
      "  6%|▌         | 35/562 [00:04<01:00,  8.72it/s]\u001b[A\n",
      "  6%|▋         | 36/562 [00:04<01:00,  8.73it/s]\u001b[A\n",
      "  7%|▋         | 37/562 [00:04<01:00,  8.73it/s]\u001b[A\n",
      "  7%|▋         | 38/562 [00:04<00:59,  8.73it/s]\u001b[A\n",
      "  7%|▋         | 39/562 [00:04<00:59,  8.74it/s]\u001b[A\n",
      "100%|██████████| 562/562 [01:02<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0, train loss: 0.0338, train acc: 0.1866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0, val loss: 0.0363, val acc: 0.1431\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #1, train loss: 0.0187, train acc: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #1, val loss: 0.0301, val acc: 0.2545\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #2, train loss: 0.0123, train acc: 0.6187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #2, val loss: 0.0254, val acc: 0.3460\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #3, train loss: 0.0086, train acc: 0.7222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #3, val loss: 0.0253, val acc: 0.3645\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #4, train loss: 0.0062, train acc: 0.7926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #4, val loss: 0.0232, val acc: 0.4191\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #5, train loss: 0.0047, train acc: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #5, val loss: 0.0222, val acc: 0.4424\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #6, train loss: 0.0036, train acc: 0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #6, val loss: 0.0214, val acc: 0.4559\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #7, train loss: 0.0029, train acc: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #7, val loss: 0.0209, val acc: 0.4770\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #8, train loss: 0.0023, train acc: 0.9171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #8, val loss: 0.0212, val acc: 0.4796\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #9, train loss: 0.0018, train acc: 0.9366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #9, val loss: 0.0201, val acc: 0.5072\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10, train loss: 0.0016, train acc: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #10, val loss: 0.0192, val acc: 0.5236\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #11, train loss: 0.0014, train acc: 0.9535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #11, val loss: 0.0197, val acc: 0.5119\n",
      "------------------------------\n",
      "curr_lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [01:02<00:00,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #12, train loss: 0.0012, train acc: 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Process Process-323:\n",
      "Process Process-322:\n",
      "Process Process-326:\n",
      "Process Process-327:\n",
      "Process Process-324:\n",
      "Process Process-325:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fb6099db8158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mn_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlogit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"../sv_system/data/feat_dataset.py\", line 80, in __getitem__\n",
      "    return (self.preprocess(os.path.join(self.data_folder, self.files[index])),\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"../sv_system/data/feat_dataset.py\", line 32, in preprocess\n",
      "    data = np.load(example)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/npyio.py\", line 433, in load\n",
      "    pickle_kwargs=pickle_kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/numpy/lib/format.py\", line 646, in read_array\n",
      "    count = numpy.multiply.reduce(shape, dtype=numpy.int64)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process Process-328:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-321:\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/conda/envs/pytorch-py3.6/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
    "from fine_tune_utils import class_weight\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weight(config, dev_train_df))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# plateau_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5)\n",
    "step_scheduler = MultiStepLR(optimizer, [30, 50, 70], 0.2)\n",
    "\n",
    "writer = SummaryWriter(\"logs/tdnn_xvector_voxc1_se_2\")\n",
    "model_path = \"trained_models/voxc1_tdnn_xvector_se_2.pt\"\n",
    "\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    step_scheduler.step()\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "    \n",
    "# =============== train code #===============\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in tqdm(enumerate(dev_train_dataloader), ascii=None, total=len(dev_train_dataloader)):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                        \n",
    "        loss_sum += loss.item()\n",
    "        n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "#         if (batch_idx+1) % 1000 == 0:\n",
    "#             print(\"Batch {}/{}\\t Loss {:.6f}\" \\\n",
    "#                   .format(batch_idx+1, len(si_loader), loss_sum / total))\n",
    "    train_loss = loss_sum / total\n",
    "    train_acc = n_corrects / total\n",
    "#     plateau_scheduler.step(train_loss)\n",
    "    \n",
    "    print(\"epoch #{}, train loss: {:.4f}, train acc: {:.4f}\".format(epoch_idx, train_loss, train_acc))\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch_idx+1)\n",
    "    writer.add_scalar(\"train/acc\", train_acc, epoch_idx+1)\n",
    "\n",
    "#=============== dev_val code #===============\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        loss_sum += loss.item()\n",
    "        n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "    val_loss = loss_sum / total\n",
    "    val_acc = n_corrects / total\n",
    "    \n",
    "    print(\"epoch #{}, val loss: {:.4f}, val acc: {:.4f}\".format(epoch_idx, val_loss, val_acc))\n",
    "    writer.add_scalar(\"val/loss\", val_loss, epoch_idx+1)\n",
    "    writer.add_scalar(\"val/acc\", val_acc, epoch_idx+1)\n",
    "    \n",
    "#=============== model save #===============\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## =============== dev_val code #===============\n",
    "model.eval()\n",
    "loss_sum = 0\n",
    "n_corrects = 0\n",
    "total = 0\n",
    "for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "    if not config['no_cuda']:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    logit = model(X)\n",
    "    loss = criterion(logit, y)\n",
    "    loss_sum += loss.item()\n",
    "    n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "    total += y.size(0)\n",
    "val_loss = loss_sum / total\n",
    "val_acc = n_corrects / total\n",
    "\n",
    "print(\"epoch #{}, val loss: {:.4f}, val acc: {:.4f}\".format(epoch_idx, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See, Attention map\n",
    "att_maps = []\n",
    "model.eval()\n",
    "total = 0\n",
    "for batch_idx, (X, y) in enumerate(dev_train_dataloader):\n",
    "    if not config['no_cuda']:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    att_map = model.att_map(X).cpu().detach().numpy()\n",
    "    att_maps.append(att_map)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See, Fr features\n",
    "fr_feats = []\n",
    "model.eval()\n",
    "total = 0\n",
    "for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "    if not config['no_cuda']:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    fr_feat = model.fr_feat(X).cpu().detach()\n",
    "    fr_feats.append(fr_feat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4115, 0.4619, 0.2880, 0.1456, 0.2449, 0.2377, 0.1846, 0.2711, 0.3090,\n",
       "        0.2152, 0.3659, 0.2667, 0.3660, 0.3011, 0.2163, 0.4169, 0.4812, 0.4101,\n",
       "        0.3309, 0.3308, 0.3580, 0.2597, 0.3758, 0.0898, 0.4742, 0.2708, 0.1194,\n",
       "        0.3323, 0.1286, 0.2033, 0.1993, 0.2460, 0.2657, 0.3245, 0.3804, 0.3026,\n",
       "        0.1827, 0.2627, 0.2961, 0.2626, 0.3103, 0.3536, 0.5638, 0.2204, 0.3099,\n",
       "        0.2129])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity as cosine\n",
    "cosine(fr_feats[0][0,:,0:1], fr_feats[0][0,:,1:], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1500, 47])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_feats[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  0.,  0.,  0.,  0.,  0.,  0., 18., 26.]),\n",
       " array([0.00847906, 0.00992662, 0.01137418, 0.01282174, 0.0142693 ,\n",
       "        0.01571687, 0.01716443, 0.01861199, 0.02005955, 0.02150711,\n",
       "        0.02295467], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADbRJREFUeJzt3X+sZPVdxvH3UxZoC61S9nazUOilBE1WE5d6Q9D2DypFKY1CrTGQ2GKsWaqSFO0/29ZEtCRSU1rTYDDbQEpNS0sthDVgLVkxiFZ0F1dYfv/aVtYteylJgTa2Ah//mLPkdr1379w7Z3Zmv75fyeSeOfM9c57MnfPcs+ecmU1VIUk6/L1q0gEkSf2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNWHMoV7Z27dqanZ09lKuUpMPejh07nqmqmeXGHdJCn52dZfv27YdylZJ02EvyzWHGechFkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIacUg/KSpJkzS7+daJrXv3le8e+zrcQ5ekRljoktQIC12SGrFsoSc5KckdSR5Icn+SD3XzL0+yJ8nO7nbe+ONKkpYyzEnRF4EPV9U9SV4H7Ehye/fYp6vqk+OLJ0ka1rKFXlV7gb3d9PNJHgROHHcwSdLKrOgYepJZ4HTg7m7WpUnuTXJdkuN6ziZJWoGhCz3JscBXgcuq6jngGuBUYCODPfirllhuU5LtSbbPz8/3EFmStJihCj3JkQzK/AtVdRNAVT1dVS9V1cvAZ4EzFlu2qrZU1VxVzc3MLPtf4kmSVmmYq1wCXAs8WFWfWjB//YJh7wF29R9PkjSsYa5yeRvwPuC+JDu7eR8FLkqyEShgN3DJWBJKkoYyzFUudwFZ5KHb+o8jSVotPykqSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1Ijli30JCcluSPJA0nuT/Khbv4bktye5NHu53HjjytJWsowe+gvAh+uqg3AmcDvJdkAbAa2VdVpwLbuviRpQpYt9KraW1X3dNPPAw8CJwLnA9d3w64HLhhXSEnS8lZ0DD3JLHA6cDewrqr2dg99G1jXazJJ0ooMXehJjgW+ClxWVc8tfKyqCqglltuUZHuS7fPz8yOFlSQtbahCT3IkgzL/QlXd1M1+Osn67vH1wL7Flq2qLVU1V1VzMzMzfWSWJC1imKtcAlwLPFhVn1rw0Fbg4m76YuCW/uNJkoa1ZogxbwPeB9yXZGc376PAlcCNST4AfBP49fFElCQNY9lCr6q7gCzx8Nn9xpEkrZafFJWkRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUiGG+y0WSejW7+dZJR2iSe+iS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWrEsoWe5Lok+5LsWjDv8iR7kuzsbueNN6YkaTnD7KF/Djh3kfmfrqqN3e22fmNJklZq2UKvqjuBZw9BFknSCEY5hn5pknu7QzLHLTUoyaYk25Nsn5+fH2F1kqSDWW2hXwOcCmwE9gJXLTWwqrZU1VxVzc3MzKxydZKk5ayq0Kvq6ap6qapeBj4LnNFvLEnSSq2q0JOsX3D3PcCupcZKkg6NNcsNSHIDcBawNslTwB8BZyXZCBSwG7hkjBklSUNYttCr6qJFZl87hiySpBH4SVFJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUiGULPcl1SfYl2bVg3huS3J7k0e7nceONKUlazjB76J8Dzj1g3mZgW1WdBmzr7kuSJmjZQq+qO4FnD5h9PnB9N309cEHPuSRJK7TaY+jrqmpvN/1tYF1PeSRJqzTySdGqKqCWejzJpiTbk2yfn58fdXWSpCWsttCfTrIeoPu5b6mBVbWlquaqam5mZmaVq5MkLWe1hb4VuLibvhi4pZ84kqTVGuayxRuAbwA/meSpJB8ArgTOSfIo8M7uviRpgtYsN6CqLlriobN7ziJJGoGfFJWkRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqREWuiQ1wkKXpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGmGhS1IjLHRJaoSFLkmNsNAlqRFrRlk4yW7geeAl4MWqmusjlCRp5UYq9M47quqZHp5HkjQCD7lIUiNGLfQCvp5kR5JNfQSSJK3OqIdc3l5Ve5K8Ebg9yUNVdefCAV3RbwI4+eSTR1ydJGkpI+2hV9We7uc+4GbgjEXGbKmquaqam5mZGWV1kqSDWHWhJzkmyev2TwO/COzqK5gkaWVGOeSyDrg5yf7n+WJVfa2XVJKkFVt1oVfVE8DP9JhFkjQCL1uUpEZY6JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqhIUuSY2w0CWpERa6JDXCQpekRljoktQIC12SGjHKfxJ9SM1uvnVi69595bsntm5JGpZ76JLUCAtdkhphoUtSIyx0SWqEhS5JjbDQJakRFrokNeKwuQ59kiZ1DbzXv0taCffQJakRFrokNcJCl6RGjFToSc5N8nCSx5Js7iuUJGnlVl3oSY4A/gJ4F7ABuCjJhr6CSZJWZpQ99DOAx6rqiar6IfAl4Px+YkmSVmqUQj8R+M8F95/q5kmSJmDs16En2QRs6u6+kOThA4asBZ4Zd44eHPKc+cSqFvP17Jc5+/X/Nucqt+f93jzMoFEKfQ9w0oL7b+rm/Yiq2gJsWepJkmyvqrkRchwS5uyXOftlzn4dLjkPNMohl38DTktySpKjgAuBrf3EkiSt1Kr30KvqxSSXAn8HHAFcV1X395ZMkrQiIx1Dr6rbgNtGzLDk4ZgpY85+mbNf5uzX4ZLzR6SqJp1BktQDP/ovSY3ovdCX+zqAJEcn+XL3+N1JZhc89pFu/sNJfmnB/N9Pcn+SXUluSPLqSeVMcnySO5K8kOTqA5b52ST3dct8JkmmLWeS1ya5NclD3Wt65agZx5HzgGW3Jtk1rTmTHJVkS5JHutf1vVOa86Lu/Xlvkq8lWTvBnOck2dHl2ZHkFxYsM03b0aI5x7UdjayqersxODn6OPAW4CjgP4ANB4z5XeAvu+kLgS930xu68UcDp3TPcwSDDys9CbymG3cj8JsTzHkM8Hbgg8DVByzzr8CZQIC/Bd41bTmB1wLv6KaPAv5xGnMuWO5XgS8Cuyb8/jzY7/2PgSu66VcBa6ctJ4PzZfv2ZwP+DLh8gjlPB07opn8a2DOl29GiOcexHfVx63sPfZivAzgfuL6b/mvg7O4v8PnAl6rqB1X1JPBY93wweDO+Jsma7oX8r0nlrKrvVdVdwH8vHJxkPfD6qvqXGvyWPw9cMG05q+r7VXVHN/1D4B4GnyGYqpwASY4F/gC4YsR8Y80J/BbwpwBV9XJVjfqBlHHkTHc7ptveXs9kt6N/r6r967+fwfZ99BRuR4vmHNN2NLK+C32YrwN4ZUxVvQh8Fzh+qWWrag/wSeBbwF7gu1X19QnmPNhzPrXMc05Dzlck+XHgl4FtU5rz48BVwPdHzPd/MnRGztm9hgAfT3JPkq8kWTdtOavqf4DfAe5jUOQbgGunJOd7gXuq6gdM93a0MOcretyORjb1J0WTHMfgr+cpwAkM9jB+Y7KpDn/dv3ZuAD5TVU9MOs+BkmwETq2qmyedZRlrGOyZ/XNVvRX4BoMdkKmS5EgGhX46g+3oXuAjEw0FJPkp4BPAJZPOcjBL5Zy27ajvQh/m6wBeGdO9GD8GfOcgy74TeLKq5ru9jJuAn59gzoM958J/ci36VQhTkHO/LcCjVfXnI2YcV86fA+aS7AbuAn4iyT9MYc7vMPgXxE3d/a8Ab53CnBsBqurx7lDGjUx4O0ryJuBm4P1V9fiC8VO1HS2Rc78+t6OR9V3ow3wdwFbg4m7614C/795gW4ELu+NopwCnMTg58i3gzO6scoCzgQcnmHNRVbUXeC7JmV3O9wO3TFtOgCRXMHjDXjZivrHlrKprquqEqpplcJLvkao6awpzFvA3wP5sZwMPTFtOBoW1IclMd/8cJrgddYcpbgU2V9U/7R88bdvRUjlhLNvR6Po+ywqcBzzC4Kzyx7p5fwL8Sjf9agZ7MY8xKOy3LFj2Y91yD7PgjDGDqwgeAnYBfwUcPeGcu4FngRcYHI/b0M2f6zI+DlxN98GtacrJYO+kGGzMO7vbb09bzgOee5YernIZ4+/9zcCdDA5jbANOntKcH+x+7/cy+CN0/KRyAn8IfG/Be3An8MZp246WysmYtqNRb35SVJIaMfUnRSVJw7HQJakRFrokNcJCl6RGWOiS1AgLXZIaYaFLUiMsdElqxP8CbsDarkdvCSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(att_maps[0][15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02295467, 0.02295467, 0.02223028, 0.02295467, 0.02295467,\n",
       "       0.02295467, 0.02113651, 0.02113651, 0.02295467, 0.02295467,\n",
       "       0.00886847, 0.01112725, 0.02295467, 0.02295467, 0.02113651,\n",
       "       0.02182527, 0.02295467, 0.02193193, 0.02295467, 0.02113651,\n",
       "       0.02113651, 0.02295467, 0.02113651, 0.02113651, 0.02113651,\n",
       "       0.02295467, 0.02295467, 0.02223028, 0.02113651, 0.02113651,\n",
       "       0.02113651, 0.02113651, 0.02182527, 0.02295467, 0.00847906,\n",
       "       0.02295467, 0.02295467, 0.02193193, 0.02295467, 0.02295467,\n",
       "       0.02295467, 0.02113651, 0.02113651, 0.02113651, 0.02113651,\n",
       "       0.02113651, 0.02113651], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_maps[0][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA on embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "global_mean = si_embeds.mean(0)\n",
    "clf = LDA(solver='svd', n_components=200)\n",
    "clf.fit(si_embeds - global_mean, si_key_df.label)\n",
    "\n",
    "si_embeds = clf.transform(si_embeds - global_mean).astype(np.float32)\n",
    "\n",
    "sv_embeds = clf.transform(sv_embeds - global_mean).astype(np.float32)\n",
    "\n",
    "si_dataset, embed_dim, n_labels = embedToDataset(si_embeds.reshape(-1,200), si_key_df)\n",
    "sv_dataset, _, _ = embedToDataset(sv_embeds, sv_key_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
