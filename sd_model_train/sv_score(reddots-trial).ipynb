{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/muncok/DL/projects/sv_experiments/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "from sv_system.data.dataloader import init_default_loader\n",
    "from sv_system.train.si_train import set_seed\n",
    "from sv_system.data.dataset import SpeechDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils import secToFrames, secToSample\n",
    "from sv_system.utils.parser import test_config\n",
    "si_config = test_config('tdnn')\n",
    "si_config['input_clip'] = True\n",
    "si_config['input_length'] = secToSample(4)\n",
    "si_config['input_frames'] = secToFrames(4)\n",
    "si_config['splice_frames'] = secToFrames(0.2)\n",
    "si_config['input_format'] = 'fbank'\n",
    "si_config['data_folder'] = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\"\n",
    "# si_config['data_folder'] = \"/home/muncok/DL/projects/sv_experiments/vad/reddots_vad_cut_1sec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def lda_on_tensor(tensor, lda):\n",
    "    return torch.from_numpy(lda.transform(tensor.numpy()).astype(np.float32))\n",
    "\n",
    "def embeds_utterance(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt['splice_frames']\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in tqdm_notebook(val_iter, total=len(val_iter)):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-(splice_dim), splice_dim)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if not opt['no_cuda']:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SI_Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from ../models/compare_train_methods/reddots/si_reddots_TdnnModel_3s_0.1s_fbank_full_frame.pt\n"
     ]
    }
   ],
   "source": [
    "from sv_system.model.TDNN import TdnnModel\n",
    "model = TdnnModel(si_config, 70, embed_mode=True)\n",
    "# model.load(\"../models/compare_train_methods/voxc/si_voxc_TdnnModel_3s_0.1s_fbank_full_frame.pt\")\n",
    "model.load(\"../models/compare_train_methods/reddots/si_reddots_TdnnModel_3s_0.1s_fbank_full_frame.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SimpleCNN:\n\tMissing key(s) in state_dict: \"convb_1.0.weight\", \"convb_1.0.bias\", \"convb_1.1.weight\", \"convb_1.1.bias\", \"convb_1.1.running_mean\", \"convb_1.1.running_var\", \"convb_2.0.weight\", \"convb_2.0.bias\", \"convb_2.1.weight\", \"convb_2.1.bias\", \"convb_2.1.running_mean\", \"convb_2.1.running_var\", \"convb_3.0.weight\", \"convb_3.0.bias\", \"convb_3.1.weight\", \"convb_3.1.bias\", \"convb_3.1.running_mean\", \"convb_3.1.running_var\", \"convb_4.0.weight\", \"convb_4.0.bias\", \"convb_4.1.weight\", \"convb_4.1.bias\", \"convb_4.1.running_mean\", \"convb_4.1.running_var\". \n\tUnexpected key(s) in state_dict: \"extractor.convb_1.0.weight\", \"extractor.convb_1.0.bias\", \"extractor.convb_1.1.weight\", \"extractor.convb_1.1.bias\", \"extractor.convb_1.1.running_mean\", \"extractor.convb_1.1.running_var\", \"extractor.convb_2.0.weight\", \"extractor.convb_2.0.bias\", \"extractor.convb_2.1.weight\", \"extractor.convb_2.1.bias\", \"extractor.convb_2.1.running_mean\", \"extractor.convb_2.1.running_var\", \"extractor.convb_3.0.weight\", \"extractor.convb_3.0.bias\", \"extractor.convb_3.1.weight\", \"extractor.convb_3.1.bias\", \"extractor.convb_3.1.running_mean\", \"extractor.convb_3.1.running_var\", \"extractor.convb_4.0.weight\", \"extractor.convb_4.0.bias\", \"extractor.convb_4.1.weight\", \"extractor.convb_4.1.bias\", \"extractor.convb_4.1.running_mean\", \"extractor.convb_4.1.running_var\", \"tdnn1.kernel\", \"tdnn1.bias\", \"tdnn1.context\", \"tdnn2.kernel\", \"tdnn2.bias\", \"tdnn2.context\", \"tdnn3.kernel\", \"tdnn3.bias\", \"tdnn3.context\", \"tdnn4.kernel\", \"tdnn4.bias\", \"tdnn4.context\". \n\tWhile copying the parameter named \"output.weight\", whose dimensions in the model are torch.Size([70, 320]) and whose dimensions in the checkpoint are torch.Size([70, 1024]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-08ddbf0a3db3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msv_system\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuxModels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msi_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/compare_train_methods/reddots/si_reddots_TdnnModel_3s_0.1s_fbank_full_frame.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DL/projects/sv_system/model/model.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded from {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SimpleCNN:\n\tMissing key(s) in state_dict: \"convb_1.0.weight\", \"convb_1.0.bias\", \"convb_1.1.weight\", \"convb_1.1.bias\", \"convb_1.1.running_mean\", \"convb_1.1.running_var\", \"convb_2.0.weight\", \"convb_2.0.bias\", \"convb_2.1.weight\", \"convb_2.1.bias\", \"convb_2.1.running_mean\", \"convb_2.1.running_var\", \"convb_3.0.weight\", \"convb_3.0.bias\", \"convb_3.1.weight\", \"convb_3.1.bias\", \"convb_3.1.running_mean\", \"convb_3.1.running_var\", \"convb_4.0.weight\", \"convb_4.0.bias\", \"convb_4.1.weight\", \"convb_4.1.bias\", \"convb_4.1.running_mean\", \"convb_4.1.running_var\". \n\tUnexpected key(s) in state_dict: \"extractor.convb_1.0.weight\", \"extractor.convb_1.0.bias\", \"extractor.convb_1.1.weight\", \"extractor.convb_1.1.bias\", \"extractor.convb_1.1.running_mean\", \"extractor.convb_1.1.running_var\", \"extractor.convb_2.0.weight\", \"extractor.convb_2.0.bias\", \"extractor.convb_2.1.weight\", \"extractor.convb_2.1.bias\", \"extractor.convb_2.1.running_mean\", \"extractor.convb_2.1.running_var\", \"extractor.convb_3.0.weight\", \"extractor.convb_3.0.bias\", \"extractor.convb_3.1.weight\", \"extractor.convb_3.1.bias\", \"extractor.convb_3.1.running_mean\", \"extractor.convb_3.1.running_var\", \"extractor.convb_4.0.weight\", \"extractor.convb_4.0.bias\", \"extractor.convb_4.1.weight\", \"extractor.convb_4.1.bias\", \"extractor.convb_4.1.running_mean\", \"extractor.convb_4.1.running_var\", \"tdnn1.kernel\", \"tdnn1.bias\", \"tdnn1.context\", \"tdnn2.kernel\", \"tdnn2.bias\", \"tdnn2.context\", \"tdnn3.kernel\", \"tdnn3.bias\", \"tdnn3.context\", \"tdnn4.kernel\", \"tdnn4.bias\", \"tdnn4.context\". \n\tWhile copying the parameter named \"output.weight\", whose dimensions in the model are torch.Size([70, 320]) and whose dimensions in the checkpoint are torch.Size([70, 1024])."
     ]
    }
   ],
   "source": [
    "from sv_system.model.AuxModels import SimpleCNN\n",
    "model = SimpleCNN(si_config, 70)\n",
    "model.load(\"../models/compare_train_methods/reddots/si_reddots_TdnnModel_3s_0.1s_fbank_full_frame.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AngularCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from ../models/compare_train_methods/reddots/si_reddots_Angular_4.0s_0.2s_fbank_.pt\n"
     ]
    }
   ],
   "source": [
    "from sv_system.model.AuxModels import AngleConv\n",
    "model = AngleConv(si_config, 70)\n",
    "model.load(\"../models/compare_train_methods/reddots/si_reddots_Angular_4.0s_0.2s_fbank_.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpeechModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from ../models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\n"
     ]
    }
   ],
   "source": [
    "from sv_system.model.SpeechModel import SpeechResModel, SpeechModel\n",
    "model = SpeechResModel(\"res15\", 1260)\n",
    "model.load(\"../models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reddots Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndx = pd.read_pickle(\"../dataset/dataframes/reddots/m_part1/m_part1_ndx.pkl\")\n",
    "# trn = pd.read_pickle(\"../dataset/dataframes/reddots/m_part1/m_part1_trn.pkl\")\n",
    "# cord = pickle.load(open(\"../dataset/dataframes/reddots/m_part1/ndx_idxs.pkl\", \"rb\"))\n",
    "\n",
    "ndx = pd.read_pickle(\"../dataset/dataframes/reddots//m_part4_tp/m_part4_tp_ndx.pkl\")\n",
    "trn = pd.read_pickle(\"../dataset/dataframes/reddots//m_part4_tp/m_part4_tp_trn.pkl\")\n",
    "cord = pickle.load(open(\"../dataset/dataframes/reddots/m_part4_tp//ndx_idxs.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cord = []\n",
    "# y_cord = []\n",
    "# ndx_file =pd.DataFrame(ndx.file.unique().tolist(), columns=['file'])\n",
    "# all_trials = trn.id.unique().tolist()\n",
    "# for trial_id in tqdm(all_trials):\n",
    "#     trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "#     trial_embed_idx = np.nonzero(ndx_file.file.isin(trial_ndx.file))[0].tolist()\n",
    "#     x_cord += [all_trials.index(trial_id)] * len(trial_embed_idx)\n",
    "#     y_cord += trial_embed_idx\n",
    "\n",
    "# cord = [x_cord, y_cord]\n",
    "# pickle.dump(cord, open(\"../dataset/dataframes/reddots/m_part1/ndx_idxs.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type = {0:'TC', 1:'TW', 2:'IC', 3:'IW'}\n",
    "si_config['batch_size'] = 64\n",
    "si_config['num_workers'] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enrollment (trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43290694a8a4dc69a8694a3a348f461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "si_config['data_folder'] = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\"\n",
    "trn_dataset = SpeechDataset.read_df(si_config, trn, \"test\")\n",
    "\n",
    "val_dataloader = init_default_loader(si_config, trn_dataset, shuffle=False)\n",
    "trn_embeddings, _ = embeds_utterance(si_config, val_dataloader, model, lda)\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)\n",
    "\n",
    "spk_models = torch.cat([emb for emb in spk_model_dict.values()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SV Scoring (ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_file = pd.DataFrame(ndx.file.unique().tolist(), columns=['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3b9ac8be764267af92eae1f7bdc982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=117), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ndx_dataset = SpeechDataset.read_df(si_config, ndx_file, \"test\")\n",
    "val_dataloader = init_default_loader(si_config, ndx_dataset, shuffle=False) \n",
    "ndx_embeddings, _ = embeds_utterance(si_config, val_dataloader, model, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC mean:0.90, std:0.104\n",
      "TW mean:0.89, std:0.106\n",
      "IC mean:0.08, std:0.249\n",
      "IW mean:0.08, std:0.248\n"
     ]
    }
   ],
   "source": [
    "sim_matrix = F.cosine_similarity(spk_models.unsqueeze(1), ndx_embeddings.unsqueeze(0), dim=2)\n",
    "sims = sim_matrix[cord]\n",
    "\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    trial_type_idx = ndx[ndx.trial_type == t].index\n",
    "    scores[t] = sims[trial_type_idx]\n",
    "\n",
    "for t in range(4):\n",
    "     print(\"{} mean:{:.2f}, std:{:.3f}\".format(err_type[t], scores[t].mean(), scores[t].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TW] eer: 0.50, thres: 0.93027\n",
      "[IC] eer: 0.03, thres: 0.60154\n",
      "[IW] eer: 0.02, thres: 0.59883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TI] eer: 0.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score_vector = np.concatenate((scores[0], scores[1],\n",
    "                              scores[2], scores[3]))\n",
    "label_vector = np.concatenate((np.ones(len(scores[0]) + len(scores[1])), \n",
    "                           np.zeros(len(scores[2]) + len(scores[3]))))\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.2f}\".format(eer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddots LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=118), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reddots_files = pd.read_pickle(\"../dataset/dataframes/reddots/Reddots_Dataframe.pkl\").file\n",
    "used_files = pd.concat([trn.file, ndx_file.file])\n",
    "unused_files = reddots_files[~reddots_files.isin(used_files)]\n",
    "\n",
    "lda_file = pd.DataFrame(unused_files, columns=['file'])\n",
    "lda_dataset = SpeechDataset.read_df(si_config, lda_file, \"test\")\n",
    "val_dataloader = init_default_loader(si_config, lda_dataset, shuffle=False) \n",
    "lda_embeddings, _ = embeds_utterance(si_config, val_dataloader, model, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100 # for test samples\n",
    "embeddings = lda_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spks =unused_files.apply(lambda x: x.split('_')[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spks = spks.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([all_spks.index(label) for label in spks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100 # for test samples\n",
    "embeddings = lda_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = embeddings.shape[0]\n",
    "clf = LDA()\n",
    "random_idx = np.random.permutation(np.arange(0,n_samples))\n",
    "train_X, train_y = embeddings[random_idx[:n_samples-n_test]], labels[random_idx[:n_samples-n_test]]\n",
    "test_X, test_y = embeddings[random_idx[-n_test:]], labels[random_idx[-n_test:]]\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(test_X, test_y)\n",
    "print(score) # test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"../models/compare_train_methods/reddots/si_reddots_TdnnModel_3s_0.1s_fbank_full_frame.lda\",\n",
    "                      \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxc LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../dataset/dataframes/Voxc_Dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voxc = df[df.set == 'train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_dataset = train_voxc.groupby(['spk']).apply(lambda x: x.sample(n=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unused_files = lda_dataset.file\n",
    "labels = lda_dataset.label\n",
    "si_config['data_folder'] = \"/home/muncok/DL/dataset/SV_sets/voxceleb/\"\n",
    "\n",
    "lda_file = pd.DataFrame(unused_files, columns=['file'])\n",
    "lda_dataset = SpeechDataset.read_df(si_config, lda_file, \"test\")\n",
    "val_dataloader = init_default_loader(si_config, lda_dataset, shuffle=False) \n",
    "lda_embeddings, _ = embeds_utterance(si_config, val_dataloader, model, lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100 # for test samples\n",
    "embeddings = lda_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
       "              solver='svd', store_covariance=False, tol=0.0001)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = embeddings.shape[0]\n",
    "clf = LDA()\n",
    "random_idx = np.random.permutation(np.arange(0,n_samples))\n",
    "train_X, train_y = embeddings[random_idx[:n_samples-n_test]], labels[random_idx[:n_samples-n_test]]\n",
    "test_X, test_y = embeddings[random_idx[-n_test:]], labels[random_idx[-n_test:]]\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(test_X, test_y)\n",
    "print(score) # test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-e904ccadb8d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"models/lda/{}_splice_lda.pkl\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'options' is not defined"
     ]
    }
   ],
   "source": [
    "lda_out = \"models/lda/{}_splice_lda.pkl\".format(options.input.split('/')[-1][:-3])\n",
    "pickle.dump(clf, open(lda_out, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
