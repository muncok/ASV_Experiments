{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_default_loader\n",
    "from sv_system.utils.parser import get_sv_parser\n",
    "from sv_system.train.si_train import set_seed\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_sv_parser().parse_args(args=[])\n",
    "options.n_dct_filters = 40\n",
    "options.n_mels = 40\n",
    "options.timeshift_ms = 100\n",
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets\"\n",
    "options.window_size= 0.025\n",
    "options.window_stride= 0.010\n",
    "options.cache_size = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils import secToFrames, secToSample\n",
    "options.input_format = \"fbank\"\n",
    "options.input_clip = True\n",
    "options.input_length = secToSample(3) # if input_clip is false, it doesn't affect anything\n",
    "options.input_frames = secToFrames(3)\n",
    "options.splice_frames = secToFrames(0.1)  # it is for extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\n"
     ]
    }
   ],
   "source": [
    "from sv_system.model.TDNN import TdnnModel\n",
    "from sv_system.model.SpeechModel import SpeechResModel\n",
    "import pickle\n",
    "# model = TdnnModel(vars(options), 70, embed_mode=True)\n",
    "# model.load(\"models/reddots/si_train/si_reddots_tdnnfc_3s_0.1s_mean.pt\")\n",
    "model = SpeechResModel(\"res15\", 1260)\n",
    "model.load(\"models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\")\n",
    "model.cuda()\n",
    "# lda = pickle.load(open(\"models/lda/si_reddots_0.2s_random_2_lda.pkl\", \"rb\"))\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reddots Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def lda_on_tensor(tensor, lda):\n",
    "    return torch.from_numpy(lda.transform(tensor.numpy()).astype(np.float32))\n",
    "\n",
    "def embeds_utterance(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt.input_frames\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, splice_dim//2)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if opt.cuda:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "#         print(len(model_outputs))\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeds_one(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    model\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        if opt.cuda:\n",
    "            x = x.cuda()\n",
    "        model_output = model(x)\n",
    "        embeddings.append(model_output.cpu().detach())\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx = pd.read_pickle(\"dataset/dataframes/Reddots/m_part1/m_part1_ndx.pkl\")\n",
    "trn = pd.read_pickle('dataset/dataframes/Reddots/m_part1/m_part1_trn.pkl')\n",
    "# m_part4_ndx = pd.read_pickle(\"dataset/dataframes/Reddots/m_part4_tp/m_part4_tp_ndx.pkl\")\n",
    "# m_part4_trn = pd.read_pickle(\"dataset/dataframes/Reddots/m_part4_tp/m_part4_tp_trn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type = {0:'TC', 1:'TW', 2:'IC', 3:'IW'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enrollment (trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataset import SpeechDataset\n",
    "dataset = SpeechDataset.read_df(vars(options), trn, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.batch_size = 64\n",
    "options.num_workers = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_default_loader(vars(options), dataset, shuffle=False)\n",
    "trn_embeddings, _ = embeds_utterance(options, val_dataloader, model, lda)\n",
    "\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1260])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk_model_dict['m0001_31'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SV Scoring (ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_file =pd.DataFrame(ndx.file.unique().tolist(), columns=['file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpeechDataset.read_df(vars(options), ndx_file, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_default_loader(vars(options), dataset, shuffle=False) \n",
    "ndx_embeddings, _ = embeds_utterance(options, val_dataloader, model, lda)\n",
    "# torch.save(ndx_embeddings, 'trials/reddots/m_part1/{}_embeds.pkl'.format(model_name))\n",
    "# ndx_embeddings = torch.load('trials/reddots/m_part1/{}_embeds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b8a93a57264787808e20a575663be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_trials = ndx.id.unique().tolist()\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    scores[t] = []    \n",
    "\n",
    "for trial_id in tqdm(all_trials):\n",
    "    trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "    trial_embed_idx = np.nonzero(ndx_file.file.isin(trial_ndx.file))\n",
    "    trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "    sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id])\n",
    "    for t in range(4):\n",
    "        trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "        scores[t].append(sim[trial_type_idx])\n",
    "        \n",
    "# [TC, TW, IC, IW]\n",
    "for t in range(4):\n",
    "    scores[t] = torch.cat(scores[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC mean:0.92, std:0.081\n",
      "TW mean:0.92, std:0.081\n",
      "IC mean:0.92, std:0.078\n",
      "IW mean:0.92, std:0.079\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "     print(\"{} mean:{:.2f}, std:{:.3f}\".format(err_type[t], scores[t].mean(), scores[t].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TW] eer: 0.41, thres: 0.88745\n",
      "[IC] eer: 0.11, thres: 0.79204\n",
      "[IW] eer: 0.10, thres: 0.78526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TI] eer: 0.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score_vector = np.concatenate((scores[0], scores[1],\n",
    "                              scores[2], scores[3]))\n",
    "label_vector = np.concatenate((np.ones(len(scores[0]) + len(scores[1])), \n",
    "                           np.zeros(len(scores[2]) + len(scores[3]))))\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.2f}\".format(eer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
