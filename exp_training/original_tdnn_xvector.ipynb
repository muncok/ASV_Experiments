{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original_tdnn_xvector\n",
    "----\n",
    "trello: https://trello.com/c/h9uUoFVc\n",
    "\n",
    "kaldi의 tdnn_xvector 구조를 똑같이 구현하려고한다.\n",
    "\n",
    "목표는 utterance-level xvector의 generative한 특성을 살릴 수 있을까 알고싶은 것이다.\n",
    "\n",
    "----\n",
    "\n",
    "30dim mfcc를 가져와야하나?\n",
    "\n",
    "**splice_frames를 800까지 높이면 터진다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "\n",
    "# datasets\n",
    "# voxc1_fbank_xvector\n",
    "# gcommand_fbank_xvector\n",
    "\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_wav\",\n",
    "                              input_frames=300, splice_frames=[300], stride_frames=1, input_format='fbank',\n",
    "                              cuda=True,\n",
    "                              lrs=[0.01, 0.001], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False,\n",
    "                              batch_size=128,\n",
    "                              arch=\"tdnn_original\", loss=\"softmax\",\n",
    "                              n_epochs=50\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.data_utils import find_dataset, find_trial\n",
    "\n",
    "_, datasets = find_dataset(config, basedir='../')\n",
    "trial = find_trial(config, basedir='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_loaders\n",
    "\n",
    "dataloaders = init_loaders(config, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['input_dim'] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sv_system.model.model_utils import find_model\n",
    "# model = find_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.model.tdnnModel import gTDNN, st_pool_layer\n",
    "from sv_system.model.ResNet34 import BasicBlock\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class tdnn_xvector_orig(gTDNN):\n",
    "    \"\"\"xvector architecture\"\"\"\n",
    "    def __init__(self, config, n_labels=31):\n",
    "        super(tdnn_xvector_orig, self).__init__(config, n_labels)\n",
    "        inDim = config['input_dim']\n",
    "        self.tdnn = nn.Sequential(\n",
    "            #tdnn1\n",
    "            nn.Conv1d(inDim, 512, stride=1, dilation=1, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            #tdnn2\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=2, kernel_size=3),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            #tdnn3\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=3, kernel_size=3),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            #tdnn4\n",
    "            nn.Conv1d(512, 512, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.ReLU(True),            \n",
    "            nn.BatchNorm1d(512),\n",
    "            #tdnn5\n",
    "            nn.Conv1d(512, 1500, stride=1, dilation=1, kernel_size=1),\n",
    "            nn.ReLU(True),        \n",
    "            nn.BatchNorm1d(1500),\n",
    "            # statistic-pooling\n",
    "            st_pool_layer(),\n",
    "            #tdnn6\n",
    "            nn.Linear(3000, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            #tdnn7\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            #output\n",
    "            nn.Linear(512, n_labels),\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def embed(self, x):\n",
    "        x = x.squeeze()\n",
    "        # (batch, time, freq) -> (batch, freq, time)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.tdnn(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                n = m.kernel_size[0] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tdnn_xvector_orig(config, config['n_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_cuda']:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.train.train_utils import set_seed, find_optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "\n",
    "criterion, optimizer = find_optimizer(config, model)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "scheduler = MultiStepLR(optimizer, [10], 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_eer']:\n",
    "    train_loader, val_loader, test_loader, sv_loader = dataloaders\n",
    "else:\n",
    "    train_loader, val_loader, test_loader = dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                        \n",
    "        loss_sum += loss.item()\n",
    "        n_corrects += torch.sum(torch.eq(torch.argmax(logit, dim=1), y)).item()\n",
    "        total += y.size(0)\n",
    "        \n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            print(\"Batch {}/{}\\t Loss {:.6f}\" \\\n",
    "                  .format(batch_idx+1, len(train_loader), loss_sum /(batch_idx+1),)\n",
    "                 )\n",
    "        acc = n_corrects / total\n",
    "\n",
    "    acc = n_corrects / total\n",
    "    return loss_sum, acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from sv_system.train.si_train import val, sv_test\n",
    "\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "\n",
    "    scheduler.step()    \n",
    "    \n",
    "#     train code22222\n",
    "    train_loss, train_acc = train(model)\n",
    "    print(\"epoch #{}, train accuracy: {}\".format(epoch_idx, train_acc))\n",
    "\n",
    "#     validation code\n",
    "    val_loss, val_acc = val(config, val_loader, model, criterion)\n",
    "    print(\"epoch #{}, val accuracy: {}\".format(epoch_idx, val_acc))\n",
    "\n",
    "#     evaluate best_metric\n",
    "    if not config['no_eer']:\n",
    "        # eer validation code\n",
    "        eer, label, score = sv_test(config, sv_loader, model, trial)\n",
    "        print(\"epoch #{}, sv eer: {}\".format(epoch_idx, eer))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
