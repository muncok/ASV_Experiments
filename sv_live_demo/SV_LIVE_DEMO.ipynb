{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet34 import ResNet34, ResNet34_v1\n",
    "\n",
    "config = dict(\n",
    "    loss=\"softmax\",\n",
    "    gpu_no=[0], no_cuda=True\n",
    ")\n",
    "\n",
    "model = ResNet34(config, inplanes=16, n_labels=1759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extractor loaded from ./model_best.pth.tar\n"
     ]
    }
   ],
   "source": [
    "model.load_extractor(\"./model_best.pth.tar\")\n",
    "model.eval()\n",
    "\n",
    "if not config['no_cuda']:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Speaker Verification System\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from manage_audio import preprocess_audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class sv_system():\n",
    "    def __init__(self, model, n_dims=40, feat_format='fbank'):\n",
    "        self.speaker_models = dict()\n",
    "        self.dct_filters = librosa.filters.dct(n_filters=n_dims, n_input=n_dims)\n",
    "        self.model = model\n",
    "        self.n_dims = n_dims\n",
    "        self.feat_format = feat_format\n",
    "        \n",
    "        # for test\n",
    "#         self.speaker_models = self._random_speaker_model()\n",
    "    \n",
    "    def enrol(self, wav, spk_name):\n",
    "        feat = self._wav2feat(wav)\n",
    "        dvector = self._extract_dvector(feat).squeeze()\n",
    "        if spk_name not in self.speaker_models:\n",
    "            self.speaker_models[spk_name] = [dvector]\n",
    "        else:\n",
    "            self.speaker_models[spk_name] += [dvector]\n",
    "        \n",
    "    \n",
    "    def _extract_dvector(self, feat):\n",
    "        \"\"\"\n",
    "            dvector: ndarray\n",
    "        \"\"\"\n",
    "        if feat.dim() == 2:\n",
    "            feat = feat.unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        dvector = self.model.embed(feat).detach().cpu().numpy()\n",
    "        \n",
    "        return dvector\n",
    "    \n",
    "    def _wav2feat(self, wav):\n",
    "        \"\"\"\n",
    "            extracting input feature from wav (mfcc, fbank)\n",
    "        \"\"\"\n",
    "        wav_data = librosa.core.load(wav, sr=16000)[0]\n",
    "        feat = preprocess_audio(wav_data, n_mels=self.n_dims, \n",
    "                    dct_filters=self.dct_filters, in_feature=self.feat_format)\n",
    "        \n",
    "        return feat\n",
    "        \n",
    "    def _random_speaker_model(self):\n",
    "        \"\"\"\n",
    "            random speaker model used for testing a sv_system\n",
    "        \"\"\"\n",
    "        random_dvector = np.random.rand(4, self.model.embed_dim)\n",
    "        random_speakers = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "        random_speaker_models = dict.fromkeys(random_speakers)\n",
    "\n",
    "        for i, key in enumerate(random_speaker_models.keys()):\n",
    "            random_speaker_models[key] = [random_dvector[i]]*2\n",
    "        \n",
    "        return random_speaker_models\n",
    "    \n",
    "    def init_speaker_model(self):\n",
    "        self.speaker_model = dict()\n",
    "    \n",
    "    def verify(self, wav):\n",
    "        \"\"\"\n",
    "            verify a input wav and output a verification result\n",
    "            and rank-1 identification\n",
    "        \"\"\"\n",
    "        feat = self._wav2feat(wav)\n",
    "        test_dvector = self._extract_dvector(feat)\n",
    "        # order keep?\n",
    "        # averaging all dvectors for each speaker\n",
    "        avg_speaker_models = np.stack([np.mean(v, axis=0) for v in self.speaker_models.values()], \n",
    "                                      axis=0)\n",
    "\n",
    "        score = F.cosine_similarity(torch.from_numpy(avg_speaker_models).float(), \n",
    "                                    torch.from_numpy(test_dvector).float(), dim=1)\n",
    "        threshold = 0.607\n",
    "        pred_speaker = list(self.speaker_models.keys())[torch.argmax(score)]\n",
    "        if max(score) > threshold:\n",
    "            print(\"Accepted as {} ({:.3f})\".format(pred_speaker, max(score)))\n",
    "        else:\n",
    "            print(\"Reject ({:.3f})\".format(max(score)))\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sv_system = sv_system(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sv_system.enrol(\"test_wavs/f92e49f3_nohash_2.wav\", 'ID1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sv_system.enrol(\"test_wavs//b959cd0c_nohash_1.wav\", 'ID2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification &  Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accepted as ID2 (0.780)\n"
     ]
    }
   ],
   "source": [
    "test_sv_system.verify(\"test_wavs/b959cd0c_nohash_3.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject (0.372)\n"
     ]
    }
   ],
   "source": [
    "test_sv_system.verify(\"test_wavs/063d48cf_nohash_0.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
