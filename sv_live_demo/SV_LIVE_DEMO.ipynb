{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SV Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speaker Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ResNet34 import ResNet34, ResNet34_v1\n",
    "from ResNet34_1 import ResNet34_v4\n",
    "from tdnnModel import tdnn_xvector, tdnn_xvector_v1\n",
    "\n",
    "config = dict(\n",
    "    loss=\"softmax\",\n",
    "    gpu_no=[0], no_cuda=True,\n",
    "    input_dim=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = ResNet34(config, inplanes=16, n_labels=1759)\n",
    "# model = ResNet34_v4(config, layers=[3,4,6,3], n_labels=1260)\n",
    "# model = tdnn_xvector_v1(config, n_labels=1759)\n",
    "model = ResNet34_v1(config, n_labels=1759)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.load_extractor(\"../models/gcommand_equal30_wav/norm/ResNet34_v1_softmax/fbank_30f_100f_v01/model_best.pth.tar\")\n",
    "# model.load_extractor(\"../models/gcommand_equal30_wav/norm/tdnn_xvector_softmax/fbank_80f_80f_v00/model_best.pth.tar\")\n",
    "# model.load_extractor(\"./tdnn_model3/model_best.pth.tar\")\n",
    "model.load(\"./ResNet34_v1_1/model_best.pth.tar\")\n",
    "model.eval()\n",
    "\n",
    "if not config['no_cuda']:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Speaker Verification System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from pydub  import AudioSegment\n",
    "from manage_audio import strip_audio\n",
    "from manage_audio import preprocess_audio\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "\n",
    "def seg2wav(seg):\n",
    "    wav_data = (np.array(seg.get_array_of_samples())\n",
    "                / 32768.0).astype(np.float32)\n",
    "    \n",
    "    return wav_data\n",
    "\n",
    "def zero_padding(data, in_len):\n",
    "    padding_len = max(0, in_len - len(data))\n",
    "    data = np.pad(data, (padding_len//2, padding_len - padding_len//2), \"constant\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "class sv_system():\n",
    "    def __init__(self, model, spk_models=None, lda_model=None,\n",
    "                 n_dims=40, feat_format='fbank'):\n",
    "        self.speaker_models = pickle.load(open(spk_models, \"rb\")) if spk_models \\\n",
    "                                else dict()\n",
    "        self.lda_model = pickle.load(open(lda_model, \"rb\")) if lda_model \\\n",
    "                                else None\n",
    "        self.dct_filters = librosa.filters.dct(n_filters=n_dims, n_input=n_dims)\n",
    "        self.model = model\n",
    "        self.n_dims = n_dims\n",
    "        self.feat_format = feat_format\n",
    "        self.enrolled_feats = dict()\n",
    "    \n",
    "    def enrol(self, wav, spk_name):\n",
    "        feat = self._wav2feat(wav)\n",
    "#         print(\"feat shape: {}\".format(feat.shape))\n",
    "        dvector = self._extract_dvector(feat).squeeze()\n",
    "        if spk_name not in self.speaker_models:\n",
    "            self.enrolled_feats[spk_name] = [feat]\n",
    "            self.speaker_models[spk_name] = [dvector]\n",
    "        else:\n",
    "            self.enrolled_feats[spk_name] += [feat]\n",
    "            self.speaker_models[spk_name] += [dvector]\n",
    "            \n",
    "        \n",
    "    def enrols(self, wav, spk_name):\n",
    "        feats = self._wav2feats(wav)\n",
    "        for feat in feats:\n",
    "            dvector = self._extract_dvector(feat).squeeze()\n",
    "\n",
    "            if spk_name not in self.speaker_models:\n",
    "                self.speaker_models[spk_name] = [dvector]\n",
    "            else:\n",
    "                self.speaker_models[spk_name] += [dvector]\n",
    "                   \n",
    "    def _extract_dvector(self, feat):\n",
    "        \"\"\"\n",
    "            dvector: ndarray\n",
    "        \"\"\"\n",
    "        if feat.dim() == 2:\n",
    "            feat = feat.unsqueeze(0).unsqueeze(0)\n",
    "        elif feat.dim() == 3:\n",
    "            if isinstance(self.model, ResNet34_v1):\n",
    "                feat = feat.unsqueeze(1)\n",
    "            else:\n",
    "                feat = feat.unsqueeze(0)\n",
    "                \n",
    "        \n",
    "        dvector = self.model.embed(feat).detach().cpu().numpy()\n",
    "        if self.lda_model:\n",
    "            dvector = self.lda_model.transform(dvector).astype(np.float32)\n",
    "                \n",
    "        return dvector\n",
    "    \n",
    "    def _wav2feats(self, wav):\n",
    "        wav_seg = AudioSegment.from_wav(wav)\n",
    "#         wav_seg = wav_seg.normalize()\n",
    "        voice_segs = pydub.silence.split_on_silence(wav_seg, min_silence_len=100, \n",
    "                keep_silence=500, silence_thresh=-32)\n",
    "        self.voice_segs = voice_segs\n",
    "        print([len(seg) for seg in voice_segs])\n",
    "#         max_len = int(len(max(voice_segs, key=len)) * 16000/1000)\n",
    "#         wav_data = [zero_padding(strip_audio(seg2wav(seg), rms_ths=0.10), 16000)\n",
    "#                     for seg in voice_segs]\n",
    "        wav_data = [seg2wav(seg) for seg in voice_segs]\n",
    "        feats = []\n",
    "        for wav_d in wav_data:\n",
    "            feat = preprocess_audio(wav_d, n_mels=self.n_dims, \n",
    "                        dct_filters=self.dct_filters, in_feature=self.feat_format)\n",
    "            feats.append(feat)\n",
    "        \n",
    "        return feats\n",
    "        \n",
    "    def _wav2feat(self, wav):\n",
    "        \"\"\"\n",
    "            extracting input feature from wav (mfcc, fbank)\n",
    "        \"\"\"\n",
    "#         wav_data = librosa.core.load(wav, sr=16000)[0]\n",
    "        wav_seg = AudioSegment.from_wav(wav)\n",
    "#         wav_seg = wav_seg.normalize()\n",
    "#         print(len(wav_seg))\n",
    "#         wav_seg = wav_seg.strip_silence(silence_len=100, padding=100, silence_thresh=-32)\n",
    "#         assert len(wav_seg) > 0, \"no voice\"\n",
    "        wav_data = seg2wav(wav_seg)\n",
    "#         wav_data = strip_audio(wav_data, rms_ths=0.10)\n",
    "#         wav_data = zero_padding(wav_data, 16000)\n",
    "        \n",
    "        feat = preprocess_audio(wav_data, n_mels=self.n_dims, \n",
    "                    dct_filters=self.dct_filters, in_feature=self.feat_format)\n",
    "        \n",
    "        return feat\n",
    "        \n",
    "    def init_speaker_model(self):\n",
    "        self.speaker_model = dict()\n",
    "    \n",
    "    def compute_spk_model(self):\n",
    "#         self.concat_feats = np.concatenate([self._extract_dvector(torch.cat(v, dim=0)) \n",
    "#                                         for v in self.enrolled_feats.values()], \n",
    "#                                       axis=0)\n",
    "        self.concat_feats = avg_speaker_models = np.stack([np.mean(v, axis=0).squeeze() for v in self.speaker_models.values()], \n",
    "                                      axis=0)\n",
    "    def verify(self, wav):\n",
    "        \"\"\"\n",
    "            verify a input wav and output a verification result\n",
    "            and rank-1 identification\n",
    "        \"\"\"\n",
    "        feat = self._wav2feat(wav)\n",
    "        test_dvector = self._extract_dvector(feat)\n",
    "        # order keep?\n",
    "        # averaging all dvectors for each speaker\n",
    "#         avg_speaker_models = np.stack([np.mean(v, axis=0).squeeze() for v in self.speaker_models.values()], \n",
    "#                                       axis=0)\n",
    "\n",
    "#         score = F.cosine_similarity(torch.from_numpy(self.concat_feats).float(), \n",
    "#                                         torch.from_numpy(test_dvector).float(), dim=1).numpy()\n",
    "\n",
    "        score = []\n",
    "        for k, v in self.speaker_models.items():\n",
    "            v = np.array(v)\n",
    "            score_ = F.cosine_similarity(torch.from_numpy(v).float(), \n",
    "                                        torch.from_numpy(test_dvector).float(), dim=1).numpy()\n",
    "            score.append(np.median(score_))\n",
    "            \n",
    "        pred_speaker = list(self.speaker_models.keys())[np.argmax(score)]\n",
    "            \n",
    "        return pred_speaker, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kor_dataset = os.listdir(\"kor_voices/wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "for wav_file in kor_dataset:\n",
    "    filen = wav_file.rstrip('.wav')\n",
    "    spk, sent = filen.split('_')[0], filen.split('_')[1]\n",
    "    records.append((spk, sent, \"kor_voices/wav/\"+wav_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kor_dataset_df = pd.DataFrame.from_records(records, columns=['spk', 'sent', 'wav'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speaker model similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spk_model = test_sv_system.speaker_models\n",
    "spk_model_idx = list(spk_model.keys())\n",
    "avg_speaker_models = torch.from_numpy(np.stack([np.mean(v, axis=0).squeeze() for v in spk_model.values()], \n",
    "                                       axis=0))\n",
    "spk_model_scores = F.cosine_similarity(avg_speaker_models.unsqueeze(1), avg_speaker_models.unsqueeze(0), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "trials = []\n",
    "for a ,b in itertools.product(range(len(spk_model_idx)),range(len(spk_model_idx))):\n",
    "    trials.append((spk_model_idx[a],spk_model_idx[b],a,b))\n",
    "spk_model_trial_df = pd.DataFrame.from_records(trials, columns=['spk_a', 'spk_b', 'spk_a_id', 'spk_b_id'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spk_model_trial_df['score'] = spk_model_scores[spk_model_trial_df.spk_a_id, spk_model_trial_df.spk_b_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spk_model_trial_df[spk_model_trial_df.score > 0.8].spk_a.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blacklist = spk_model_trial_df[spk_model_trial_df.score > 0.8].spk_a.value_counts()[:7].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blacklist = ['be', 'ms', 'cy', 'dw', 'dg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_kor_dataset_df = kor_dataset_df[~kor_dataset_df.spk.isin(blacklist)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sv_system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_sv_system = sv_system(model, spk_models=None, lda_model=None)\n",
    "# test_sv_system = sv_system(model, spk_models=None, lda_model=\"tdnn_model3/lda_model.pkl\")\n",
    "test_sv_system = sv_system(model, spk_models=None, lda_model=None, n_dims=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "blacklist = ['hm', 'hs', 'be', 'ms', 'ds', 'cy', 'dw', 'dg', 'ej']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enroll_spks = ['je', 'ip', 'hm', 'sv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# white_df = kor_dataset_df[~kor_dataset_df.spk.isin(blacklist)]\n",
    "white_df = kor_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enrollment_df = white_df[white_df.spk.isin(enroll_spks)].groupby(['spk','sent']).apply(lambda x: x.sample(n=1))\n",
    "# enrollment_df = kor_dataset_df[kor_dataset_df.spk.isin(enroll_spks)].groupby(['spk']).apply(lambda x: x.sample(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df = white_df[(~white_df.wav.isin(enrollment_df.wav))]\n",
    "# test_df = kor_dataset_df[kor_dataset_df.spk.isin(test_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"enroll: {}, test: {}\".format(len(enrollment_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sv_system.init_speaker_model()\n",
    "for idx, row in enrollment_df.iterrows():\n",
    "    test_sv_system.enrol(row.wav, row.spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sv_system.compute_spk_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp_counts = 0 # true positive\n",
    "fp_counts = 0 # false positive\n",
    "threshold = 0.85\n",
    "\n",
    "scores = []\n",
    "labels = []\n",
    "preds = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    pred_speaker, score = test_sv_system.verify(row.wav)\n",
    "    preds.append(pred_speaker)\n",
    "    if row.spk in enroll_spks and max(score) >= threshold:\n",
    "        tp_counts += 1\n",
    "        scores.append(score); labels.append(1)\n",
    "    elif row.spk in enroll_spks and max(score) < threshold:\n",
    "        scores.append(score); labels.append(1)\n",
    "    elif row.spk not in enroll_spks and max(score) >= threshold:\n",
    "        fp_counts += 1\n",
    "        scores.append(score); labels.append(0)\n",
    "    else:\n",
    "        scores.append(score); labels.append(0)\n",
    "scores = np.array(scores)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp_rate = tp_counts / len(test_df)\n",
    "fp_rate = fp_counts / len(test_df)\n",
    "\n",
    "print(\"tp: {:.2f}, fn: {:.2f}, fp: {:.2f}, tn: {:.2f}\".format(tp_rate, 1-tp_rate, fp_rate, 1-fp_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thres = roc_curve(\n",
    "        labels, np.max(scores, axis=1), pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.3f}%\".format(eer*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df['score'] = np.max(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df[test_df.spk.isin(enroll_spks)].hist()\n",
    "plt.xlim([0.5, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df[~test_df.spk.isin(enroll_spks)].hist()\n",
    "plt.xlim([0.5, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = test_df[~test_df.spk.isin(enroll_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enroll_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(test_df.spk.tolist(), preds, labels=test_df.spk.unique().tolist())\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=test_df.spk.unique().tolist(),\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cos_score(a, b):\n",
    "    print(np.dot(a, b)/np.linalg.norm(a)/np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df = pd.concat([test_df, pd.DataFrame.from_records(scores.round(4).tolist(), \n",
    "                                                          index=test_df.index, \n",
    "                                                          columns=test_sv_system.speaker_models.keys())], \n",
    "                      axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df.drop(columns='score').to_csv(\"./ResNet34_v1_1/result.csv\", float_format='%.3f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enrollment_df.to_csv(\"./ResNet34_v1_1/enrollment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_sv_system.enrols(\"test_43AT1YC.wav\", \"heesu\")\n",
    "test_sv_system.enrols(\"mini_dataset/heesu_en1.wav\", \"heesu\")\n",
    "# test_sv_system.enrols(\"mini_dataset/heesu_en2.wav\", \"heesu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sv_system.enrol(\"./mini_dataset/inpyo.wav\", 'inpyo')\n",
    "test_sv_system.enrol(\"./mini_dataset/inpyo_6Pu01w1.wav\", 'inpyo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sv_system.enrol(\"./mini_dataset/jiwoong.wav\", 'jiwoong')\n",
    "test_sv_system.enrol(\"./mini_dataset/jiwoong_3bJIHKe.wav\", 'jiwoong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sv_system.enrol(\"./mini_dataset/younghyun.wav\", 'younghyun')\n",
    "test_sv_system.enrol(\"./mini_dataset/younghyun_y4SCszr.wav\", 'younghyun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification &  Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for wav in sorted(os.listdir(\"mini_dataset/\")):\n",
    "    if 'wav' not in wav: continue\n",
    "    if wav in test_sv_system.enrolled_wavs: continue\n",
    "#     if 'heesu' not in wav: continue\n",
    "    print(wav)\n",
    "    test_sv_system.verify(\"mini_dataset/\"+wav)\n",
    "    print(\"--------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## import IPython.display as ipd\n",
    "ipd.Audio(\"mini_dataset/inpyo.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 연속문장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(\"test_43AT1YC.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wav_seg = AudioSegment.from_wav(\"mini_dataset/heesu_1.wav\")\n",
    "# wav_seg = wav_seg.normalize()\n",
    "# wav_seg = wav_seg.strip_silence(silence_len=20, silence_thresh=-16,\n",
    "#         padding=20)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voice_segs = pydub.silence.split_on_silence(wav_seg, min_silence_len=100, keep_silence=500, silence_thresh=-32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voice_segs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import soundfile as sd\n",
    "sd.write(\"mini_dataset/heesu_en1_right.wav\", seg2wav(voice_segs[5]), 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voice_segs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AudioSegment.from_wav(\"mini_dataset/inpyo_rtXndSE.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AudioSegment.from_wav(\"mini_dataset/jiwoong.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"kor_voices/kor_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spks = df.spk.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['label'] = df.spk.apply(lambda x: spks.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle(\"kor_voices/kor_dataset.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
