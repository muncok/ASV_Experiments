{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_fbank_xvector\", \n",
    "                              data_folder=\"/dataset/SV_sets/voxceleb12/feats/fbank64_vad/\",\n",
    "                              input_frames=400, splice_frames=[200, 400], stride_frames=1, \n",
    "                              input_format='fbank', input_dim=65, random_clip=True,\n",
    "                              n_epochs=200, lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False, batch_size=128,\n",
    "                              gpu_no=[0], cuda=True, num_workers=4,\n",
    "                              arch=\"tdnn_conv\", loss=\"softmax\",\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.feat_dataset import FeatDataset\n",
    "# dev_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_dev.csv\")\n",
    "dev_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_si.csv\")\n",
    "dev_df = dev_df.sample(frac=1.0)\n",
    "dev_train_df = dev_df[dev_df.set == 'train']\n",
    "dev_val_df = dev_df[dev_df.set == 'val']\n",
    "eval_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_eval.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_train_dataset = FeatDataset.read_df(config, dev_train_df, 'train')\n",
    "dev_val_dataset = FeatDataset.read_df(config, dev_val_df, 'test')\n",
    "eval_dataset = FeatDataset.read_df(config, eval_df, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_default_loader \n",
    "dev_train_dataloader = init_default_loader(config, dev_train_dataset, shuffle=True, var_len=False) \n",
    "dev_val_dataloader = init_default_loader(config, dev_val_dataset, shuffle=False, var_len=False) \n",
    "eval_dataloader = init_default_loader(config, eval_dataset, shuffle=False, var_len=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdnn_models import tdnn_xvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = tdnn_xvector(config, 512, n_labels=len(dev_df.label.unique()))\n",
    "# saved_model = torch.load(\"trained_models/vox1_dev_tdnn_xvector_held_out.pt\")\n",
    "# model.load_state_dict(saved_model)\n",
    "\n",
    "if not config['no_cuda']:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(\"logs/self_paced_hard_voxc1_si\")\n",
    "model_path = \"trained_models/voxc1_si_tdnn_xvector_spl_hard.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "curr_lr: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100/1047\t Loss 0.053281\n",
      "Batch 200/1047\t Loss 0.052417\n",
      "Batch 300/1047\t Loss 0.051760\n",
      "Batch 400/1047\t Loss 0.051301\n",
      "Batch 500/1047\t Loss 0.050988\n",
      "Batch 600/1047\t Loss 0.050781\n",
      "Batch 700/1047\t Loss 0.050645\n",
      "Batch 800/1047\t Loss 0.050554\n",
      "Batch 900/1047\t Loss 0.050488\n",
      "Batch 1000/1047\t Loss 0.050452\n",
      "epoch #0, train loss: 0.0504, train acc: 0.0529\n",
      "sel_samples/total: 41281/134000\n",
      "epoch #0, val loss: 0.0447, val acc: 0.0201\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.043362\n",
      "Batch 200/1047\t Loss 0.043235\n",
      "Batch 300/1047\t Loss 0.043266\n",
      "Batch 400/1047\t Loss 0.043316\n",
      "Batch 500/1047\t Loss 0.043348\n",
      "Batch 600/1047\t Loss 0.043434\n",
      "Batch 700/1047\t Loss 0.043458\n",
      "Batch 800/1047\t Loss 0.043477\n",
      "Batch 900/1047\t Loss 0.043477\n",
      "Batch 1000/1047\t Loss 0.043510\n",
      "epoch #1, train loss: 0.0435, train acc: 0.1708\n",
      "sel_samples/total: 29851/134000\n",
      "epoch #1, val loss: 0.0381, val acc: 0.0750\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.037675\n",
      "Batch 200/1047\t Loss 0.037688\n",
      "Batch 300/1047\t Loss 0.037752\n",
      "Batch 400/1047\t Loss 0.037829\n",
      "Batch 500/1047\t Loss 0.037887\n",
      "Batch 600/1047\t Loss 0.037946\n",
      "Batch 700/1047\t Loss 0.038005\n",
      "Batch 800/1047\t Loss 0.038036\n",
      "Batch 900/1047\t Loss 0.038079\n",
      "Batch 1000/1047\t Loss 0.038108\n",
      "epoch #2, train loss: 0.0381, train acc: 0.3257\n",
      "sel_samples/total: 30430/134000\n",
      "epoch #2, val loss: 0.0337, val acc: 0.1236\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.032989\n",
      "Batch 200/1047\t Loss 0.033028\n",
      "Batch 300/1047\t Loss 0.033125\n",
      "Batch 400/1047\t Loss 0.033182\n",
      "Batch 500/1047\t Loss 0.033280\n",
      "Batch 600/1047\t Loss 0.033328\n",
      "Batch 700/1047\t Loss 0.033349\n",
      "Batch 800/1047\t Loss 0.033403\n",
      "Batch 900/1047\t Loss 0.033460\n",
      "Batch 1000/1047\t Loss 0.033514\n",
      "epoch #3, train loss: 0.0335, train acc: 0.4634\n",
      "sel_samples/total: 30420/134000\n",
      "epoch #3, val loss: 0.0304, val acc: 0.1946\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.029004\n",
      "Batch 200/1047\t Loss 0.029116\n",
      "Batch 300/1047\t Loss 0.029242\n",
      "Batch 400/1047\t Loss 0.029341\n",
      "Batch 500/1047\t Loss 0.029449\n",
      "Batch 600/1047\t Loss 0.029476\n",
      "Batch 700/1047\t Loss 0.029538\n",
      "Batch 800/1047\t Loss 0.029563\n",
      "Batch 900/1047\t Loss 0.029633\n",
      "Batch 1000/1047\t Loss 0.029661\n",
      "epoch #4, train loss: 0.0297, train acc: 0.5782\n",
      "sel_samples/total: 29385/134000\n",
      "epoch #4, val loss: 0.0277, val acc: 0.2382\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.025879\n",
      "Batch 200/1047\t Loss 0.025881\n",
      "Batch 300/1047\t Loss 0.025976\n",
      "Batch 400/1047\t Loss 0.026078\n",
      "Batch 500/1047\t Loss 0.026163\n",
      "Batch 600/1047\t Loss 0.026196\n",
      "Batch 700/1047\t Loss 0.026253\n",
      "Batch 800/1047\t Loss 0.026307\n",
      "Batch 900/1047\t Loss 0.026346\n",
      "Batch 1000/1047\t Loss 0.026391\n",
      "epoch #5, train loss: 0.0264, train acc: 0.6709\n",
      "sel_samples/total: 27853/134000\n",
      "epoch #5, val loss: 0.0244, val acc: 0.3142\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.022936\n",
      "Batch 200/1047\t Loss 0.023025\n",
      "Batch 300/1047\t Loss 0.023108\n",
      "Batch 400/1047\t Loss 0.023237\n",
      "Batch 500/1047\t Loss 0.023338\n",
      "Batch 600/1047\t Loss 0.023404\n",
      "Batch 700/1047\t Loss 0.023455\n",
      "Batch 800/1047\t Loss 0.023501\n",
      "Batch 900/1047\t Loss 0.023554\n",
      "Batch 1000/1047\t Loss 0.023591\n",
      "epoch #6, train loss: 0.0236, train acc: 0.7381\n",
      "sel_samples/total: 26406/134000\n",
      "epoch #6, val loss: 0.0213, val acc: 0.3858\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.020333\n",
      "Batch 200/1047\t Loss 0.020476\n",
      "Batch 300/1047\t Loss 0.020588\n",
      "Batch 400/1047\t Loss 0.020679\n",
      "Batch 500/1047\t Loss 0.020804\n",
      "Batch 600/1047\t Loss 0.020897\n",
      "Batch 700/1047\t Loss 0.021022\n",
      "Batch 800/1047\t Loss 0.021088\n",
      "Batch 900/1047\t Loss 0.021123\n",
      "Batch 1000/1047\t Loss 0.021181\n",
      "epoch #7, train loss: 0.0212, train acc: 0.7915\n",
      "sel_samples/total: 24809/134000\n",
      "epoch #7, val loss: 0.0217, val acc: 0.3814\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.018279\n",
      "Batch 200/1047\t Loss 0.018542\n",
      "Batch 300/1047\t Loss 0.018663\n",
      "Batch 400/1047\t Loss 0.018690\n",
      "Batch 500/1047\t Loss 0.018788\n",
      "Batch 600/1047\t Loss 0.018846\n",
      "Batch 700/1047\t Loss 0.018905\n",
      "Batch 800/1047\t Loss 0.018991\n",
      "Batch 900/1047\t Loss 0.019044\n",
      "Batch 1000/1047\t Loss 0.019107\n",
      "epoch #8, train loss: 0.0191, train acc: 0.8315\n",
      "sel_samples/total: 23213/134000\n",
      "epoch #8, val loss: 0.0207, val acc: 0.4039\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.016562\n",
      "Batch 200/1047\t Loss 0.016721\n",
      "Batch 300/1047\t Loss 0.016782\n",
      "Batch 400/1047\t Loss 0.016959\n",
      "Batch 500/1047\t Loss 0.017061\n",
      "Batch 600/1047\t Loss 0.017166\n",
      "Batch 700/1047\t Loss 0.017218\n",
      "Batch 800/1047\t Loss 0.017248\n",
      "Batch 900/1047\t Loss 0.017295\n",
      "Batch 1000/1047\t Loss 0.017342\n",
      "epoch #9, train loss: 0.0174, train acc: 0.8617\n",
      "sel_samples/total: 21814/134000\n",
      "epoch #9, val loss: 0.0171, val acc: 0.4989\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.014848\n",
      "Batch 200/1047\t Loss 0.015094\n",
      "Batch 300/1047\t Loss 0.015143\n",
      "Batch 400/1047\t Loss 0.015238\n",
      "Batch 500/1047\t Loss 0.015263\n",
      "Batch 600/1047\t Loss 0.015396\n",
      "Batch 700/1047\t Loss 0.015500\n",
      "Batch 800/1047\t Loss 0.015553\n",
      "Batch 900/1047\t Loss 0.015597\n",
      "Batch 1000/1047\t Loss 0.015642\n",
      "epoch #10, train loss: 0.0157, train acc: 0.8858\n",
      "sel_samples/total: 20493/134000\n",
      "epoch #10, val loss: 0.0176, val acc: 0.4914\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.013770\n",
      "Batch 200/1047\t Loss 0.013887\n",
      "Batch 300/1047\t Loss 0.013953\n",
      "Batch 400/1047\t Loss 0.014018\n",
      "Batch 500/1047\t Loss 0.014066\n",
      "Batch 600/1047\t Loss 0.014158\n",
      "Batch 700/1047\t Loss 0.014187\n",
      "Batch 800/1047\t Loss 0.014188\n",
      "Batch 900/1047\t Loss 0.014260\n",
      "Batch 1000/1047\t Loss 0.014314\n",
      "epoch #11, train loss: 0.0143, train acc: 0.9052\n",
      "sel_samples/total: 19364/134000\n",
      "epoch #11, val loss: 0.0164, val acc: 0.5240\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.012670\n",
      "Batch 200/1047\t Loss 0.012649\n",
      "Batch 300/1047\t Loss 0.012708\n",
      "Batch 400/1047\t Loss 0.012752\n",
      "Batch 500/1047\t Loss 0.012812\n",
      "Batch 600/1047\t Loss 0.012831\n",
      "Batch 700/1047\t Loss 0.012926\n",
      "Batch 800/1047\t Loss 0.012983\n",
      "Batch 900/1047\t Loss 0.012979\n",
      "Batch 1000/1047\t Loss 0.012995\n",
      "epoch #12, train loss: 0.0130, train acc: 0.9200\n",
      "sel_samples/total: 18428/134000\n",
      "epoch #12, val loss: 0.0161, val acc: 0.5393\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.011462\n",
      "Batch 200/1047\t Loss 0.011694\n",
      "Batch 300/1047\t Loss 0.011746\n",
      "Batch 400/1047\t Loss 0.011652\n",
      "Batch 500/1047\t Loss 0.011620\n",
      "Batch 600/1047\t Loss 0.011696\n",
      "Batch 700/1047\t Loss 0.011717\n",
      "Batch 800/1047\t Loss 0.011832\n",
      "Batch 900/1047\t Loss 0.011887\n",
      "Batch 1000/1047\t Loss 0.011967\n",
      "epoch #13, train loss: 0.0120, train acc: 0.9313\n",
      "sel_samples/total: 17547/134000\n",
      "epoch #13, val loss: 0.0161, val acc: 0.5388\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.010682\n",
      "Batch 200/1047\t Loss 0.010502\n",
      "Batch 300/1047\t Loss 0.010619\n",
      "Batch 400/1047\t Loss 0.010606\n",
      "Batch 500/1047\t Loss 0.010711\n",
      "Batch 600/1047\t Loss 0.010779\n",
      "Batch 700/1047\t Loss 0.010816\n",
      "Batch 800/1047\t Loss 0.010898\n",
      "Batch 900/1047\t Loss 0.011002\n",
      "Batch 1000/1047\t Loss 0.011039\n",
      "epoch #14, train loss: 0.0110, train acc: 0.9406\n",
      "sel_samples/total: 16750/134000\n",
      "epoch #14, val loss: 0.0144, val acc: 0.5921\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.009579\n",
      "Batch 200/1047\t Loss 0.009389\n",
      "Batch 300/1047\t Loss 0.009457\n",
      "Batch 400/1047\t Loss 0.009610\n",
      "Batch 500/1047\t Loss 0.009690\n",
      "Batch 600/1047\t Loss 0.009762\n",
      "Batch 700/1047\t Loss 0.009801\n",
      "Batch 800/1047\t Loss 0.009858\n",
      "Batch 900/1047\t Loss 0.009916\n",
      "Batch 1000/1047\t Loss 0.009954\n",
      "epoch #15, train loss: 0.0100, train acc: 0.9493\n",
      "sel_samples/total: 16073/134000\n",
      "epoch #15, val loss: 0.0134, val acc: 0.6188\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.008505\n",
      "Batch 200/1047\t Loss 0.008835\n",
      "Batch 300/1047\t Loss 0.008821\n",
      "Batch 400/1047\t Loss 0.008844\n",
      "Batch 500/1047\t Loss 0.008903\n",
      "Batch 600/1047\t Loss 0.008967\n",
      "Batch 700/1047\t Loss 0.008992\n",
      "Batch 800/1047\t Loss 0.009064\n",
      "Batch 900/1047\t Loss 0.009115\n",
      "Batch 1000/1047\t Loss 0.009169\n",
      "epoch #16, train loss: 0.0092, train acc: 0.9555\n",
      "sel_samples/total: 15451/134000\n",
      "epoch #16, val loss: 0.0146, val acc: 0.5932\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.008157\n",
      "Batch 200/1047\t Loss 0.008140\n",
      "Batch 300/1047\t Loss 0.008242\n",
      "Batch 400/1047\t Loss 0.008235\n",
      "Batch 500/1047\t Loss 0.008283\n",
      "Batch 600/1047\t Loss 0.008306\n",
      "Batch 700/1047\t Loss 0.008329\n",
      "Batch 800/1047\t Loss 0.008354\n",
      "Batch 900/1047\t Loss 0.008388\n",
      "Batch 1000/1047\t Loss 0.008460\n",
      "epoch #17, train loss: 0.0085, train acc: 0.9613\n",
      "sel_samples/total: 14904/134000\n",
      "epoch #17, val loss: 0.0138, val acc: 0.6254\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.007693\n",
      "Batch 200/1047\t Loss 0.007642\n",
      "Batch 300/1047\t Loss 0.007642\n",
      "Batch 400/1047\t Loss 0.007582\n",
      "Batch 500/1047\t Loss 0.007665\n",
      "Batch 600/1047\t Loss 0.007667\n",
      "Batch 700/1047\t Loss 0.007720\n",
      "Batch 800/1047\t Loss 0.007715\n",
      "Batch 900/1047\t Loss 0.007744\n",
      "Batch 1000/1047\t Loss 0.007750\n",
      "epoch #18, train loss: 0.0078, train acc: 0.9662\n",
      "sel_samples/total: 14465/134000\n",
      "epoch #18, val loss: 0.0125, val acc: 0.6477\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.006943\n",
      "Batch 200/1047\t Loss 0.006877\n",
      "Batch 300/1047\t Loss 0.006758\n",
      "Batch 400/1047\t Loss 0.006857\n",
      "Batch 500/1047\t Loss 0.006894\n",
      "Batch 600/1047\t Loss 0.006998\n",
      "Batch 700/1047\t Loss 0.007024\n",
      "Batch 800/1047\t Loss 0.007039\n",
      "Batch 900/1047\t Loss 0.007075\n",
      "Batch 1000/1047\t Loss 0.007119\n",
      "epoch #19, train loss: 0.0071, train acc: 0.9699\n",
      "sel_samples/total: 14145/134000\n",
      "epoch #19, val loss: 0.0124, val acc: 0.6552\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.006328\n",
      "Batch 200/1047\t Loss 0.006354\n",
      "Batch 300/1047\t Loss 0.006449\n",
      "Batch 400/1047\t Loss 0.006363\n",
      "Batch 500/1047\t Loss 0.006338\n",
      "Batch 600/1047\t Loss 0.006324\n",
      "Batch 700/1047\t Loss 0.006336\n",
      "Batch 800/1047\t Loss 0.006324\n",
      "Batch 900/1047\t Loss 0.006366\n",
      "Batch 1000/1047\t Loss 0.006411\n",
      "epoch #20, train loss: 0.0064, train acc: 0.9736\n",
      "sel_samples/total: 13728/134000\n",
      "epoch #20, val loss: 0.0118, val acc: 0.6807\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.005724\n",
      "Batch 200/1047\t Loss 0.005782\n",
      "Batch 300/1047\t Loss 0.005750\n",
      "Batch 400/1047\t Loss 0.005797\n",
      "Batch 500/1047\t Loss 0.005802\n",
      "Batch 600/1047\t Loss 0.005806\n",
      "Batch 700/1047\t Loss 0.005845\n",
      "Batch 800/1047\t Loss 0.005837\n",
      "Batch 900/1047\t Loss 0.005831\n",
      "Batch 1000/1047\t Loss 0.005832\n",
      "epoch #21, train loss: 0.0059, train acc: 0.9770\n",
      "sel_samples/total: 13371/134000\n",
      "epoch #21, val loss: 0.0122, val acc: 0.6670\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.004807\n",
      "Batch 200/1047\t Loss 0.004996\n",
      "Batch 300/1047\t Loss 0.005035\n",
      "Batch 400/1047\t Loss 0.005177\n",
      "Batch 500/1047\t Loss 0.005236\n",
      "Batch 600/1047\t Loss 0.005163\n",
      "Batch 700/1047\t Loss 0.005176\n",
      "Batch 800/1047\t Loss 0.005258\n",
      "Batch 900/1047\t Loss 0.005261\n",
      "Batch 1000/1047\t Loss 0.005288\n",
      "epoch #22, train loss: 0.0053, train acc: 0.9789\n",
      "sel_samples/total: 13141/134000\n",
      "epoch #22, val loss: 0.0118, val acc: 0.6793\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.004832\n",
      "Batch 200/1047\t Loss 0.004766\n",
      "Batch 300/1047\t Loss 0.004733\n",
      "Batch 400/1047\t Loss 0.004720\n",
      "Batch 500/1047\t Loss 0.004692\n",
      "Batch 600/1047\t Loss 0.004698\n",
      "Batch 700/1047\t Loss 0.004711\n",
      "Batch 800/1047\t Loss 0.004733\n",
      "Batch 900/1047\t Loss 0.004786\n",
      "Batch 1000/1047\t Loss 0.004835\n",
      "epoch #23, train loss: 0.0048, train acc: 0.9815\n",
      "sel_samples/total: 13072/134000\n",
      "epoch #23, val loss: 0.0118, val acc: 0.6791\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.004485\n",
      "Batch 200/1047\t Loss 0.004320\n",
      "Batch 300/1047\t Loss 0.004311\n",
      "Batch 400/1047\t Loss 0.004344\n",
      "Batch 500/1047\t Loss 0.004318\n",
      "Batch 600/1047\t Loss 0.004389\n",
      "Batch 700/1047\t Loss 0.004445\n",
      "Batch 800/1047\t Loss 0.004506\n",
      "Batch 900/1047\t Loss 0.004527\n",
      "Batch 1000/1047\t Loss 0.004514\n",
      "epoch #24, train loss: 0.0045, train acc: 0.9833\n",
      "sel_samples/total: 13002/134000\n",
      "epoch #24, val loss: 0.0111, val acc: 0.6989\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.003762\n",
      "Batch 200/1047\t Loss 0.003994\n",
      "Batch 300/1047\t Loss 0.004013\n",
      "Batch 400/1047\t Loss 0.003985\n",
      "Batch 500/1047\t Loss 0.003964\n",
      "Batch 600/1047\t Loss 0.003938\n",
      "Batch 700/1047\t Loss 0.003952\n",
      "Batch 800/1047\t Loss 0.004000\n",
      "Batch 900/1047\t Loss 0.004021\n",
      "Batch 1000/1047\t Loss 0.003998\n",
      "epoch #25, train loss: 0.0040, train acc: 0.9850\n",
      "sel_samples/total: 12843/134000\n",
      "epoch #25, val loss: 0.0114, val acc: 0.6933\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.003575\n",
      "Batch 200/1047\t Loss 0.003572\n",
      "Batch 300/1047\t Loss 0.003640\n",
      "Batch 400/1047\t Loss 0.003562\n",
      "Batch 500/1047\t Loss 0.003646\n",
      "Batch 600/1047\t Loss 0.003663\n",
      "Batch 700/1047\t Loss 0.003649\n",
      "Batch 800/1047\t Loss 0.003625\n",
      "Batch 900/1047\t Loss 0.003635\n",
      "Batch 1000/1047\t Loss 0.003646\n",
      "epoch #26, train loss: 0.0037, train acc: 0.9875\n",
      "sel_samples/total: 12633/134000\n",
      "epoch #26, val loss: 0.0108, val acc: 0.7069\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.002909\n",
      "Batch 200/1047\t Loss 0.002999\n",
      "Batch 300/1047\t Loss 0.002996\n",
      "Batch 400/1047\t Loss 0.003002\n",
      "Batch 500/1047\t Loss 0.002994\n",
      "Batch 600/1047\t Loss 0.002984\n",
      "Batch 700/1047\t Loss 0.003041\n",
      "Batch 800/1047\t Loss 0.003085\n",
      "Batch 900/1047\t Loss 0.003104\n",
      "Batch 1000/1047\t Loss 0.003119\n",
      "epoch #27, train loss: 0.0031, train acc: 0.9893\n",
      "sel_samples/total: 12443/134000\n",
      "epoch #27, val loss: 0.0106, val acc: 0.7181\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.002643\n",
      "Batch 200/1047\t Loss 0.002675\n",
      "Batch 300/1047\t Loss 0.002827\n",
      "Batch 400/1047\t Loss 0.002843\n",
      "Batch 500/1047\t Loss 0.002812\n",
      "Batch 600/1047\t Loss 0.002871\n",
      "Batch 700/1047\t Loss 0.002902\n",
      "Batch 800/1047\t Loss 0.002887\n",
      "Batch 900/1047\t Loss 0.002878\n",
      "Batch 1000/1047\t Loss 0.002899\n",
      "epoch #28, train loss: 0.0029, train acc: 0.9898\n",
      "sel_samples/total: 12499/134000\n",
      "epoch #28, val loss: 0.0145, val acc: 0.6526\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.002584\n",
      "Batch 200/1047\t Loss 0.002552\n",
      "Batch 300/1047\t Loss 0.002508\n",
      "Batch 400/1047\t Loss 0.002514\n",
      "Batch 500/1047\t Loss 0.002518\n",
      "Batch 600/1047\t Loss 0.002514\n",
      "Batch 700/1047\t Loss 0.002515\n",
      "Batch 800/1047\t Loss 0.002574\n",
      "Batch 900/1047\t Loss 0.002610\n",
      "Batch 1000/1047\t Loss 0.002598\n",
      "epoch #29, train loss: 0.0026, train acc: 0.9909\n",
      "sel_samples/total: 12750/134000\n",
      "epoch #29, val loss: 0.0097, val acc: 0.7384\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.002290\n",
      "Batch 200/1047\t Loss 0.002196\n",
      "Batch 300/1047\t Loss 0.002199\n",
      "Batch 400/1047\t Loss 0.002285\n",
      "Batch 500/1047\t Loss 0.002306\n",
      "Batch 600/1047\t Loss 0.002336\n",
      "Batch 700/1047\t Loss 0.002301\n",
      "Batch 800/1047\t Loss 0.002296\n",
      "Batch 900/1047\t Loss 0.002325\n",
      "Batch 1000/1047\t Loss 0.002315\n",
      "epoch #30, train loss: 0.0023, train acc: 0.9919\n",
      "sel_samples/total: 12450/134000\n",
      "epoch #30, val loss: 0.0100, val acc: 0.7366\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.002018\n",
      "Batch 200/1047\t Loss 0.001983\n",
      "Batch 300/1047\t Loss 0.002010\n",
      "Batch 400/1047\t Loss 0.001955\n",
      "Batch 500/1047\t Loss 0.001957\n",
      "Batch 600/1047\t Loss 0.001991\n",
      "Batch 700/1047\t Loss 0.002032\n",
      "Batch 800/1047\t Loss 0.002007\n",
      "Batch 900/1047\t Loss 0.002036\n",
      "Batch 1000/1047\t Loss 0.002051\n",
      "epoch #31, train loss: 0.0021, train acc: 0.9929\n",
      "sel_samples/total: 12678/134000\n",
      "epoch #31, val loss: 0.0099, val acc: 0.7357\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.001477\n",
      "Batch 200/1047\t Loss 0.001619\n",
      "Batch 300/1047\t Loss 0.001615\n",
      "Batch 400/1047\t Loss 0.001624\n",
      "Batch 500/1047\t Loss 0.001731\n",
      "Batch 600/1047\t Loss 0.001753\n",
      "Batch 700/1047\t Loss 0.001717\n",
      "Batch 800/1047\t Loss 0.001739\n",
      "Batch 900/1047\t Loss 0.001741\n",
      "Batch 1000/1047\t Loss 0.001751\n",
      "epoch #32, train loss: 0.0018, train acc: 0.9945\n",
      "sel_samples/total: 12724/134000\n",
      "epoch #32, val loss: 0.0107, val acc: 0.7213\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.001671\n",
      "Batch 200/1047\t Loss 0.001496\n",
      "Batch 300/1047\t Loss 0.001551\n",
      "Batch 400/1047\t Loss 0.001496\n",
      "Batch 500/1047\t Loss 0.001510\n",
      "Batch 600/1047\t Loss 0.001505\n",
      "Batch 700/1047\t Loss 0.001524\n",
      "Batch 800/1047\t Loss 0.001503\n",
      "Batch 900/1047\t Loss 0.001461\n",
      "Batch 1000/1047\t Loss 0.001464\n",
      "epoch #33, train loss: 0.0015, train acc: 0.9953\n",
      "sel_samples/total: 12524/134000\n",
      "epoch #33, val loss: 0.0093, val acc: 0.7530\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.001405\n",
      "Batch 200/1047\t Loss 0.001307\n",
      "Batch 300/1047\t Loss 0.001330\n",
      "Batch 400/1047\t Loss 0.001306\n",
      "Batch 500/1047\t Loss 0.001310\n",
      "Batch 600/1047\t Loss 0.001314\n",
      "Batch 700/1047\t Loss 0.001301\n",
      "Batch 800/1047\t Loss 0.001275\n",
      "Batch 900/1047\t Loss 0.001279\n",
      "Batch 1000/1047\t Loss 0.001291\n",
      "epoch #34, train loss: 0.0013, train acc: 0.9961\n",
      "sel_samples/total: 12772/134000\n",
      "epoch #34, val loss: 0.0090, val acc: 0.7590\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.001081\n",
      "Batch 200/1047\t Loss 0.001057\n",
      "Batch 300/1047\t Loss 0.001075\n",
      "Batch 400/1047\t Loss 0.001030\n",
      "Batch 500/1047\t Loss 0.001026\n",
      "Batch 600/1047\t Loss 0.001023\n",
      "Batch 700/1047\t Loss 0.001026\n",
      "Batch 800/1047\t Loss 0.001024\n",
      "Batch 900/1047\t Loss 0.001031\n",
      "Batch 1000/1047\t Loss 0.001045\n",
      "epoch #35, train loss: 0.0011, train acc: 0.9969\n",
      "sel_samples/total: 12523/134000\n",
      "epoch #35, val loss: 0.0090, val acc: 0.7573\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000715\n",
      "Batch 200/1047\t Loss 0.000759\n",
      "Batch 300/1047\t Loss 0.000848\n",
      "Batch 400/1047\t Loss 0.000832\n",
      "Batch 500/1047\t Loss 0.000857\n",
      "Batch 600/1047\t Loss 0.000878\n",
      "Batch 700/1047\t Loss 0.000864\n",
      "Batch 800/1047\t Loss 0.000849\n",
      "Batch 900/1047\t Loss 0.000850\n",
      "Batch 1000/1047\t Loss 0.000842\n",
      "epoch #36, train loss: 0.0008, train acc: 0.9976\n",
      "sel_samples/total: 12687/134000\n",
      "epoch #36, val loss: 0.0088, val acc: 0.7599\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000684\n",
      "Batch 200/1047\t Loss 0.000660\n",
      "Batch 300/1047\t Loss 0.000653\n",
      "Batch 400/1047\t Loss 0.000680\n",
      "Batch 500/1047\t Loss 0.000698\n",
      "Batch 600/1047\t Loss 0.000703\n",
      "Batch 700/1047\t Loss 0.000718\n",
      "Batch 800/1047\t Loss 0.000742\n",
      "Batch 900/1047\t Loss 0.000736\n",
      "Batch 1000/1047\t Loss 0.000743\n",
      "epoch #37, train loss: 0.0008, train acc: 0.9978\n",
      "sel_samples/total: 13168/134000\n",
      "epoch #37, val loss: 0.0087, val acc: 0.7637\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000581\n",
      "Batch 200/1047\t Loss 0.000543\n",
      "Batch 300/1047\t Loss 0.000579\n",
      "Batch 400/1047\t Loss 0.000579\n",
      "Batch 500/1047\t Loss 0.000598\n",
      "Batch 600/1047\t Loss 0.000596\n",
      "Batch 700/1047\t Loss 0.000577\n",
      "Batch 800/1047\t Loss 0.000570\n",
      "Batch 900/1047\t Loss 0.000568\n",
      "Batch 1000/1047\t Loss 0.000562\n",
      "epoch #38, train loss: 0.0006, train acc: 0.9986\n",
      "sel_samples/total: 13003/134000\n",
      "epoch #38, val loss: 0.0082, val acc: 0.7801\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000640\n",
      "Batch 200/1047\t Loss 0.000531\n",
      "Batch 300/1047\t Loss 0.000525\n",
      "Batch 400/1047\t Loss 0.000508\n",
      "Batch 500/1047\t Loss 0.000491\n",
      "Batch 600/1047\t Loss 0.000478\n",
      "Batch 700/1047\t Loss 0.000477\n",
      "Batch 800/1047\t Loss 0.000486\n",
      "Batch 900/1047\t Loss 0.000479\n",
      "Batch 1000/1047\t Loss 0.000469\n",
      "epoch #39, train loss: 0.0005, train acc: 0.9988\n",
      "sel_samples/total: 13298/134000\n",
      "epoch #39, val loss: 0.0078, val acc: 0.7824\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000371\n",
      "Batch 200/1047\t Loss 0.000309\n",
      "Batch 300/1047\t Loss 0.000312\n",
      "Batch 400/1047\t Loss 0.000330\n",
      "Batch 500/1047\t Loss 0.000345\n",
      "Batch 600/1047\t Loss 0.000356\n",
      "Batch 700/1047\t Loss 0.000348\n",
      "Batch 800/1047\t Loss 0.000346\n",
      "Batch 900/1047\t Loss 0.000346\n",
      "Batch 1000/1047\t Loss 0.000345\n",
      "epoch #40, train loss: 0.0003, train acc: 0.9993\n",
      "sel_samples/total: 13175/134000\n",
      "epoch #40, val loss: 0.0078, val acc: 0.7858\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000305\n",
      "Batch 200/1047\t Loss 0.000310\n",
      "Batch 300/1047\t Loss 0.000315\n",
      "Batch 400/1047\t Loss 0.000320\n",
      "Batch 500/1047\t Loss 0.000311\n",
      "Batch 600/1047\t Loss 0.000308\n",
      "Batch 700/1047\t Loss 0.000307\n",
      "Batch 800/1047\t Loss 0.000303\n",
      "Batch 900/1047\t Loss 0.000303\n",
      "Batch 1000/1047\t Loss 0.000300\n",
      "epoch #41, train loss: 0.0003, train acc: 0.9993\n",
      "sel_samples/total: 14289/134000\n",
      "epoch #41, val loss: 0.0075, val acc: 0.7911\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000260\n",
      "Batch 200/1047\t Loss 0.000263\n",
      "Batch 300/1047\t Loss 0.000237\n",
      "Batch 400/1047\t Loss 0.000226\n",
      "Batch 500/1047\t Loss 0.000239\n",
      "Batch 600/1047\t Loss 0.000241\n",
      "Batch 700/1047\t Loss 0.000236\n",
      "Batch 800/1047\t Loss 0.000233\n",
      "Batch 900/1047\t Loss 0.000234\n",
      "Batch 1000/1047\t Loss 0.000234\n",
      "epoch #42, train loss: 0.0002, train acc: 0.9995\n",
      "sel_samples/total: 14850/134000\n",
      "epoch #42, val loss: 0.0073, val acc: 0.7943\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000189\n",
      "Batch 200/1047\t Loss 0.000180\n",
      "Batch 300/1047\t Loss 0.000172\n",
      "Batch 400/1047\t Loss 0.000165\n",
      "Batch 500/1047\t Loss 0.000162\n",
      "Batch 600/1047\t Loss 0.000163\n",
      "Batch 700/1047\t Loss 0.000164\n",
      "Batch 800/1047\t Loss 0.000162\n",
      "Batch 900/1047\t Loss 0.000160\n",
      "Batch 1000/1047\t Loss 0.000160\n",
      "epoch #43, train loss: 0.0002, train acc: 0.9998\n",
      "sel_samples/total: 15663/134000\n",
      "epoch #43, val loss: 0.0071, val acc: 0.7987\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000139\n",
      "Batch 200/1047\t Loss 0.000138\n",
      "Batch 300/1047\t Loss 0.000139\n",
      "Batch 400/1047\t Loss 0.000132\n",
      "Batch 500/1047\t Loss 0.000131\n",
      "Batch 600/1047\t Loss 0.000126\n",
      "Batch 700/1047\t Loss 0.000125\n",
      "Batch 800/1047\t Loss 0.000126\n",
      "Batch 900/1047\t Loss 0.000127\n",
      "Batch 1000/1047\t Loss 0.000124\n",
      "epoch #44, train loss: 0.0001, train acc: 0.9998\n",
      "sel_samples/total: 17140/134000\n",
      "epoch #44, val loss: 0.0068, val acc: 0.8082\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000110\n",
      "Batch 200/1047\t Loss 0.000096\n",
      "Batch 300/1047\t Loss 0.000099\n",
      "Batch 400/1047\t Loss 0.000112\n",
      "Batch 500/1047\t Loss 0.000109\n",
      "Batch 600/1047\t Loss 0.000111\n",
      "Batch 700/1047\t Loss 0.000109\n",
      "Batch 800/1047\t Loss 0.000107\n",
      "Batch 900/1047\t Loss 0.000107\n",
      "Batch 1000/1047\t Loss 0.000105\n",
      "epoch #45, train loss: 0.0001, train acc: 0.9999\n",
      "sel_samples/total: 19455/134000\n",
      "epoch #45, val loss: 0.0067, val acc: 0.8079\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000081\n",
      "Batch 200/1047\t Loss 0.000080\n",
      "Batch 300/1047\t Loss 0.000078\n",
      "Batch 400/1047\t Loss 0.000080\n",
      "Batch 500/1047\t Loss 0.000080\n",
      "Batch 600/1047\t Loss 0.000082\n",
      "Batch 700/1047\t Loss 0.000080\n",
      "Batch 800/1047\t Loss 0.000079\n",
      "Batch 900/1047\t Loss 0.000078\n",
      "Batch 1000/1047\t Loss 0.000077\n",
      "epoch #46, train loss: 0.0001, train acc: 0.9999\n",
      "sel_samples/total: 22242/134000\n",
      "epoch #46, val loss: 0.0066, val acc: 0.8097\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000059\n",
      "Batch 200/1047\t Loss 0.000063\n",
      "Batch 300/1047\t Loss 0.000065\n",
      "Batch 400/1047\t Loss 0.000067\n",
      "Batch 500/1047\t Loss 0.000070\n",
      "Batch 600/1047\t Loss 0.000069\n",
      "Batch 700/1047\t Loss 0.000070\n",
      "Batch 800/1047\t Loss 0.000069\n",
      "Batch 900/1047\t Loss 0.000069\n",
      "Batch 1000/1047\t Loss 0.000069\n",
      "epoch #47, train loss: 0.0001, train acc: 0.9999\n",
      "sel_samples/total: 25565/134000\n",
      "epoch #47, val loss: 0.0065, val acc: 0.8112\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000057\n",
      "Batch 200/1047\t Loss 0.000058\n",
      "Batch 300/1047\t Loss 0.000056\n",
      "Batch 400/1047\t Loss 0.000054\n",
      "Batch 500/1047\t Loss 0.000057\n",
      "Batch 600/1047\t Loss 0.000057\n",
      "Batch 700/1047\t Loss 0.000058\n",
      "Batch 800/1047\t Loss 0.000057\n",
      "Batch 900/1047\t Loss 0.000057\n",
      "Batch 1000/1047\t Loss 0.000057\n",
      "epoch #48, train loss: 0.0001, train acc: 0.9999\n",
      "sel_samples/total: 30116/134000\n",
      "epoch #48, val loss: 0.0064, val acc: 0.8129\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000048\n",
      "Batch 200/1047\t Loss 0.000049\n",
      "Batch 300/1047\t Loss 0.000048\n",
      "Batch 400/1047\t Loss 0.000048\n",
      "Batch 500/1047\t Loss 0.000048\n",
      "Batch 600/1047\t Loss 0.000048\n",
      "Batch 700/1047\t Loss 0.000048\n",
      "Batch 800/1047\t Loss 0.000049\n",
      "Batch 900/1047\t Loss 0.000049\n",
      "Batch 1000/1047\t Loss 0.000049\n",
      "epoch #49, train loss: 0.0000, train acc: 0.9999\n",
      "sel_samples/total: 34858/134000\n",
      "epoch #49, val loss: 0.0063, val acc: 0.8146\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000043\n",
      "Batch 200/1047\t Loss 0.000042\n",
      "Batch 300/1047\t Loss 0.000044\n",
      "Batch 400/1047\t Loss 0.000044\n",
      "Batch 500/1047\t Loss 0.000044\n",
      "Batch 600/1047\t Loss 0.000044\n",
      "Batch 700/1047\t Loss 0.000044\n",
      "Batch 800/1047\t Loss 0.000044\n",
      "Batch 900/1047\t Loss 0.000044\n",
      "Batch 1000/1047\t Loss 0.000043\n",
      "epoch #50, train loss: 0.0000, train acc: 0.9999\n",
      "sel_samples/total: 40745/134000\n",
      "epoch #50, val loss: 0.0063, val acc: 0.8152\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000037\n",
      "Batch 400/1047\t Loss 0.000038\n",
      "Batch 500/1047\t Loss 0.000038\n",
      "Batch 600/1047\t Loss 0.000038\n",
      "Batch 700/1047\t Loss 0.000038\n",
      "Batch 800/1047\t Loss 0.000038\n",
      "Batch 900/1047\t Loss 0.000038\n",
      "Batch 1000/1047\t Loss 0.000039\n",
      "epoch #51, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 46606/134000\n",
      "epoch #51, val loss: 0.0062, val acc: 0.8169\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000039\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #52, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 53283/134000\n",
      "epoch #52, val loss: 0.0061, val acc: 0.8168\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #53, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 60526/134000\n",
      "epoch #53, val loss: 0.0061, val acc: 0.8198\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000031\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #54, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 67477/134000\n",
      "epoch #54, val loss: 0.0060, val acc: 0.8206\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000029\n",
      "Batch 200/1047\t Loss 0.000031\n",
      "Batch 300/1047\t Loss 0.000032\n",
      "Batch 400/1047\t Loss 0.000032\n",
      "Batch 500/1047\t Loss 0.000032\n",
      "Batch 600/1047\t Loss 0.000032\n",
      "Batch 700/1047\t Loss 0.000032\n",
      "Batch 800/1047\t Loss 0.000032\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #55, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 74649/134000\n",
      "epoch #55, val loss: 0.0060, val acc: 0.8207\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000032\n",
      "Batch 400/1047\t Loss 0.000032\n",
      "Batch 500/1047\t Loss 0.000032\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #56, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 81374/134000\n",
      "epoch #56, val loss: 0.0059, val acc: 0.8214\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000032\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #57, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 88143/134000\n",
      "epoch #57, val loss: 0.0059, val acc: 0.8212\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000031\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #58, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 94284/134000\n",
      "epoch #58, val loss: 0.0059, val acc: 0.8223\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #59, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 100484/134000\n",
      "epoch #59, val loss: 0.0059, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #60, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 105920/134000\n",
      "epoch #60, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "Batch 100/1047\t Loss 0.000038\n",
      "Batch 200/1047\t Loss 0.000037\n",
      "Batch 300/1047\t Loss 0.000038\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000037\n",
      "Batch 600/1047\t Loss 0.000037\n",
      "Batch 700/1047\t Loss 0.000037\n",
      "Batch 800/1047\t Loss 0.000037\n",
      "Batch 900/1047\t Loss 0.000037\n",
      "Batch 1000/1047\t Loss 0.000037\n",
      "epoch #61, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 110710/134000\n",
      "epoch #61, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000037\n",
      "Batch 200/1047\t Loss 0.000037\n",
      "Batch 300/1047\t Loss 0.000037\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000037\n",
      "Batch 600/1047\t Loss 0.000037\n",
      "Batch 700/1047\t Loss 0.000038\n",
      "Batch 800/1047\t Loss 0.000038\n",
      "Batch 900/1047\t Loss 0.000037\n",
      "Batch 1000/1047\t Loss 0.000038\n",
      "epoch #62, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 114398/134000\n",
      "epoch #62, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000037\n",
      "Batch 200/1047\t Loss 0.000037\n",
      "Batch 300/1047\t Loss 0.000037\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000037\n",
      "Batch 600/1047\t Loss 0.000037\n",
      "Batch 700/1047\t Loss 0.000037\n",
      "Batch 800/1047\t Loss 0.000037\n",
      "Batch 900/1047\t Loss 0.000037\n",
      "Batch 1000/1047\t Loss 0.000037\n",
      "epoch #63, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 116392/134000\n",
      "epoch #63, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000037\n",
      "Batch 300/1047\t Loss 0.000037\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000037\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000037\n",
      "Batch 900/1047\t Loss 0.000037\n",
      "Batch 1000/1047\t Loss 0.000037\n",
      "epoch #64, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 118649/134000\n",
      "epoch #64, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000038\n",
      "Batch 200/1047\t Loss 0.000037\n",
      "Batch 300/1047\t Loss 0.000037\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000037\n",
      "Batch 600/1047\t Loss 0.000037\n",
      "Batch 700/1047\t Loss 0.000037\n",
      "Batch 800/1047\t Loss 0.000037\n",
      "Batch 900/1047\t Loss 0.000037\n",
      "Batch 1000/1047\t Loss 0.000037\n",
      "epoch #65, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 120267/134000\n",
      "epoch #65, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000036\n",
      "Batch 400/1047\t Loss 0.000037\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000036\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #66, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 122144/134000\n",
      "epoch #66, val loss: 0.0058, val acc: 0.8225\n",
      "------------------------------\n",
      "curr_lr: 0.001\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000036\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #67, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 123776/134000\n",
      "epoch #67, val loss: 0.0058, val acc: 0.8225\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000036\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #68, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 125371/134000\n",
      "epoch #68, val loss: 0.0058, val acc: 0.8248\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000037\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000036\n",
      "Batch 400/1047\t Loss 0.000036\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000036\n",
      "Batch 700/1047\t Loss 0.000036\n",
      "Batch 800/1047\t Loss 0.000036\n",
      "Batch 900/1047\t Loss 0.000036\n",
      "Batch 1000/1047\t Loss 0.000036\n",
      "epoch #69, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 126345/134000\n",
      "epoch #69, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000036\n",
      "Batch 400/1047\t Loss 0.000036\n",
      "Batch 500/1047\t Loss 0.000036\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #70, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 126978/134000\n",
      "epoch #70, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #71, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 128150/134000\n",
      "epoch #71, val loss: 0.0058, val acc: 0.8243\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #72, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 128772/134000\n",
      "epoch #72, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 0.0001\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #73, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 129418/134000\n",
      "epoch #73, val loss: 0.0058, val acc: 0.8236\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #74, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 130199/134000\n",
      "epoch #74, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #75, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 130942/134000\n",
      "epoch #75, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000035\n",
      "epoch #76, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 130845/134000\n",
      "epoch #76, val loss: 0.0058, val acc: 0.8220\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #77, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 131722/134000\n",
      "epoch #77, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #78, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 131649/134000\n",
      "epoch #78, val loss: 0.0058, val acc: 0.8231\n",
      "------------------------------\n",
      "curr_lr: 1e-05\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #79, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 132575/134000\n",
      "epoch #79, val loss: 0.0058, val acc: 0.8233\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #80, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 132579/134000\n",
      "epoch #80, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #81, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 132516/134000\n",
      "epoch #81, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #82, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 132561/134000\n",
      "epoch #82, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #83, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133494/134000\n",
      "epoch #83, val loss: 0.0058, val acc: 0.8252\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #84, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133476/134000\n",
      "epoch #84, val loss: 0.0058, val acc: 0.8224\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-06\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #85, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133527/134000\n",
      "epoch #85, val loss: 0.0058, val acc: 0.8238\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #86, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133520/134000\n",
      "epoch #86, val loss: 0.0058, val acc: 0.8220\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #87, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133486/134000\n",
      "epoch #87, val loss: 0.0058, val acc: 0.8223\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #88, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133502/134000\n",
      "epoch #88, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #89, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133507/134000\n",
      "epoch #89, val loss: 0.0058, val acc: 0.8244\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #90, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133502/134000\n",
      "epoch #90, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000002e-07\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #91, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133478/134000\n",
      "epoch #91, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #92, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133512/134000\n",
      "epoch #92, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #93, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133514/134000\n",
      "epoch #93, val loss: 0.0058, val acc: 0.8251\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #94, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133524/134000\n",
      "epoch #94, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #95, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133515/134000\n",
      "epoch #95, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #96, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133497/134000\n",
      "epoch #96, val loss: 0.0058, val acc: 0.8249\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #97, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133502/134000\n",
      "epoch #97, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #98, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133472/134000\n",
      "epoch #98, val loss: 0.0058, val acc: 0.8233\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #99, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133487/134000\n",
      "epoch #99, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #100, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133548/134000\n",
      "epoch #100, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #101, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133516/134000\n",
      "epoch #101, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000037\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #102, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #102, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #103, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133542/134000\n",
      "epoch #103, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #104, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133473/134000\n",
      "epoch #104, val loss: 0.0058, val acc: 0.8234\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #105, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133501/134000\n",
      "epoch #105, val loss: 0.0058, val acc: 0.8238\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #106, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133482/134000\n",
      "epoch #106, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #107, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133495/134000\n",
      "epoch #107, val loss: 0.0058, val acc: 0.8234\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #108, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133524/134000\n",
      "epoch #108, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #109, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133535/134000\n",
      "epoch #109, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #110, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133507/134000\n",
      "epoch #110, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #111, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133510/134000\n",
      "epoch #111, val loss: 0.0058, val acc: 0.8229\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #112, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133492/134000\n",
      "epoch #112, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #113, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133486/134000\n",
      "epoch #113, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #114, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133474/134000\n",
      "epoch #114, val loss: 0.0058, val acc: 0.8233\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #115, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133520/134000\n",
      "epoch #115, val loss: 0.0058, val acc: 0.8236\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #116, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133531/134000\n",
      "epoch #116, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #117, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133516/134000\n",
      "epoch #117, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #118, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133482/134000\n",
      "epoch #118, val loss: 0.0058, val acc: 0.8225\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #119, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133457/134000\n",
      "epoch #119, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #120, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133474/134000\n",
      "epoch #120, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #121, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133519/134000\n",
      "epoch #121, val loss: 0.0058, val acc: 0.8244\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #122, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133502/134000\n",
      "epoch #122, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #123, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133515/134000\n",
      "epoch #123, val loss: 0.0058, val acc: 0.8242\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #124, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133489/134000\n",
      "epoch #124, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #125, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133508/134000\n",
      "epoch #125, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #126, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133478/134000\n",
      "epoch #126, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #127, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133511/134000\n",
      "epoch #127, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #128, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133510/134000\n",
      "epoch #128, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #129, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133485/134000\n",
      "epoch #129, val loss: 0.0058, val acc: 0.8224\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #130, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133513/134000\n",
      "epoch #130, val loss: 0.0058, val acc: 0.8224\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #131, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133490/134000\n",
      "epoch #131, val loss: 0.0058, val acc: 0.8240\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #132, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133486/134000\n",
      "epoch #132, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #133, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133497/134000\n",
      "epoch #133, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #134, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133496/134000\n",
      "epoch #134, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000032\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #135, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #135, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #136, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133488/134000\n",
      "epoch #136, val loss: 0.0058, val acc: 0.8243\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #137, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133536/134000\n",
      "epoch #137, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #138, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #138, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #139, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133507/134000\n",
      "epoch #139, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #140, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133547/134000\n",
      "epoch #140, val loss: 0.0058, val acc: 0.8240\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #141, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133489/134000\n",
      "epoch #141, val loss: 0.0058, val acc: 0.8245\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #142, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133499/134000\n",
      "epoch #142, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #143, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133512/134000\n",
      "epoch #143, val loss: 0.0058, val acc: 0.8234\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #144, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133528/134000\n",
      "epoch #144, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #145, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133513/134000\n",
      "epoch #145, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #146, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133511/134000\n",
      "epoch #146, val loss: 0.0058, val acc: 0.8233\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #147, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133532/134000\n",
      "epoch #147, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #148, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133527/134000\n",
      "epoch #148, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #149, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133491/134000\n",
      "epoch #149, val loss: 0.0058, val acc: 0.8231\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #150, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133493/134000\n",
      "epoch #150, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #151, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #151, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #152, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #152, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #153, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133492/134000\n",
      "epoch #153, val loss: 0.0058, val acc: 0.8230\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #154, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133492/134000\n",
      "epoch #154, val loss: 0.0058, val acc: 0.8229\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #155, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133506/134000\n",
      "epoch #155, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000031\n",
      "Batch 200/1047\t Loss 0.000032\n",
      "Batch 300/1047\t Loss 0.000032\n",
      "Batch 400/1047\t Loss 0.000032\n",
      "Batch 500/1047\t Loss 0.000032\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #156, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133508/134000\n",
      "epoch #156, val loss: 0.0058, val acc: 0.8229\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #157, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133509/134000\n",
      "epoch #157, val loss: 0.0058, val acc: 0.8242\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #158, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #158, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #159, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133482/134000\n",
      "epoch #159, val loss: 0.0058, val acc: 0.8227\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #160, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133501/134000\n",
      "epoch #160, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #161, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133510/134000\n",
      "epoch #161, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #162, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133471/134000\n",
      "epoch #162, val loss: 0.0058, val acc: 0.8242\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #163, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133484/134000\n",
      "epoch #163, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #164, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133493/134000\n",
      "epoch #164, val loss: 0.0058, val acc: 0.8240\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #165, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133465/134000\n",
      "epoch #165, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #166, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133532/134000\n",
      "epoch #166, val loss: 0.0058, val acc: 0.8224\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #167, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133501/134000\n",
      "epoch #167, val loss: 0.0058, val acc: 0.8244\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #168, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133505/134000\n",
      "epoch #168, val loss: 0.0058, val acc: 0.8251\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #169, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133497/134000\n",
      "epoch #169, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #170, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133499/134000\n",
      "epoch #170, val loss: 0.0058, val acc: 0.8246\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #171, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133487/134000\n",
      "epoch #171, val loss: 0.0058, val acc: 0.8243\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #172, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133510/134000\n",
      "epoch #172, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #173, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133496/134000\n",
      "epoch #173, val loss: 0.0058, val acc: 0.8243\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #174, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133504/134000\n",
      "epoch #174, val loss: 0.0058, val acc: 0.8241\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #175, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133498/134000\n",
      "epoch #175, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #176, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133519/134000\n",
      "epoch #176, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #177, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133485/134000\n",
      "epoch #177, val loss: 0.0058, val acc: 0.8246\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000036\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000035\n",
      "Batch 800/1047\t Loss 0.000035\n",
      "Batch 900/1047\t Loss 0.000035\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #178, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133512/134000\n",
      "epoch #178, val loss: 0.0058, val acc: 0.8238\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #179, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133526/134000\n",
      "epoch #179, val loss: 0.0058, val acc: 0.8229\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000035\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000035\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #180, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133468/134000\n",
      "epoch #180, val loss: 0.0058, val acc: 0.8234\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #181, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133472/134000\n",
      "epoch #181, val loss: 0.0058, val acc: 0.8246\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #182, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133492/134000\n",
      "epoch #182, val loss: 0.0058, val acc: 0.8233\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #183, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133518/134000\n",
      "epoch #183, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #184, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133489/134000\n",
      "epoch #184, val loss: 0.0058, val acc: 0.8226\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #185, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133492/134000\n",
      "epoch #185, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #186, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133517/134000\n",
      "epoch #186, val loss: 0.0058, val acc: 0.8232\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #187, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133511/134000\n",
      "epoch #187, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #188, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133463/134000\n",
      "epoch #188, val loss: 0.0058, val acc: 0.8239\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000035\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #189, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133488/134000\n",
      "epoch #189, val loss: 0.0058, val acc: 0.8238\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #190, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133484/134000\n",
      "epoch #190, val loss: 0.0058, val acc: 0.8228\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #191, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133525/134000\n",
      "epoch #191, val loss: 0.0058, val acc: 0.8243\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #192, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133473/134000\n",
      "epoch #192, val loss: 0.0058, val acc: 0.8236\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000035\n",
      "Batch 200/1047\t Loss 0.000035\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #193, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133505/134000\n",
      "epoch #193, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #194, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133489/134000\n",
      "epoch #194, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000032\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #195, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133494/134000\n",
      "epoch #195, val loss: 0.0058, val acc: 0.8237\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000036\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #196, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133446/134000\n",
      "epoch #196, val loss: 0.0058, val acc: 0.8234\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000034\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000034\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #197, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133500/134000\n",
      "epoch #197, val loss: 0.0058, val acc: 0.8235\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000033\n",
      "Batch 200/1047\t Loss 0.000033\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000033\n",
      "Batch 500/1047\t Loss 0.000033\n",
      "Batch 600/1047\t Loss 0.000033\n",
      "Batch 700/1047\t Loss 0.000033\n",
      "Batch 800/1047\t Loss 0.000033\n",
      "Batch 900/1047\t Loss 0.000033\n",
      "Batch 1000/1047\t Loss 0.000033\n",
      "epoch #198, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133502/134000\n",
      "epoch #198, val loss: 0.0058, val acc: 0.8222\n",
      "------------------------------\n",
      "curr_lr: 1.0000000000000004e-08\n",
      "Batch 100/1047\t Loss 0.000034\n",
      "Batch 200/1047\t Loss 0.000034\n",
      "Batch 300/1047\t Loss 0.000033\n",
      "Batch 400/1047\t Loss 0.000034\n",
      "Batch 500/1047\t Loss 0.000035\n",
      "Batch 600/1047\t Loss 0.000034\n",
      "Batch 700/1047\t Loss 0.000034\n",
      "Batch 800/1047\t Loss 0.000034\n",
      "Batch 900/1047\t Loss 0.000034\n",
      "Batch 1000/1047\t Loss 0.000034\n",
      "epoch #199, train loss: 0.0000, train acc: 1.0000\n",
      "sel_samples/total: 133503/134000\n",
      "epoch #199, val loss: 0.0058, val acc: 0.8232\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "from sklearn.metrics import roc_curve\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss(reduce=False)\n",
    "plateau_scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "step_scheduler = MultiStepLR(optimizer, [30], 0.1)\n",
    "\n",
    "k = 6\n",
    "\n",
    "for epoch_idx in range(0, config['n_epochs']):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "    \n",
    "    n_sel_samples = 0\n",
    "# =============== train code #===============\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(dev_train_dataloader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        ### spl masking\n",
    "        spl_mask = loss.gt(k)\n",
    "        masked_loss = torch.masked_select(loss, spl_mask).mean()\n",
    "        n_sel_samples += spl_mask.sum().item()\n",
    "        masked_loss.backward()\n",
    "        optimizer.step()\n",
    "                        \n",
    "        loss_sum += masked_loss.item()\n",
    "        n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            print(\"Batch {}/{}\\t Loss {:.6f}\" \\\n",
    "                  .format(batch_idx+1, len(dev_train_dataloader), loss_sum / total))\n",
    "    train_loss = loss_sum / total\n",
    "    train_acc = n_corrects / total\n",
    "    plateau_scheduler.step(train_loss)\n",
    "    \n",
    "    print(\"epoch #{}, train loss: {:.4f}, train acc: {:.4f}\".format(epoch_idx, train_loss, train_acc))\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch_idx+1)\n",
    "    writer.add_scalar(\"train/acc\", train_acc, epoch_idx+1)\n",
    "    \n",
    "    k = k/1.2\n",
    "    print(\"sel_samples/total: {}/{}\".format(n_sel_samples, total))\n",
    "\n",
    "#=============== dev_val code #===============\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        loss_sum += loss.mean().item()\n",
    "        n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "    val_loss = loss_sum / total\n",
    "    val_acc = n_corrects / total\n",
    "    \n",
    "    \n",
    "    print(\"epoch #{}, val loss: {:.4f}, val acc: {:.4f}\".format(epoch_idx, val_loss, val_acc))\n",
    "    writer.add_scalar(\"val/loss\", val_loss, epoch_idx+1)\n",
    "    writer.add_scalar(\"val/acc\", val_acc, epoch_idx+1)\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See, Fr features\n",
    "fr_feats = []\n",
    "model.eval()\n",
    "total = 0\n",
    "for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "    if not config['no_cuda']:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    fr_feat = model.fr_feat(X).cpu().detach()\n",
    "    fr_feats.append(fr_feat)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Freeze Model & FineTurne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "freezed_params = []\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param_name not in ['classifier.2.weight', 'classifier.2.bias']:\n",
    "        freezed_params.append(param)\n",
    "        \n",
    "for param in freezed_params:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #0, train loss: 0.0219, train acc: 0.9818\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #1, train loss: 0.0217, train acc: 0.9818\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #2, train loss: 0.0214, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #3, train loss: 0.0210, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #4, train loss: 0.0206, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #5, train loss: 0.0202, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #6, train loss: 0.0198, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #7, train loss: 0.0194, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #8, train loss: 0.0190, train acc: 0.9848\n",
      "------------------------------\n",
      "curr_lr: 0.01\n",
      "epoch #9, train loss: 0.0186, train acc: 0.9848\n"
     ]
    }
   ],
   "source": [
    "# =============== fine_tune code #===============\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
    "for epoch_idx in range(0, 10):\n",
    "    print(\"-\"*30)\n",
    "    curr_lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    print(\"curr_lr: {}\".format(curr_lr))\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    n_corrects = 0\n",
    "    total = 0\n",
    "    for batch_idx, (X, y) in enumerate(held_out_train_dataloader):\n",
    "        if not config['no_cuda']:\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logit = model(X)\n",
    "        loss = criterion(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_sum += loss.item()\n",
    "        n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "        total += y.size(0)\n",
    "    #         if (batch_idx+1) % 1000 == 0:\n",
    "    #             print(\"Batch {}/{}\\t Loss {:.6f}\" \\\n",
    "    #                   .format(batch_idx+1, len(si_loader), loss_sum / total))\n",
    "    train_loss = loss_sum / total\n",
    "    train_acc = n_corrects / total\n",
    "\n",
    "    print(\"epoch #{}, train loss: {:.4f}, train acc: {:.4f}\".format(epoch_idx, train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-73438e0851f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#=============== dev_val code #===============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#=============== dev_val code #===============\n",
    "model.eval()\n",
    "loss_sum = 0\n",
    "n_corrects = 0\n",
    "total = 0\n",
    "for batch_idx, (X, y) in enumerate(dev_val_dataloader):\n",
    "    if not config['no_cuda']:\n",
    "        X = X.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "    logit = model(X)\n",
    "    loss = criterion(logit, y)\n",
    "    loss_sum += loss.item()\n",
    "    n_corrects += logit.max(1)[1].eq(y).sum().item()\n",
    "    total += y.size(0)\n",
    "val_loss = loss_sum / total\n",
    "val_acc = n_corrects / total\n",
    "print(\"epoch #{}, val loss: {:.4f}, val acc: {:.4f}\".format(epoch_idx, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SV Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA on embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "global_mean = si_embeds.mean(0)\n",
    "clf = LDA(solver='svd', n_components=200)\n",
    "clf.fit(si_embeds - global_mean, si_key_df.label)\n",
    "\n",
    "si_embeds = clf.transform(si_embeds - global_mean).astype(np.float32)\n",
    "\n",
    "sv_embeds = clf.transform(sv_embeds - global_mean).astype(np.float32)\n",
    "\n",
    "si_dataset, embed_dim, n_labels = embedToDataset(si_embeds.reshape(-1,200), si_key_df)\n",
    "sv_dataset, _, _ = embedToDataset(sv_embeds, sv_key_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
