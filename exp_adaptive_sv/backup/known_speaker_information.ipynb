{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# known_speaker_information\n",
    "\n",
    "SI network에는 학습에 사용되었던 speaker들의 정보가 녹아져있다.\n",
    "\n",
    "특히 마지막 linear layer는 각 speaker에 대한 agent들로 이루어져 있다.\n",
    "\n",
    "과연 새로운 unknown speaker가 나타났을 때 기존 speaker들과 어떤 연관이 있을 수 있을까?\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 speaker와의 연관성은 그냥 logit을 구하면 나온다. \n",
    "\n",
    "logit의 값들이 학습에 사용된 스피커와의 연관성이라고 생각하면된다.  \n",
    "\n",
    "*ResNet34_v4_softmax_best.pth.tar* 기준으로 embeding layer로는 EER이 5.35\n",
    "\n",
    "마지막 logit으로 구했을 때는 5.72로 나빠진다.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sv_set에 있는 speaker들은 logit을 구했을떄 max 값을 가지는 speaker들의 수가 많다.\n",
    "\n",
    "![img](https://trello-attachments.s3.amazonaws.com/5bac5ccd23298141e2fcbedc/5bab882710e5cc1022669618/dca15a2b2de87efd907a20546bf606b3/image.png)\n",
    "\n",
    "반대로 si_set의 validation set에 대해서는 적다.\n",
    "\n",
    "![img2](https://trello-attachments.s3.amazonaws.com/5bac5ccd23298141e2fcbedc/5bab882710e5cc1022669618/0c6f83113718cbef5c29d58dbeed1a60/image.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 sv embedding들을 last_weight(마지막 fc layer)와 cosine similarity를 구했을 때\n",
    "대단히 낮은 값들이 나왔다.\n",
    "\n",
    "즉 close-set의 스피커들은 hard negative sample이 될 수 없다.\n",
    "\n",
    "![image.png](https://trello-attachments.s3.amazonaws.com/5bac5ccd23298141e2fcbedc/5bab882710e5cc1022669618/995fade5b9af23ec605e0d609e236714/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import set_train_config\n",
    "import easydict\n",
    "\n",
    "# datasets\n",
    "# voxc1_fbank_xvector\n",
    "# gcommand_fbank_xvector\n",
    "\n",
    "args = easydict.EasyDict(dict(dataset=\"voxc1_fbank_xvector\",\n",
    "                              input_frames=800, splice_frames=[300, 800], stride_frames=1, input_format='fbank',\n",
    "                              cuda=True,\n",
    "                              lrs=[0.1, 0.01], lr_schedule=[20], seed=1337,\n",
    "                              no_eer=False,\n",
    "                              batch_size=128,\n",
    "                              arch=\"ResNet34_v4\", loss=\"softmax\",\n",
    "                              n_epochs=50\n",
    "                             ))\n",
    "config = set_train_config(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.data_utils import find_dataset, find_trial\n",
    "\n",
    "_, datasets = find_dataset(config, basedir='../')\n",
    "trial = find_trial(config, basedir='../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_loaders\n",
    "\n",
    "dataloaders = init_loaders(config, datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.model.model_utils import find_model\n",
    "config['n_labels'] = 1260\n",
    "model = find_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_cuda']:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "saved_model = torch.load(\"../best_models/voxc1/ResNet34_v4_softmax/ResNet34_v4_softmax_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04956873602385262"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model[\"best_metric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(saved_model['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_w = model.output.weight.cpu().detach().t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.train.train_utils import set_seed, find_optimizer\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "criterion, optimizer = find_optimizer(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['no_eer']:\n",
    "    train_loader, val_loader, test_loader, sv_loader = dataloaders\n",
    "else:\n",
    "    train_loader, val_loader, test_loader = dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def embeds_utterance(config, val_dataloader, model):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            X, y = batch\n",
    "            if not config['no_cuda']:\n",
    "                X = X.cuda()\n",
    "                \n",
    "            model_output = model.embed(X).cpu().detach()\n",
    "            embeddings.append(model_output)\n",
    "            labels.append(y.numpy())\n",
    "        embeddings = torch.cat(embeddings)\n",
    "        labels = np.hstack(labels)\n",
    "    return embeddings, labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_embeddings, labels = embeds_utterance(config, val_loader, model)\n",
    "test_embeddings, labels = embeds_utterance(config, sv_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_embeddings, open(\"../best_models/voxc1/ResNet34_v3_angular/test_embeddings.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastw_sim = torch.matmul(test_embeddings, last_w.t()).numpy()\n",
    "# lastw_sim = F.cosine_similarity(test_embeddings.unsqueeze(1), last_w.unsqueeze(0), dim=2).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame(lastw_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df = pd.read_pickle(\"../dataset/dataframes/voxc1/sv_voxc_dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df['spk'] = sv_df['spk'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spk\n",
       "Eartha_Kitt          [568, 746, 805, 1088, 276, 594, 167, 637, 303,...\n",
       "Ed_Westwick          [321, 990, 442, 893, 1141, 313, 1129, 314, 284...\n",
       "Eddie_Griffin        [904, 1089, 1060, 910, 936, 913, 863, 356, 965...\n",
       "Eddie_Izzard         [767, 936, 951, 866, 139, 346, 3, 1089, 1140, ...\n",
       "Eddie_Kaye_Thomas    [1027, 202, 989, 760, 345, 406, 923, 710, 520,...\n",
       "Eddie_McClintock     [413, 453, 523, 1132, 1141, 745, 528, 955, 893...\n",
       "Edgar_Wright         [1056, 139, 425, 635, 1111, 1142, 961, 953, 71...\n",
       "Eduardo_Noriega      [293, 482, 1171, 119, 894, 1125, 938, 462, 300...\n",
       "Edward_Asner         [1081, 95, 107, 711, 304, 115, 1014, 520, 479,...\n",
       "Efren_Ramirez        [893, 590, 255, 523, 635, 719, 494, 287, 1034,...\n",
       "Elaine_Cassidy       [36, 846, 645, 1209, 575, 292, 568, 832, 851, ...\n",
       "Elaine_Hendrix       [146, 316, 393, 975, 779, 31, 1111, 998, 333, ...\n",
       "Eleanor_Tomlinson    [562, 815, 779, 645, 846, 586, 110, 542, 339, ...\n",
       "Eli_Roth             [1189, 52, 595, 678, 1056, 635, 980, 495, 363,...\n",
       "Eli_Wallach          [327, 1111, 912, 1057, 1170, 942, 530, 728, 14...\n",
       "Elisabeth_Moss       [838, 779, 681, 389, 829, 60, 746, 31, 438, 85...\n",
       "Elle_Fanning         [272, 829, 129, 961, 596, 373, 756, 706, 392, ...\n",
       "Ellen_Burstyn        [432, 829, 981, 1057, 251, 36, 717, 148, 956, ...\n",
       "Ellen_Wong                             [829, 1088, 1031, 35, 438, 431]\n",
       "Elodie_Yung          [346, 703, 813, 1119, 851, 429, 846, 618, 1168...\n",
       "Emile_Hirsch         [1066, 953, 495, 3, 1034, 519, 173, 386, 373, ...\n",
       "Emily_Atack          [846, 292, 129, 575, 1117, 470, 272, 568, 353,...\n",
       "Emraan_Hashmi        [936, 2, 352, 1132, 865, 523, 186, 322, 511, 1...\n",
       "Eoin_Macken          [910, 874, 951, 15, 738, 865, 1116, 710, 8, 76...\n",
       "Eric_Braeden         [1054, 202, 1070, 1141, 1194, 1116, 929, 211, ...\n",
       "Eric_Dane            [520, 952, 379, 314, 494, 600, 1013, 865, 1026...\n",
       "Eric_McCormack       [923, 244, 15, 338, 863, 406, 936, 453, 1132, ...\n",
       "Eric_Roberts         [1082, 406, 734, 324, 10, 89, 115, 1071, 1078,...\n",
       "Erik_Estrada         [55, 734, 202, 863, 923, 892, 491, 1169, 300, ...\n",
       "Erin_Andrews         [851, 297, 110, 681, 746, 846, 316, 1113, 131,...\n",
       "Ernest_Borgnine      [1081, 202, 811, 402, 372, 771, 488, 1064, 117...\n",
       "Ernie_Hudson         [493, 425, 764, 1027, 396, 150, 520, 765, 732,...\n",
       "Esai_Morales         [143, 218, 872, 212, 462, 818, 226, 1194, 280,...\n",
       "Estelle_Harris       [189, 91, 706, 1148, 904, 166, 539, 1004, 1089...\n",
       "Eugene_Levy          [235, 256, 904, 965, 1182, 1137, 63, 380, 139,...\n",
       "Eugenio_Derbez       [863, 953, 300, 139, 520, 1171, 936, 1026, 114...\n",
       "Eva_Green            [36, 312, 330, 975, 846, 542, 851, 91, 548, 33...\n",
       "Eva_Longoria         [1004, 288, 706, 1042, 872, 681, 702, 904, 392...\n",
       "Evanna_Lynch         [829, 163, 258, 788, 1160, 1088, 339, 586, 588...\n",
       "Ezra_Miller          [1111, 989, 953, 590, 818, 923, 1019, 519, 111...\n",
       "dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df.groupby(\"spk\").idxmax(axis=1).groupby('spk').unique()\n",
    "# sim_df.groupby(\"spk\").idxmax(axis=1).groupby(\"spk\").apply(lambda x: x.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute EER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def sv_test(config, sv_loader, model, trial):\n",
    "        if isinstance(model, torch.nn.DataParallel):\n",
    "            model_t = model.module\n",
    "        else:\n",
    "            model_t = model\n",
    "\n",
    "        embeddings, _ = embeds_utterance(config, sv_loader, model_t)\n",
    "        sim_matrix = F.cosine_similarity(\n",
    "                embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=2)\n",
    "        cord = [trial.enrolment_id.tolist(), trial.test_id.tolist()]\n",
    "        score_vector = sim_matrix[cord].numpy()\n",
    "        label_vector = np.array(trial.label)\n",
    "        fpr, tpr, thres = roc_curve(\n",
    "                label_vector, score_vector, pos_label=1)\n",
    "        eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "\n",
    "        return eer, label_vector, score_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.data_utils import find_trial\n",
    "trial = find_trial(config, basedir=\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.053561920988180176,\n",
       " array([1, 0, 1, ..., 0, 1, 0]),\n",
       " array([0.8261922, 0.5786556, 0.8692004, ..., 0.5851219, 0.8255653,\n",
       "        0.6215607], dtype=float32))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_test(config, sv_loader, model, trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
