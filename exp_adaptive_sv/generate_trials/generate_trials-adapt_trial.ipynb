{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Ernollment Trial with voxceleb1\n",
    "---------\n",
    "\n",
    "trial 길이가 충분히 긴 set을 만들고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sv_system import get_embeds, cosine_sim, compute_plda_score\n",
    "from utils import key2df, df2dict, get_id2idx\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm  import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voxc1_df['label'] = voxc1_df.groupby('spk').ngroup().values\n",
    "# voxc1_df = voxc1_df.sort_values('id').reset_index(drop=True)\n",
    "# voxc1_df = voxc1_df.fillna('test')\n",
    "# voxc1_meta = pd.read_pickle(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_meta.pkl\")\n",
    "# spk2gender = voxc1_meta.Gender.to_dict()\n",
    "# voxc1_df['gender'] = voxc1_df.spk.apply(lambda x: spk2gender[x])\n",
    "# voxc1_df.to_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1.csv\", index=False)\n",
    "\n",
    "# voxc1_dev_df = voxc1_df[voxc1_df.spk.isin(dev_spks)]\n",
    "# voxc1_eval_df = voxc1_df[voxc1_df.spk.isin(eval_spks)]\n",
    "# voxc1_dev_df.to_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_dev.csv\", index=False)\n",
    "# voxc1_eval_df.to_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1.csv\")\n",
    "spk_uttr_stat = voxc1_df.spk.value_counts()\n",
    "voxc1_meta = pd.read_pickle(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_meta.pkl\")\n",
    "spk2gender = voxc1_meta.Gender.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import key2df\n",
    "\n",
    "embed_dir = \"../embeddings/voxc2_fbank64_voxc2untied_xvector/\"\n",
    "sv_embeds = np.load(embed_dir+\"ln_lda_sv_embeds.npy\")\n",
    "sv_keys = pickle.load(open(embed_dir + \"/sv_keys.pkl\", \"rb\"))\n",
    "sv_id2idx = get_id2idx(sv_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sv_system import compute_plda_score\n",
    "kaldi_plda_model = embed_dir+\"plda_train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioffe_plda.verifier import Verifier\n",
    "py_plda_model = Verifier()\n",
    "py_plda_model = Verifier(pickle.load(open(\"../py_plda_model_ln_lda.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-out Developement set\n",
    "\n",
    "utterance가 150개 이상인 화자들을 evaluation spks로 빼고 나머지는 developement spk로 빼었다.  \n",
    "그리고 developement spk 음성을 이용해서 threshold를 정하기 위한 trial을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_spks = spk_uttr_stat[(spk_uttr_stat < 150)].index.tolist()\n",
    "dev_uttrs = voxc1_df[voxc1_df.spk.isin(dev_spks)][['id', 'spk', 'gender', 'session']]\n",
    "eval_spks = spk_uttr_stat[spk_uttr_stat >= 150].index.tolist()\n",
    "eval_uttrs = voxc1_df[voxc1_df.spk.isin(eval_spks)][['id', 'spk', 'gender', 'session']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of dev spks: 940\n",
      "number of eval spks: 311\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of dev spks: {len(dev_spks)}\")\n",
    "print(f\"number of eval spks: {len(eval_spks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cohort Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_ids = dev_uttrs.groupby(\"spk\", group_keys=False).apply(lambda x: x.sample(n=20)).id\n",
    "np.save(\"trials/dev940_eval311/dev_cohort_ids.npy\", np.array(cohort_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev trials for eT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc2_trial = pd.read_pickle(\"../trials/voxc2_1211_trials.pkl\")\n",
    "trial_for_thresh = voxc2_trial[(voxc2_trial.enroll_spk.isin(dev_spks)) \n",
    "                               & (voxc2_trial.test_spk.isin(dev_spks))]\n",
    "\n",
    "dev_trials = trial_for_thresh[[\"enroll_idx\", \"test_idx\", \"label\"]]\n",
    "dev_trials.columns = [\"enr_id\", \"test_id\", \"label\"]\n",
    "dev_trials = dev_trials.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_trials.to_pickle(\"../trials/dev940_eval311/dev_original_trials.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    157309\n",
       "0     85172\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_trials.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Target trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "dev_combs = dev_uttrs.groupby(\"spk\", group_keys=False).apply(lambda x: itertools.combinations(x.id, 2))\n",
    "dev_target_trials = []\n",
    "for comb in dev_combs:\n",
    "    dev_target_trials += list(comb)\n",
    "\n",
    "dev_target_trial_df = pd.DataFrame(dev_target_trials, columns=['enr', 'tst'])\n",
    "dev_target_trial_set = dev_target_trial_df.groupby('enr', group_keys=False).apply(\n",
    "    lambda x: list(x.tst)).to_dict()\n",
    "# pickle.dump(dev_target_trial_set, open(\"trials/dev940_eval311/dev_target_trials.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82141"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_target_trial_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_target_adapt = 150\n",
    "adapt_uttrs = eval_uttrs.groupby(\"spk\", group_keys=False).apply(lambda x: x.sample(n=n_target_adapt))\n",
    "test_uttrs = eval_uttrs.drop(index=adapt_uttrs.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter speaker scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_embeds = []\n",
    "for spk in eval_spks:\n",
    "    embeds = get_embeds(eval_uttrs[eval_uttrs.spk == spk].id, sv_embeds, sv_id2idx, norm=False).mean(0)\n",
    "    spk_embeds.append(embeds)\n",
    "\n",
    "spk_embeds = np.stack(spk_embeds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_spk_scores = py_plda_model.score_avg(spk_embeds, spk_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spaker similarity sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_groups = np.argsort(inter_spk_scores, axis=1)[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_idx = 0\n",
    "close_spk_idx = sorted_groups[spk_idx][-10:]\n",
    "close_spks = np.array(eval_spks)[close_spk_idx]\n",
    "inter_spk_scores[spk_idx][close_spk_idx]\n",
    "hard_neg_embeds = get_embeds(eval_uttrs[eval_uttrs.spk.isin(close_spks)].id, sv_embeds, sv_id2idx, norm=False)\n",
    "hard_neg_scores = py_plda_model.multi_sess(spk_embeds[spk_idx], hard_neg_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.70471, -2.00652, -1.07242, ..., -7.32827, -1.32971, -4.01678]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_neg_scores[-1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speaker clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster_model = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')\n",
    "cluster_ids = cluster_model.fit_predict(inter_spk_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([54, 29, 50, 50, 38, 25, 18, 12, 28,  7]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cluster_ids, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/311 [00:00<?, ?it/s]/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "100%|██████████| 311/311 [01:01<00:00,  5.09it/s]\n"
     ]
    }
   ],
   "source": [
    "n_enr = 3 \n",
    "n_repeat_enr = 5\n",
    "l_trial = 300\n",
    "p_tar = 0.1\n",
    "\n",
    "adapt_trials = []\n",
    "\n",
    "for spk_idx, adapt_spk in tqdm(enumerate(eval_spks), total=len(eval_spks)):\n",
    "    # target and nontarget utterances\n",
    "    target_uttrs = adapt_uttrs[adapt_uttrs.spk == adapt_spk]\n",
    "    target_uttrs.loc[:, 'label'] = 1\n",
    "    \n",
    "    # cluster based nontarget pool\n",
    "    own_id = cluster_ids[spk_idx]\n",
    "    nonTarget_spks = np.array(eval_spks)[cluster_ids==own_id]\n",
    "    nonTarget_spks = set(nonTarget_spks) - set([adapt_spk]) \n",
    "    nonTarget_adapt_uttrs = adapt_uttrs[adapt_uttrs.spk.isin(nonTarget_spks)]\n",
    "    nonTarget_adapt_uttrs.loc[:, 'label'] = 0\n",
    "    # enrollment set\n",
    "    enr_uttrs_set = target_uttrs.sample(n=n_enr*n_repeat_enr, replace=True)\n",
    "    target_adapt_uttrs = target_uttrs.drop(index=enr_uttrs_set.index)\n",
    "    \n",
    "    for idx in range(0, len(enr_uttrs_set), n_enr):\n",
    "        enr_uttrs = enr_uttrs_set[idx:idx+n_enr]\n",
    "        \n",
    "        # number of targets and nontargets\n",
    "        n_adapt_target_uttrs = int(l_trial * p_tar)\n",
    "        target_adapt_uttrs_ = target_adapt_uttrs.sample(n=n_adapt_target_uttrs)\n",
    "        n_nonTargets = l_trial - n_adapt_target_uttrs\n",
    "        \n",
    "        nonTarget_idx = np.random.choice(np.arange(len(nonTarget_adapt_uttrs)), size=n_nonTargets, replace=False)\n",
    "        nonTarget_adapt_uttrs_ = nonTarget_adapt_uttrs.iloc[nonTarget_idx]\n",
    "\n",
    "        adapt_trial = pd.concat([target_adapt_uttrs_, nonTarget_adapt_uttrs_])\n",
    "        adapt_trial = adapt_trial.sample(frac=1.0)\n",
    "        adapt_trials += [({'spk':adapt_spk, \"p_tar\":p_tar}, np.array(enr_uttrs.id), adapt_trial)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(adapt_trials, open(f\"../trials/dev940_eval311/split_trials/adapt_len{l_trial}_enr{n_enr}_ptar{p_tar}_cluster_trials.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt+Test trials\n",
    "\n",
    "이전처럼 adapt와 test trial을 같이 생성한다.\n",
    "그래야 실제 환경에 더 맞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/311 [00:00<?, ?it/s]/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-278-5fc3e4fe15ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m### Adapt target and nonTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mn_adapt_target_uttrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_trial\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_tar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtarget_adapt_uttrs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_adapt_uttrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_adapt_target_uttrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mn_nonTargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_trial\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_adapt_target_uttrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4195\u001b[0m                              \"provide positive value.\")\n\u001b[1;32m   4196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4197\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "n_enr = 1 \n",
    "n_repeat_enr = 1\n",
    "l_trial = 1000\n",
    "p_tar = 0.1\n",
    "p_hard = 0.9\n",
    "\n",
    "adapt_trials = []\n",
    "\n",
    "for adapt_spk in tqdm(eval_spks, total=len(eval_spks)):\n",
    "    target_uttrs = target_adapt_trials[target_adapt_trials.spk == adapt_spk]\n",
    "    target_uttrs.loc[:, 'label'] = 1\n",
    "    nonTarget_adapt_uttrs = target_adapt_trials[target_adapt_trials.spk != adapt_spk]\n",
    "    nonTarget_adapt_uttrs.loc[:, 'label'] = 0\n",
    "    \n",
    "    enr_uttrs_set = target_uttrs.sample(n=n_enr*n_repeat_enr, replace=True)\n",
    "    target_adapt_uttrs = target_uttrs.drop(index=enr_uttrs_set.index)\n",
    "    for idx in range(0, len(enr_uttrs_set), n_enr):\n",
    "        enr_uttrs = enr_uttrs_set[idx:idx+n_enr]\n",
    "        \n",
    "        ### Adapt target and nonTarget\n",
    "        n_adapt_target_uttrs = int(l_trial * p_tar)\n",
    "        target_adapt_uttrs_ = target_adapt_uttrs.sample(n=n_adapt_target_uttrs)\n",
    "        \n",
    "        n_nonTargets = l_trial - n_adapt_target_uttrs\n",
    "        n_hard_nonTargets = np.ceil(n_nonTargets * p_hard).astype(np.int64)\n",
    "        n_random_nonTargets = n_nonTargets - n_hard_nonTargets\n",
    "        \n",
    "        if n_hard_nonTargets > 0:\n",
    "            # init_enroll dependent hard trials\n",
    "            enr_embeds = get_embeds(enr_uttrs.id, sv_embeds, sv_id2idx, norm=False)\n",
    "            nonTarget_test_embeds = get_embeds(nonTarget_adapt_uttrs.id, sv_embeds, sv_id2idx, norm=False)\n",
    "            nonTarget_scores = py_plda_model.multi_sess(enr_embeds, nontarget_test_embeds, cov_scaling=True).mean(0)\n",
    "            nonTarget_sorted_idx = np.argsort(nonTarget_scores)\n",
    "            nonTarget_hard_idx = nonTarget_sorted_idx[-n_hard_nonTargets:]\n",
    "            nonTarget_random_idx = np.random.choice(nonTarget_sorted_idx[:-n_hard_nonTargets], size=n_random_nonTargets, replace=False)\n",
    "            nonTarget_idx = np.concatenate([nonTarget_hard_idx, nonTarget_random_idx])\n",
    "            \n",
    "            # spk depentdent hard trials\n",
    "        else:\n",
    "            nonTarget_idx = np.random.choice(np.arange(len(nonTarget_adapt_uttrs)), size=n_random_nonTargets, replace=False)\n",
    "\n",
    "        nonTarget_adapt_uttrs_ = nonTarget_adapt_uttrs.iloc[nonTarget_idx]\n",
    "\n",
    "        adapt_trial = pd.concat([target_adapt_uttrs_, nonTarget_adapt_uttrs_])\n",
    "        adapt_trial = adapt_trial.sample(frac=1.0)\n",
    "        adapt_trials += [({'spk':adapt_spk, \"p_tar\":p_tar, \"p_hard\":p_hard}, np.array(enr_uttrs.id), adapt_trial)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(adapt_trials, open(f\"../trials/dev940_eval311/split_trials/adapt_len{l_trial}_enr{n_enr}_hard{p_hard}_ptar{p_tar}_trials.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test trials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  9%|▉         | 28/311 [00:05<01:00,  4.69it/s]\u001b[A\n",
      "  9%|▉         | 29/311 [00:06<00:59,  4.71it/s]\u001b[A\n",
      " 10%|▉         | 30/311 [00:06<00:59,  4.71it/s]\u001b[A\n",
      " 10%|▉         | 31/311 [00:06<00:59,  4.72it/s]\u001b[A\n",
      " 10%|█         | 32/311 [00:06<00:59,  4.71it/s]\u001b[A\n",
      " 11%|█         | 33/311 [00:06<00:58,  4.72it/s]\u001b[A\n",
      " 11%|█         | 34/311 [00:07<00:58,  4.71it/s]\u001b[A\n",
      " 11%|█▏        | 35/311 [00:07<00:58,  4.73it/s]\u001b[A\n",
      " 12%|█▏        | 36/311 [00:07<00:58,  4.72it/s]\u001b[A\n",
      " 12%|█▏        | 37/311 [00:07<00:57,  4.74it/s]\u001b[A\n",
      " 12%|█▏        | 38/311 [00:08<00:57,  4.74it/s]\u001b[A\n",
      "100%|██████████| 311/311 [01:00<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "test_trials = {}\n",
    "\n",
    "for test_spk in tqdm(eval_spks, total=len(eval_spks)):\n",
    "    target_test_uttrs = target_test_trials[target_test_trials.spk == test_spk]\n",
    "    nonTarget_test_uttrs = target_test_trials[target_test_trials.spk != test_spk]\n",
    "    target_test_uttrs.loc[:, 'label'] = 1\n",
    "    nonTarget_test_uttrs.loc[:, 'label'] = 0\n",
    "    \n",
    "    ## test trial \n",
    "#     target_test_embeds = get_embeds(target_test_uttrs.id, sv_embeds, sv_id2idx, norm=False)\n",
    "#     nontarget_test_embeds = get_embeds(nontarget_test_uttrs.id, sv_embeds, sv_id2idx, norm=False)\n",
    "#     nontarget_scores = py_plda_model.multi_sess(target_test_embeds, nontarget_test_embeds, cov_scaling=true).mean(0)\n",
    "#     # use only half of nonTarget\n",
    "#     nonTarget_sorted_idx = np.argsort(nonTarget_scores)[-len(nonTarget_scores)//2:]\n",
    "# #     nonTarget_idx = nonTarget_sorted_idx[-len(target_test_uttrs):]\n",
    "#     nonTarget_idx = np.random.choice(nonTarget_sorted_idx, size=len(target_test_uttrs), replace=False)\n",
    "#     nonTarget_test_uttrs = nonTarget_test_uttrs.iloc[nonTarget_idx]\n",
    "\n",
    "    nonTarget_test_uttrs = nonTarget_test_uttrs.sample(n=2000)\n",
    "    \n",
    "#     print(target_test_uttrs.shape)\n",
    "#     print(nonTarget_test_uttrs.shape)\n",
    "\n",
    "    test_trial = pd.concat([target_test_uttrs, nonTarget_test_uttrs])\n",
    "    test_trial = test_trial.sample(frac=1.0)\n",
    "    test_trials[test_spk] = test_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_trials, open(\"../trials/dev940_eval311/split_trials/test_random_trials.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "enr_embeds = get_embeds(adapt_trials[0][1], sv_embeds, sv_id2idx, norm=False)\n",
    "nonT_embeds = get_embeds(nonTarget_test_uttrs.id, sv_embeds, sv_id2idx, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonTarget_scores = py_plda_model.multi_sess(enr_embeds, nonT_embeds, cov_scaling=True).mean(0)\n",
    "nonTarget_scores = py_plda_model.multi_sess(target_test_embeds, nonT_embeds, cov_scaling=True).mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed Evaluation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_embed_dict = eval_uttrs.groupby('spk', group_keys=False).apply(lambda x: get_embeds(x.id, sv_embeds, sv_id2idx, norm=False).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
