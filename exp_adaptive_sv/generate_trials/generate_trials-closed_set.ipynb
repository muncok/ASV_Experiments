{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Ernollment Trial (Closed set)\n",
    "---------\n",
    "\n",
    "trial에 등장하는 대상을 소수의 인원으로 제한시킨 trial을 만들고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from utils import key2df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_df = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1.csv\")\n",
    "spk_uttr_stat = voxc1_df.spk.value_counts()\n",
    "voxc1_meta = pd.read_pickle(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_meta.pkl\")\n",
    "spk2gender = voxc1_meta.Gender.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Held-out validation set\n",
    "\n",
    "utterance가 150개 넘는 것들을 trial spks로 빼고 나머지는 validation spk로 빼었다.  \n",
    "그리고 validation spk 음성을 이용해서 threshold를 정하기 위한 trial을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_spks = spk_uttr_stat[spk_uttr_stat <= 150].index.tolist()\n",
    "dev_uttrs = voxc1_df[voxc1_df.spk.isin(dev_spks)]\n",
    "eval_spks = spk_uttr_stat[spk_uttr_stat > 150].index.tolist()\n",
    "eval_uttrs = voxc1_df[voxc1_df.spk.isin(eval_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_spks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_sizes = [3, 5, 7, 9]\n",
    "n_enroll_utters = 1 # later we can use 1~3 enrollment cases\n",
    "n_family = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "cases = {} # total cases: n_family * family_size\n",
    "\n",
    "for family_size in family_sizes:\n",
    "    closed_sets = np.random.choice(all_spks, size=(n_family, family_size), replace=True)\n",
    "    for spk_set in closed_sets: \n",
    "        closed_set_uttrs = trial_uttrs[trial_uttrs.spk.isin(spk_set)]\n",
    "        open_set_uttrs = trial_uttrs[~trial_uttrs.spk.isin(spk_set)]\n",
    "        open_set_uttrs.loc[:, 'label'] = 0\n",
    "        for enr_spk in spk_set: # TODO: multiple enrolled speakers case\n",
    "            enr_uttrs = closed_set_uttrs[closed_set_uttrs.spk == enr_spk].sample(n=n_enroll_utters)\n",
    "            target_uttrs =  closed_set_uttrs[closed_set_uttrs.spk == enr_spk].drop(index=enr_uttrs.index)\n",
    "            nonTarget_uttrs = closed_set_uttrs[closed_set_uttrs.spk != enr_spk]\n",
    "            target_uttrs.loc[:, 'label'] = 1\n",
    "            nonTarget_uttrs.loc[:, 'label'] = 0\n",
    "\n",
    "            # adapt trials\n",
    "            n_adapt_trial = int(min(len(target_uttrs), len(nonTarget_uttrs))*0.8)\n",
    "            adapt_target_uttrs = target_uttrs.sample(n=n_adapt_trial)\n",
    "            adapt_nonTarget_uttrs = nonTarget_uttrs.sample(n=n_adapt_trial)\n",
    "            \n",
    "            # test trials\n",
    "            n_test_trial = min(len(target_uttrs), len(nonTarget_uttrs)) - n_adapt_trial \n",
    "            test_target_uttrs = target_uttrs.drop(index=adapt_target_uttrs.index).sample(n=n_test_trial)\n",
    "            test_nonTarget_uttrs = nonTarget_uttrs.drop(index=adapt_nonTarget_uttrs.index).sample(n=n_test_trial)\n",
    "            \n",
    "            # shuffle trials and it will be fixed for consistency\n",
    "            adapt_trial = pd.concat([adapt_target_uttrs, adapt_nonTarget_uttrs]).sample(frac=1)\n",
    "            test_trial = pd.concat([test_target_uttrs, test_nonTarget_uttrs]).sample(frac=1)\n",
    "            \n",
    "            # ood trials\n",
    "            ood_trial= open_set_uttrs.groupby('spk', group_keys=False).apply(lambda x: x.sample(n=1))[:len(test_trial)]\n",
    "            \n",
    "            if family_size not in cases:\n",
    "                cases[family_size] = []\n",
    "            cases[family_size] += [[enr_spk, \n",
    "                       enr_uttrs.index.tolist(), \n",
    "                       (adapt_trial.index.tolist(), adapt_trial.label.tolist()),\n",
    "                       (test_trial.index.tolist(),test_trial.label.tolist()),\n",
    "                       (ood_trial.index.tolist(), ood_trial.label.tolist())\n",
    "                     ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for family_size in family_sizes:\n",
    "    save_dir = \"./trials/enr306/enr306_closedset_big/FS_{}/\".format(family_size)\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    pickle.dump(cases[family_size], open(save_dir + \"/trials.pkl\", \"wb\"))    \n",
    "    trial_info = {'set_size':family_size, 'n_enrs':n_enroll_utters}\n",
    "    pickle.dump(trial_info, open(save_dir + \"/trial_info.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spk            id10003\n",
       "session    5ablueV_1tw\n",
       "label                2\n",
       "origin           voxc2\n",
       "Name: id10003-5ablueV_1tw-00001, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_df.loc['id10003-5ablueV_1tw-00001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
