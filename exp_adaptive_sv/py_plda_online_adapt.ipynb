{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Adapt\n",
    "\n",
    "init enrollment만 adaptation에 쓰인다고 가정해야, 효율적으로 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sv_system import get_embeds, cosine_sim, score_trials\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import key2df, df2dict, compute_eer, get_id2idx\n",
    "\n",
    "embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_xvector/\"\n",
    "sv_embeds = np.load(embed_dir+\"ln_lda_sv_embeds.npy\")\n",
    "sv_keys = pickle.load(open(embed_dir + \"/sv_keys.pkl\", \"rb\"))\n",
    "sv_id2idx = get_id2idx(sv_keys)\n",
    "\n",
    "cohort_ids = np.load(\"trials/dev940_eval311/dev_cohort_ids.npy\")\n",
    "cohort_embeds = get_embeds(cohort_ids, sv_embeds, sv_id2idx, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioffe_plda.verifier import Verifier\n",
    "py_plda_model = Verifier()\n",
    "py_plda_model = Verifier(pickle.load(open(\"py_plda_model_ln_lda.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_trials(enr_embeds, test_embeds, score_method):\n",
    "        if score_method == \"scoreAvg\":\n",
    "            score = py_plda_model.score_avg(enr_embeds, test_embeds).mean(0)\n",
    "        elif score_method == \"vectorAvg\":\n",
    "            score = py_plda_model.vector_avg(enr_embeds, test_embeds).mean(0)\n",
    "        elif score_method == \"multiSessScale\":\n",
    "            score = py_plda_model.multi_sess(enr_embeds, test_embeds, cov_scaling=True).mean(0)\n",
    "        elif score_method == \"multiSessAdapt\":\n",
    "            score = py_plda_model.multi_sess(enr_embeds, test_embeds, cov_adapt=True).mean(0)\n",
    "        else:\n",
    "            raise NotImplemtedError\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = pickle.load(open(\"trials/dev940_eval311/hard_enr3xsess_ntar9/trials.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapt_ratio = 0.2\n",
    "\n",
    "eT_list =  [-4.26017]\n",
    "init = []\n",
    "optimal = []\n",
    "labels = []\n",
    "scoreAvg = {k:[] for k in eT_list}\n",
    "vectorAvg = {k:[] for k in eT_list}\n",
    "multiSessScale = {k:[] for k in eT_list}\n",
    "multiSessAdapt = {k:[] for k in eT_list}\n",
    "\n",
    "for t_i in tqdm(range(len(trials)), total=len(trials)):\n",
    "    enr_spk, enr_ids, test_trial = trials[t_i]\n",
    "    test_trial = (np.array(test_trial.id), np.array(test_trial.label))\n",
    "\n",
    "    adapt_len = int(len(test_trial[0]) * adapt_ratio)\n",
    "    \n",
    "    init_enr_embeds = get_embeds(enr_ids, sv_embeds,  sv_id2idx, norm=False)\n",
    "    test_embeds = get_embeds(test_trial[0], sv_embeds, sv_id2idx, norm=False)\n",
    "\n",
    "    adapt_scores = score_trials(init_enr_embeds, test_embeds, \"scoreAvg\")\n",
    "    \n",
    "    for eT in eT_list:\n",
    "        adapt_times = np.nonzero(adapt_scores > eT)[0]\n",
    "        adapted_embeds = test_embeds[adapt_scores > eT]\n",
    "        \n",
    "        scoreAvg_list = []\n",
    "        vectorAvg_list = []\n",
    "        multiSessScale_list = []\n",
    "        multiSessAdapt_list = []\n",
    "        \n",
    "        prev_t = 0\n",
    "        for n, t in enumerate(adapt_times.tolist() + [len(test_embeds)]):\n",
    "#             print(n, prev_t, t)\n",
    "            total_enr_embeds = np.concatenate([init_enr_embeds, adapted_embeds[:n]])\n",
    "            test_embeds_ = test_embeds[prev_t:t]\n",
    "#             scoreAvg_list.append(score_trials(total_enr_embeds, test_embeds_, \"scoreAvg_list\"))\n",
    "            vectorAvg_list.append(score_trials(total_enr_embeds, test_embeds_, \"vectorAvg\"))\n",
    "            multiSessScale_list.append(score_trials(total_enr_embeds, test_embeds_, \"multiSessScale\"))\n",
    "            multiSessAdapt_list.append(score_trials(total_enr_embeds, test_embeds_, \"multiSessAdapt\"))\n",
    "            prev_t = t\n",
    "    \n",
    "        init.append(score_trials(init_enr_embeds, test_embeds, \"multiSessScale\")[adapt_len:])\n",
    "#         scoreAvg[eT].append(np.concatenate(scoreAvg_list)[adapt_len:])\n",
    "        vectorAvg[eT].append(np.concatenate(vectorAvg)[adapt_len:])\n",
    "        multiSessScale[eT].append(np.concatenate(multiSessScale)[adapt_len:])\n",
    "        multiSessAdapt[eT].append(np.concatenate(multiSessAdapt)[adapt_len:])\n",
    "        \n",
    "    labels.append(test_trial[1])\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eT in eT_list:\n",
    "#     print(\"optimal\")\n",
    "#     compute_eer(np.concatenate(online_optimal), np.concatenate(online_labels))\n",
    "#     print(\"init\")\n",
    "#     compute_eer(np.concatenate(online_init), np.concatenate(online_labels))\n",
    "#     print(\"scoreAvg\")\n",
    "#     compute_eer(np.concatenate(online_scoreAvg[eT]), np.concatenate(online_labels))\n",
    "    print(\"vectorAvg\")\n",
    "    compute_eer(np.concatenate(online_vectorAvg[eT]), np.concatenate(online_labels));\n",
    "    print(\"multiSessScale\")\n",
    "    compute_eer(np.concatenate(online_multiSessScale[eT]), np.concatenate(online_labels))\n",
    "    print(\"multiSessAdapt\")\n",
    "    compute_eer(np.concatenate(online_multiSessAdapt[eT]), np.concatenate(online_labels))\n",
    "    print(\"multiSessScaleAdapt\")\n",
    "    compute_eer(np.concatenate(online_multiSessScaleAdapt[eT]), np.concatenate(online_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
