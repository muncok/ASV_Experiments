{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Ernollment Trial with voxceleb1\n",
    "---------\n",
    "\n",
    "trial 길이가 충분히 긴 set을 만들고자 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from utils import key2df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes & embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_si = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_si_with_frames.csv\", index_col=False)\n",
    "voxc1_sv = pd.read_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_sv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_df = pd.concat([voxc1_si, voxc1_sv], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_uttr_stat = voxc1_df.spk.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Held-out validation set\n",
    "\n",
    "utterance가 150개 넘는 것들을 trial spks로 빼고 나머지는 validation spk로 빼었다.  \n",
    "그리고 validation spk 음성을 이용해서 threshold를 정하기 위한 trial을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_spks = spk_uttr_stat[spk_uttr_stat <= 150].index.tolist()\n",
    "dev_uttrs = voxc1_df[voxc1_df.spk.isin(dev_spks)]\n",
    "eval_spks = spk_uttr_stat[spk_uttr_stat > 150].index.tolist()\n",
    "eval_uttrs = voxc1_df[voxc1_df.spk.isin(eval_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_dev_df = voxc1_df[voxc1_df.spk.isin(dev_spks)]\n",
    "voxc1_eval_df = voxc1_df[voxc1_df.spk.isin(eval_spks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "voxc1_dev_df['label'] = voxc1_dev_df.groupby('spk').ngroup().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_dev_df = voxc1_dev_df.sort_values('id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_dev_df = voxc1_dev_df.fillna('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_dev_df.to_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_dev.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxc1_eval_df.to_csv(\"/dataset/SV_sets/voxceleb1/dataframes/voxc1_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_spks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design trials for each enr_spk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of spks: 306\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of spks: {len(eval_spks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "trials = []\n",
    "\n",
    "for enr_spk in eval_spks[:2]: # TODO: multiple enrolled speakers case\n",
    "    target_uttrs = voxc1_eval_df[voxc1_eval_df.spk == enr_spk]\n",
    "    nonTarget_uttrs = voxc1_eval_df[voxc1_eval_df.spk != enr_spk]\n",
    "    target_uttrs.loc[:, 'label'] = 1\n",
    "    nonTarget_uttrs.loc[:, 'label'] = 0\n",
    "    \n",
    "    enr_uttrs =  target_uttrs[(target_uttrs.frames > 300) & (target_uttrs.frames < 400)]\n",
    "    for idx, enr_uttr in enr_uttrs.iterrows():\n",
    "        target_uttrs_ = target_uttrs.drop(index=idx)\n",
    "        # adapt trials\n",
    "        adapt_target_uttrs = target_uttrs_.sample(n=50)\n",
    "        adapt_nonTarget_uttrs = nonTarget_uttrs.sample(n=200)\n",
    "\n",
    "        # test trials\n",
    "        test_target_uttrs = target_uttrs_.drop(index=adapt_target_uttrs.index)\n",
    "        test_nonTarget_uttrs = nonTarget_uttrs.drop(index=adapt_nonTarget_uttrs.index).sample(n=3000)\n",
    "\n",
    "        # shuffle trials and it will be fixed for consistency\n",
    "        adapt_trial = pd.concat([adapt_target_uttrs, adapt_nonTarget_uttrs]).sample(frac=1)\n",
    "        test_trial = pd.concat([test_target_uttrs, test_nonTarget_uttrs]).sample(frac=1)\n",
    "\n",
    "        trials += [[enr_spk, \n",
    "                   [enr_uttr.id], \n",
    "                   (np.array(adapt_trial.id), np.array(adapt_trial.label)),\n",
    "                   (np.array(test_trial.id),np.array(test_trial.label)),\n",
    "                 ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./trials/enr306/short_enr_test/\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "pickle.dump(trials, open(save_dir + \"/trials.pkl\", \"wb\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
