{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sv_system_utils import get_embeds, cosine_sim, compute_error\n",
    "from batch_sv_system_utils import compute_eer\n",
    "from utils import key2df, df2dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id2idx(keys):\n",
    "    key_df = key2df(keys)\n",
    "    id2idx, idx2id = df2dict(key_df) \n",
    "    return id2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_embeds/\"\n",
    "# embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_300f_embeds/\"\n",
    "sv_embeds = np.load(embed_dir + \"/sv_embeds.npy\")\n",
    "keys = pickle.load(open(embed_dir + \"/sv_keys.pkl\", \"rb\"))\n",
    "id2idx = get_id2idx(keys)\n",
    "\n",
    "plda_embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_xvector/\"\n",
    "# plda_embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_300f_xvector/\"\n",
    "plda_sv_embeds = np.load(plda_embed_dir + \"/sv_embeds.npy\")\n",
    "plda_model_dir = plda_embed_dir + \"plda_train/\"\n",
    "plda_keys = pickle.load(open(plda_embed_dir + \"/sv_keys.pkl\", \"rb\"))\n",
    "plda_id2idx = get_id2idx(plda_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(x, n_feat=5):\n",
    "    min_ = x.min(0)\n",
    "    max_ = x.max(0)\n",
    "    median_ = np.median(x, axis=0)\n",
    "    avg_ = x.mean(0)\n",
    "    std_ = x.std(0)\n",
    "   \n",
    "    if n_feat==2:\n",
    "        return np.stack([avg_, std_], axis=0).T\n",
    "    elif n_feat==3:\n",
    "        return np.stack([max_, avg_, std_], axis=0).T\n",
    "    elif n_feat==4:\n",
    "        return np.stack([min_, max_, avg_, std_], axis=0).T\n",
    "    elif n_feat==5:\n",
    "        return np.stack([min_, max_, median_, avg_, std_], axis=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Adaptation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Cosine + Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev normalized cosine scores\n",
    "from batch_sv_system_utils import run_trial, plot_score \n",
    "\n",
    "cohort_embeds = np.load(\"trials/enr306/cohort_embeds.npy\")\n",
    "trial = pickle.load(open(\"trials/enr306/dev_random_full_enr_spk10/trials.pkl\", \"rb\"))\n",
    "\n",
    "dev_score_list = []\n",
    "dev_norm_score_list = []\n",
    "dev_labels = []\n",
    "for t_idx in range(len(trial)):\n",
    "    enr_spk, imposters, enr_ids, test_trial = trial[t_idx]\n",
    "\n",
    "    ### get embeds\n",
    "    enr_embeds = get_embeds(enr_ids, sv_embeds, id2idx, norm=True)\n",
    "    test_embeds = get_embeds(test_trial[0], sv_embeds, id2idx, norm=True)\n",
    "\n",
    "\n",
    "    adapt_fusion, adapt_scores = run_trial(enr_embeds, test_embeds, test_trial[1],\n",
    "                                           plda_dir=None, neg_embeds=None,\n",
    "                                           plot=False, title=\"score_fusion(adapt)\",\n",
    "                                           verbose=False)\n",
    "    enr_cohort_scores = cosine_sim(enr_embeds, cohort_embeds)\n",
    "    enr_mu, enr_std = enr_cohort_scores.mean(1, keepdims=True), enr_cohort_scores.std(1, keepdims=True)\n",
    "    test_cohort_scores = cosine_sim(test_embeds, cohort_embeds)\n",
    "    test_mu, test_std = test_cohort_scores.mean(1, keepdims=True).T, test_cohort_scores.std(1, keepdims=True).T\n",
    "    norm_adapt_scores = ((adapt_scores - enr_mu)/enr_std + (adapt_scores - test_mu)/test_std)/2\n",
    "    dev_score_list.append(adapt_scores)\n",
    "    dev_norm_score_list.append(norm_adapt_scores)\n",
    "    dev_labels.append(test_trial[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR train\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "train_feat = np.concatenate([get_features(x, n_feat=3) for x in dev_norm_score_list], axis=0)\n",
    "train_labels = np.concatenate(dev_labels)[:len(train_feat)]\n",
    "\n",
    "clf = LogisticRegressionCV(Cs=10, fit_intercept=True, class_weight='balanced')\n",
    "clf.fit(train_feat, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"trials/enr306/dev_random_full_enr_spk10/norm_nf3_bal_clf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev PLDA\n",
    "from batch_sv_system_utils import run_trial, plot_score \n",
    "\n",
    "trial = pickle.load(open(\"trials/dev317_eval934/dev_random_enr20_spk10_gender/trials.pkl\", \"rb\"))\n",
    "\n",
    "dev_plda_score_list = []\n",
    "dev_labels = []\n",
    "for t_idx in range(len(trial)):\n",
    "    enr_spk, enr_ids, test_trial = trial[t_idx]\n",
    "\n",
    "    ### get embeds\n",
    "    enr_embeds = get_embeds(enr_ids, plda_sv_embeds, id2idx, norm=False)\n",
    "    test_embeds = get_embeds(test_trial[0], plda_sv_embeds, id2idx, norm=False)\n",
    "\n",
    "\n",
    "    adapt_fusion, adapt_scores = run_trial(enr_embeds, test_embeds, test_trial[1],\n",
    "                                           plda_dir=plda_model_dir, neg_embeds=None,\n",
    "                                           plot=False, title=\"score_fusion(adapt)\",\n",
    "                                           verbose=False)\n",
    "    dev_plda_score_list.append(adapt_scores)\n",
    "    dev_labels.append(test_trial[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv='warn', dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2',\n",
       "           random_state=None, refit=True, scoring=None, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR train\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "train_feat = np.concatenate([get_features(x, n_feat=5) for x in dev_plda_score_list], axis=0)\n",
    "train_labels = np.concatenate(dev_labels)\n",
    "\n",
    "lr_clf = LogisticRegressionCV(Cs=10, fit_intercept=True, class_weight='balanced')\n",
    "lr_clf.fit(train_feat, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR, SVC, LinearSVC\n",
    "svm_clf = LinearSVC(class_weight='balanced')\n",
    "svm_clf.fit(train_feat, train_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03717907,  0.25214947, -0.13143247,  0.31050746,  0.20215204]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01989696,  0.02000047, -0.02425224,  0.11643041,  0.07652798]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr_clf, open(\"trials/dev317_eval934/dev_random_enr20_spk10_gender/plda_nf4_bal_lr_clf.pkl\", \"wb\"))\n",
    "pickle.dump(svm_clf, open(\"trials/dev317_eval934/dev_random_enr20_spk10_gender/plda_nf4_bal_svm_clf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Adaptation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR train\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "train_feat = np.concatenate([get_features(x) for x in dev_norm_score_list], axis=0)\n",
    "train_labels = np.concatenate(dev_labels)[:len(train_feat)]\n",
    "\n",
    "clf = LogisticRegressionCV(Cs=10, fit_intercept=True)\n",
    "clf.fit(train_feat, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"trials/enr306/dev_random_n2000/norm_unsup_clf.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
