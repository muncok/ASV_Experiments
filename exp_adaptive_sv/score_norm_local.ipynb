{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Normalization with unsuperviesd info\n",
    "-------------\n",
    "\n",
    "z-norm과 s-norm을 구현하였다.\n",
    "\n",
    "기존에 다른 데이터셋으로 부터 imposter set을 가져와서 score normalization 했던 것에서 벗어나,  \n",
    "Unsupervised하게 모인 데이터를 가지고 score normalization을 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapt trial의 prediction 기준으로 imposter_embeds를 설정하면 에러 때문에(에러가 꽤 클 경우), imposter set의 score 분포가 깨진다.  \n",
    "adapte_label을 기준으로 하면 성능이 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_sv_system.score_norm_utils import key2df\n",
    "\n",
    "keys = pickle.load(open(\"./xvector_embeds/sv_keys.pkl\", \"rb\"))\n",
    "key_df = key2df(keys)\n",
    "key2id = {k:v for v, k in enumerate(keys)}\n",
    "\n",
    "sv_embeds = np.load(\"./xvector_embeds/sv_embeds.npy\")\n",
    "validation_set = pd.read_pickle(\"trials/enr306/validation_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uttrkey_to_id(key2id, keys):\n",
    "    return [key2id[key] for key in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from score_norm_utils import uttrkey_to_id\n",
    "imposter_set = validation_set.sample(n=500)\n",
    "ood_imposter_embeds = sv_embeds[uttrkey_to_id(key2id, imposter_set.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing trace then score normalization\n",
    "\n",
    "TODO: run_trial에 넣어야한다... 너무 느리다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trace = [adapt_tr, test_tr, ood_tr]  \n",
    "tr = trial_idxs, scores, label, pred 또는   \n",
    "tr = trial_idxs, scores, label, pred, enroll_pred  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.56792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"adaptive_sv_system/enr306_closedset_out/FS3_ENR3_QUE7/inc_update_neg/\"\n",
    "traces = pickle.load(open(base_dir+\"trace.pkl\", \"rb\"))\n",
    "meta_info = pd.read_pickle(base_dir+\"meta_info_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from adaptive_sv_system.score_norm_utils import eval_cosine_score, eval_z_score, eval_s_score\n",
    "\n",
    "cos_acc = []\n",
    "z_acc = []\n",
    "s_acc = []\n",
    "for t_idx in range(len(traces)):\n",
    "    tr = traces[t_idx]\n",
    "    meta = meta_info.iloc[t_idx]\n",
    "    adapt_tr, test_tr, ood_tr = tr\n",
    "    init_enr_idx = meta_info.iloc[t_idx].enr_idxs\n",
    "    init_enr_embeds = sv_embeds[init_enr_idx]\n",
    "\n",
    "    adapt_trial_idxs, adapt_scores, adapt_label, adapt_pred, adapt_enroll_pred = adapt_tr\n",
    "    adapt_embeds = sv_embeds[adapt_trial_idxs.astype(np.int64)]\n",
    "    adapt_enr_embeds = adapt_embeds[adapt_enroll_pred == 1]\n",
    "    total_enr_embeds = np.concatenate([init_enr_embeds, adapt_enr_embeds])\n",
    "\n",
    "    test_trial_idxs, test_scores, test_label, test_pred = test_tr\n",
    "    test_embeds = sv_embeds[test_trial_idxs.astype(np.int64)]\n",
    "    test_label = torch.from_numpy(test_label).byte()\n",
    "    \n",
    "    enr_embeds = total_enr_embeds\n",
    "#     enr_embeds = init_enr_embeds\n",
    "    \n",
    "#     imposter_embeds = adapt_embeds[adapt_pred==0]\n",
    "    imposter_embeds = ood_imposter_embeds\n",
    "\n",
    "    score, pred_acc, eer = eval_cosine_score(\n",
    "                                             enr_embeds, test_embeds, \n",
    "                                             test_label, threshold)\n",
    "    \n",
    "    z_score, z_pred_acc, z_eer = eval_z_score(\n",
    "                                              enr_embeds, test_embeds, \n",
    "                                              test_label, threshold, \n",
    "                                              imposter_embeds)\n",
    "    \n",
    "    s_score, s_pred_acc, s_eer = eval_s_score(\n",
    "                                              enr_embeds, test_embeds,\n",
    "                                              test_label, threshold,\n",
    "                                              imposter_embeds)\n",
    "    \n",
    "    \n",
    "#     print(\"cos_acc:{}\\nz_acc:{}\\ns_acc:{}\".format(pred_acc, z_pred_acc, s_pred_acc))\n",
    "#     print(\"=\"*20)\n",
    "    cos_acc += [pred_acc]\n",
    "    z_acc += [z_pred_acc]\n",
    "    s_acc += [s_pred_acc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_acc:0.9713\n",
      "z_acc:0.9713\n",
      "s_acc:0.5535\n"
     ]
    }
   ],
   "source": [
    "# only init_enr_embeds\n",
    "# ood_imposter\n",
    "print(\"cos_acc:{:.4f}\\nz_acc:{:.4f}\\ns_acc:{:.4f}\".format(\n",
    "    np.mean(cos_acc), np.mean(z_acc), np.mean(s_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_acc:0.9713\n",
      "z_acc:0.9713\n",
      "s_acc:0.5535\n"
     ]
    }
   ],
   "source": [
    "# only init_enr_embeds\n",
    "# adapt_imposter\n",
    "print(\"cos_acc:{:.4f}\\nz_acc:{:.4f}\\ns_acc:{:.4f}\".format(\n",
    "    np.mean(cos_acc), np.mean(z_acc), np.mean(s_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cos_acc:0.9713\n",
      "z_acc:0.9713\n",
      "s_acc:0.5535\n"
     ]
    }
   ],
   "source": [
    "# total_enr_embeds\n",
    "# adapt_imposter\n",
    "print(\"cos_acc:{:.4f}\\nz_acc:{:.4f}\\ns_acc:{:.4f}\".format(\n",
    "    np.mean(cos_acc), np.mean(z_acc), np.mean(s_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364, 512)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt_embeds[adapt_pred==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
