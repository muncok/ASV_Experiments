{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_home_dir = '/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/'\n",
    "rDots_pcm_dir = os.path.join(rDots_home_dir, 'pcm/')\n",
    "rDots_wav_dir = os.path.join(rDots_home_dir, 'wav/')\n",
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "rDots_infos_dir = os.path.join(rDots_home_dir, 'infos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = 'm'\n",
    "part_n = '1'\n",
    "prefix = \"{}_part{}\".format(gender, str(part_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_ndx(ndx_dir, gender, part_num):\n",
    "    assert (gender in ['f', 'm'])\n",
    "    part_num = int(part_num[0])\n",
    "    assert (part_num in [1,2,3,4])\n",
    "    spk_sent_ID, file_names, trial_types = [], [], []\n",
    "    \n",
    "    with open(ndx_dir + gender + '_part_0' + str(part_num) + '.ndx', 'r') as ndx:\n",
    "        lines = ndx.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            [spk_sent, utterance, TC, TW, IC, IW] = line.split(',')\n",
    "            file_names.append(utterance+\".wav\")\n",
    "            spk_sent_ID.append(spk_sent)\n",
    "\n",
    "            if TC=='Y': trial_types.append(0) \n",
    "            elif TW=='Y': trial_types.append(1) \n",
    "            elif IC=='Y': trial_types.append(2) \n",
    "            elif IW=='Y': trial_types.append(3) \n",
    "    return [spk_sent_ID, file_names,  trial_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_ndx_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "spk_sent_ID, file_names,trial_types = rDots_parse_ndx(rDots_ndx_dir, gender, part_n)\n",
    "ndx_dict = dict(id=spk_sent_ID, file=file_names, trial_type=trial_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx = pd.DataFrame.from_dict(ndx_dict)\n",
    "manifest_dir = \"manifests/reddots/trial/{}/\".format(prefix)\n",
    "if not os.path.isdir(manifest_dir):\n",
    "    os.makedirs(manifest_dir)\n",
    "ndx.to_pickle(os.path.join(manifest_dir, \"{}_ndx.pkl\".format(prefix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rDots_parse_trn(trn_dir, gender, part_num):\n",
    "    assert (gender in ['f', 'm'])\n",
    "    assert (part_num in ['1','2','3','4_tp', '4_td'])\n",
    "    spk_sent_ID, file_names = [], []\n",
    "\n",
    "    with open(trn_dir + gender + '_part_0' + str(part_num) + '.trn', 'r') as trn:\n",
    "        lines = trn.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            [spk_sent, utters] = line.split(' ')\n",
    "            utters = utters.split(',')\n",
    "            for uttr in utters:\n",
    "                spk_sent_ID.append(spk_sent)\n",
    "                file_names.append(uttr+\".wav\")\n",
    "    assert(len(spk_sent_ID) == len(file_names))\n",
    "    return [spk_sent_ID, file_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "rDots_trn_dir = os.path.join(rDots_home_dir, 'ndx/')\n",
    "[spk_sent, file_names] = rDots_parse_trn(rDots_trn_dir, gender, part_n)\n",
    "trn_dict = dict(id=spk_sent, file=file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.DataFrame.from_dict(trn_dict)\n",
    "trn.to_pickle(os.path.join(manifest_dir,\"{}_trn.pkl\".format(prefix)))\n",
    "trn_id = list(trn.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Learning Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reddots,  \n",
    "Trn and ndx files are disjoint. (In all parts)\n",
    "\n",
    "TW samples are only 252 out of 3854 in \"m0001_31\" case.  \n",
    "\n",
    "m_part4_tp is a good choice I think.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddots_df = pd.read_pickle(\"dataset/dataframes/Reddots/Reddots_Dataframe.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = pd.read_pickle(\"dataset/dataframes/Reddots/m_part4_tp/m_part4_tp_trn.pkl\")\n",
    "ndx = pd.read_pickle(\"dataset/dataframes/Reddots/m_part4_tp/m_part4_tp_ndx.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx['spk'] = ndx.file.apply(lambda x: x.split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0001_31_ndx = ndx[ndx.id=='m0001_31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "m0001    624\n",
       "m0002    598\n",
       "m0009    432\n",
       "m0020    408\n",
       "m0013    407\n",
       "m0007    312\n",
       "m0040    288\n",
       "m0015    288\n",
       "m0008    240\n",
       "m0026    240\n",
       "m0022    216\n",
       "m0029    216\n",
       "m0048    192\n",
       "m0053    192\n",
       "m0014    192\n",
       "m0005    168\n",
       "m0017    168\n",
       "m0021    168\n",
       "m0006    168\n",
       "m0043    168\n",
       "m0028    120\n",
       "m0047    120\n",
       "m0050    120\n",
       "m0054    120\n",
       "m0032     96\n",
       "m0010     96\n",
       "m0067     96\n",
       "m0018     96\n",
       "m0060     96\n",
       "m0038     72\n",
       "m0041     72\n",
       "m0016     72\n",
       "m0052     72\n",
       "m0064     48\n",
       "m0051     48\n",
       "m0023     48\n",
       "m0037     48\n",
       "m0057     48\n",
       "m0030     24\n",
       "m0025     24\n",
       "m0055     24\n",
       "m0004     24\n",
       "m0035     24\n",
       "m0062     24\n",
       "m0059     24\n",
       "m0056     24\n",
       "m0063     24\n",
       "m0019     24\n",
       "m0045     24\n",
       "Name: spk, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m0001_31_ndx.spk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7437"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ndx[ndx.id == \"m0001_31\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_enroll_uttrs = 2\n",
    "positive_df = common_words_df[common_words_df.spk.isin(enroll_spks)] # utterances from enroll spks\n",
    "grouped = positive_df.groupby(['spk', 'sent'], as_index=False, group_keys=False)\n",
    "enroll_df = grouped.apply(lambda x: x.sample(n=n_enroll_uttrs)) # enroll utterances for each word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
