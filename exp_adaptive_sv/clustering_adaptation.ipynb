{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batch_sv_system import get_embeds, cosine_sim, compute_plda_score\n",
    "from utils import key2df, df2dict, compute_eer, get_id2idx\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import key2df\n",
    "\n",
    "embed_dir = \"embeddings/voxc2_fbank64_voxc2untied_xvector/\"\n",
    "si_embeds = np.load(embed_dir+\"ln_lda_si_embeds.npy\")\n",
    "sv_embeds = np.load(embed_dir+\"ln_lda_sv_embeds.npy\")\n",
    "si_keys = pickle.load(open(embed_dir + \"/si_keys.pkl\", \"rb\"))\n",
    "sv_keys = pickle.load(open(embed_dir + \"/sv_keys.pkl\", \"rb\"))\n",
    "sv_id2idx = get_id2idx(sv_keys)\n",
    "si_df = key2df(si_keys)\n",
    "\n",
    "cohort_ids = np.load(\"trials/dev940_eval311/dev_cohort_ids.npy\")\n",
    "cohort_embeds = get_embeds(cohort_ids, sv_embeds, sv_id2idx, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioffe_plda.verifier import Verifier\n",
    "py_plda_model = Verifier()\n",
    "py_plda_model = Verifier(pickle.load(open(\"py_plda_model_ln_lda.pkl\", \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = pickle.load(open(\"trials/dev940_eval311/splited_trials/adapt_enr3_hard_trials.pkl\", \"rb\"))\n",
    "# trials = pickle.load(open(\"trials/dev940_eval311/random_enr3xsess_ntar9/small_trials.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [02:10<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "base_pred_list = []\n",
    "adapt_pred_list1 = []\n",
    "adapt_pred_list2 = []\n",
    "adapt_label_list = []\n",
    "\n",
    "for t_i in tqdm(range(0, len(trials), 1), total=len(trials)//1):\n",
    "    trial_info, enr_ids, adapt_trial = trials[t_i]\n",
    "    adapt_trial = (np.array(adapt_trial.id), np.array(adapt_trial.label))\n",
    "    init_enr_embeds = get_embeds(enr_ids, sv_embeds, sv_id2idx, norm=False)\n",
    "    adapt_embeds = get_embeds(adapt_trial[0], sv_embeds, sv_id2idx, norm=False)\n",
    "\n",
    "    eT = -4.2602\n",
    "    adapt_scores = py_plda_model.score_avg(init_enr_embeds, adapt_embeds)\n",
    "    base_adapt_preds = adapt_scores.mean(0) > eT\n",
    "    base_pred_list.append(base_adapt_preds)\n",
    "\n",
    "    model_ = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "    \n",
    "    X = adapt_embeds\n",
    "    cluster_preds = model_.fit_predict(X)\n",
    "    mean_plda_scores = dict.fromkeys(range(3))\n",
    "    for cluster_id in mean_plda_scores.keys():\n",
    "        mean_plda_scores[cluster_id] =  py_plda_model.multi_sess(\n",
    "            init_enr_embeds, adapt_embeds[cluster_preds==cluster_id], cov_scaling=True).mean()\n",
    "    target_cluster = max(mean_plda_scores, key=mean_plda_scores.get)\n",
    "    adapt_preds = cluster_preds == target_cluster\n",
    "    adapt_pred_list1.append(adapt_preds)\n",
    "    \n",
    "    X = np.concatenate([init_enr_embeds, adapt_embeds])\n",
    "    cluster_preds = model_.fit_predict(X)\n",
    "    target_cluster = np.argmax(np.bincount(cluster_preds[:3])) \n",
    "    adapt_preds = cluster_preds[3:] == target_cluster\n",
    "    adapt_pred_list2.append(adapt_preds)\n",
    "    \n",
    "    adapt_label_list.append(adapt_trial[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:0.359, recall:0.991\n"
     ]
    }
   ],
   "source": [
    "prec, recall, _, _ = precision_recall_fscore_support(\n",
    "    np.concatenate(adapt_label_list), np.concatenate(base_pred_list), average='binary')\n",
    "print(\"prec:{:.3f}, recall:{:.3f}\".format(prec, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:0.343, recall:0.865\n"
     ]
    }
   ],
   "source": [
    "prec, recall, _, _ = precision_recall_fscore_support(\n",
    "    np.concatenate(adapt_label_list), np.concatenate(adapt_pred_list1), average='binary')\n",
    "print(\"prec:{:.3f}, recall:{:.3f}\".format(prec, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:0.332, recall:0.922\n"
     ]
    }
   ],
   "source": [
    "prec, recall, _, _ = precision_recall_fscore_support(\n",
    "    np.concatenate(adapt_label_list), np.concatenate(adapt_pred_list2), average='binary')\n",
    "print(\"prec:{:.3f}, recall:{:.3f}\".format(prec, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec:0.193, recall:0.980\n",
      "prec:0.645, recall:0.980\n",
      "prec:0.410, recall:0.960\n",
      "prec:0.247, recall:0.980\n",
      "prec:1.000, recall:0.780\n",
      "prec:0.282, recall:0.880\n",
      "prec:0.397, recall:1.000\n",
      "prec:0.182, recall:0.400\n",
      "prec:0.207, recall:0.680\n",
      "prec:0.671, recall:0.940\n",
      "prec:1.000, recall:0.900\n",
      "prec:0.735, recall:1.000\n",
      "prec:0.209, recall:0.980\n",
      "prec:0.556, recall:1.000\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.266, recall:1.000\n",
      "prec:1.000, recall:0.880\n",
      "prec:0.447, recall:0.920\n",
      "prec:0.258, recall:0.980\n",
      "prec:0.256, recall:0.820\n",
      "prec:0.526, recall:0.820\n",
      "prec:0.979, recall:0.940\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.433, recall:0.900\n",
      "prec:0.360, recall:0.900\n",
      "prec:0.446, recall:1.000\n",
      "prec:0.266, recall:1.000\n",
      "prec:0.602, recall:1.000\n",
      "prec:0.688, recall:0.880\n",
      "prec:0.437, recall:0.900\n",
      "prec:0.778, recall:0.840\n",
      "prec:0.979, recall:0.940\n",
      "prec:0.298, recall:0.740\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.893, recall:1.000\n",
      "prec:0.212, recall:0.860\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.398, recall:0.900\n",
      "prec:0.338, recall:1.000\n",
      "prec:0.742, recall:0.980\n",
      "prec:0.605, recall:0.920\n",
      "prec:0.962, recall:1.000\n",
      "prec:0.860, recall:0.860\n",
      "prec:0.392, recall:0.980\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.170, recall:0.960\n",
      "prec:0.220, recall:0.980\n",
      "prec:0.673, recall:0.740\n",
      "prec:0.220, recall:0.980\n",
      "prec:0.363, recall:0.980\n",
      "prec:0.228, recall:0.820\n",
      "prec:0.270, recall:0.960\n",
      "prec:0.278, recall:0.880\n",
      "prec:0.241, recall:0.920\n",
      "prec:1.000, recall:0.720\n",
      "prec:0.195, recall:1.000\n",
      "prec:0.392, recall:0.940\n",
      "prec:0.247, recall:0.960\n",
      "prec:0.329, recall:0.960\n",
      "prec:0.875, recall:0.980\n",
      "prec:0.960, recall:0.960\n",
      "prec:1.000, recall:0.860\n",
      "prec:0.346, recall:0.900\n",
      "prec:0.186, recall:0.980\n",
      "prec:0.500, recall:0.780\n",
      "prec:0.239, recall:1.000\n",
      "prec:0.439, recall:0.940\n",
      "prec:0.089, recall:0.100\n",
      "prec:0.979, recall:0.920\n",
      "prec:0.169, recall:0.800\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.348, recall:0.920\n",
      "prec:0.348, recall:0.960\n",
      "prec:0.314, recall:1.000\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.255, recall:0.940\n",
      "prec:0.163, recall:0.840\n",
      "prec:0.742, recall:0.920\n",
      "prec:0.758, recall:1.000\n",
      "prec:0.240, recall:0.880\n",
      "prec:0.225, recall:1.000\n",
      "prec:0.199, recall:0.700\n",
      "prec:0.980, recall:1.000\n",
      "prec:0.272, recall:0.800\n",
      "prec:0.193, recall:0.940\n",
      "prec:0.254, recall:1.000\n",
      "prec:0.192, recall:0.920\n",
      "prec:0.156, recall:0.920\n",
      "prec:0.959, recall:0.940\n",
      "prec:0.215, recall:0.940\n",
      "prec:0.891, recall:0.980\n",
      "prec:0.240, recall:0.920\n",
      "prec:0.348, recall:0.960\n",
      "prec:0.341, recall:0.920\n",
      "prec:0.549, recall:0.900\n",
      "prec:0.110, recall:0.800\n",
      "prec:0.935, recall:0.860\n",
      "prec:0.304, recall:0.980\n",
      "prec:0.694, recall:0.680\n",
      "prec:0.264, recall:0.940\n",
      "prec:0.458, recall:0.980\n",
      "prec:0.417, recall:0.800\n",
      "prec:0.216, recall:0.920\n",
      "prec:0.293, recall:0.880\n",
      "prec:0.219, recall:0.600\n",
      "prec:0.453, recall:0.960\n",
      "prec:0.228, recall:0.980\n",
      "prec:0.340, recall:0.320\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.979, recall:0.940\n",
      "prec:0.557, recall:0.980\n",
      "prec:1.000, recall:0.900\n",
      "prec:0.436, recall:0.680\n",
      "prec:0.545, recall:0.720\n",
      "prec:0.721, recall:0.880\n",
      "prec:0.585, recall:0.960\n",
      "prec:0.284, recall:0.380\n",
      "prec:0.839, recall:0.520\n",
      "prec:0.852, recall:0.920\n",
      "prec:0.360, recall:1.000\n",
      "prec:1.000, recall:0.920\n",
      "prec:0.312, recall:0.980\n",
      "prec:0.255, recall:0.840\n",
      "prec:0.568, recall:0.840\n",
      "prec:0.284, recall:0.960\n",
      "prec:0.184, recall:1.000\n",
      "prec:0.419, recall:0.780\n",
      "prec:0.731, recall:0.980\n",
      "prec:0.345, recall:1.000\n",
      "prec:0.444, recall:0.720\n",
      "prec:0.253, recall:0.940\n",
      "prec:1.000, recall:0.980\n",
      "prec:0.371, recall:0.920\n",
      "prec:0.980, recall:1.000\n",
      "prec:0.256, recall:0.400\n",
      "prec:0.741, recall:0.860\n",
      "prec:0.246, recall:0.980\n",
      "prec:0.538, recall:1.000\n",
      "prec:0.397, recall:0.960\n",
      "prec:1.000, recall:0.940\n",
      "prec:1.000, recall:0.660\n",
      "prec:0.225, recall:1.000\n",
      "prec:0.265, recall:0.980\n",
      "prec:0.485, recall:0.980\n",
      "prec:0.388, recall:0.760\n",
      "prec:0.449, recall:0.960\n",
      "prec:0.833, recall:1.000\n",
      "prec:0.784, recall:0.800\n",
      "prec:0.863, recall:0.880\n",
      "prec:0.923, recall:0.720\n",
      "prec:0.621, recall:0.360\n",
      "prec:0.211, recall:0.900\n",
      "prec:0.420, recall:1.000\n",
      "prec:0.417, recall:0.960\n",
      "prec:0.556, recall:1.000\n",
      "prec:0.423, recall:0.940\n",
      "prec:0.505, recall:0.940\n",
      "prec:0.174, recall:0.920\n",
      "prec:0.430, recall:0.920\n",
      "prec:1.000, recall:0.960\n",
      "prec:0.234, recall:0.920\n",
      "prec:1.000, recall:0.900\n",
      "prec:0.204, recall:0.980\n",
      "prec:0.592, recall:0.900\n",
      "prec:0.662, recall:0.860\n",
      "prec:1.000, recall:0.860\n",
      "prec:0.227, recall:1.000\n",
      "prec:0.249, recall:0.960\n",
      "prec:0.138, recall:0.180\n",
      "prec:0.186, recall:0.320\n",
      "prec:0.381, recall:0.640\n",
      "prec:0.412, recall:0.840\n",
      "prec:0.463, recall:0.740\n",
      "prec:0.439, recall:0.940\n",
      "prec:0.336, recall:0.900\n",
      "prec:0.980, recall:0.960\n",
      "prec:0.797, recall:0.940\n",
      "prec:0.394, recall:1.000\n",
      "prec:1.000, recall:0.680\n",
      "prec:0.255, recall:0.960\n",
      "prec:0.230, recall:1.000\n",
      "prec:0.714, recall:1.000\n",
      "prec:1.000, recall:0.920\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.183, recall:0.720\n",
      "prec:0.527, recall:0.980\n",
      "prec:0.313, recall:0.920\n",
      "prec:0.253, recall:0.960\n",
      "prec:0.168, recall:0.900\n",
      "prec:0.287, recall:0.980\n",
      "prec:0.608, recall:0.960\n",
      "prec:0.686, recall:0.960\n",
      "prec:0.405, recall:0.980\n",
      "prec:0.224, recall:0.960\n",
      "prec:0.662, recall:0.940\n",
      "prec:0.233, recall:1.000\n",
      "prec:0.269, recall:0.980\n",
      "prec:1.000, recall:0.880\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.920, recall:0.920\n",
      "prec:0.202, recall:0.760\n",
      "prec:0.394, recall:1.000\n",
      "prec:1.000, recall:0.840\n",
      "prec:0.940, recall:0.940\n",
      "prec:0.781, recall:1.000\n",
      "prec:0.406, recall:0.820\n",
      "prec:0.746, recall:0.880\n",
      "prec:0.236, recall:0.840\n",
      "prec:0.500, recall:0.840\n",
      "prec:0.222, recall:0.880\n",
      "prec:0.667, recall:0.920\n",
      "prec:0.238, recall:0.720\n",
      "prec:0.287, recall:0.820\n",
      "prec:0.733, recall:0.660\n",
      "prec:0.700, recall:0.980\n",
      "prec:0.273, recall:0.720\n",
      "prec:0.193, recall:0.780\n",
      "prec:0.862, recall:0.500\n",
      "prec:0.333, recall:0.800\n",
      "prec:0.342, recall:0.820\n",
      "prec:0.295, recall:0.920\n",
      "prec:0.676, recall:1.000\n",
      "prec:0.429, recall:0.840\n",
      "prec:1.000, recall:0.920\n",
      "prec:0.918, recall:0.900\n",
      "prec:0.207, recall:1.000\n",
      "prec:0.522, recall:0.960\n",
      "prec:0.349, recall:0.900\n",
      "prec:0.467, recall:1.000\n",
      "prec:0.357, recall:1.000\n",
      "prec:0.322, recall:0.960\n",
      "prec:0.735, recall:1.000\n",
      "prec:0.337, recall:0.580\n",
      "prec:0.439, recall:0.860\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.588, recall:0.940\n",
      "prec:0.293, recall:0.920\n",
      "prec:0.420, recall:0.740\n",
      "prec:0.357, recall:1.000\n",
      "prec:1.000, recall:0.900\n",
      "prec:1.000, recall:0.960\n",
      "prec:0.260, recall:0.780\n",
      "prec:0.959, recall:0.940\n",
      "prec:0.227, recall:0.980\n",
      "prec:0.341, recall:0.920\n",
      "prec:0.490, recall:0.960\n",
      "prec:0.261, recall:0.980\n",
      "prec:0.353, recall:0.720\n",
      "prec:0.206, recall:0.860\n",
      "prec:0.919, recall:0.680\n",
      "prec:0.424, recall:1.000\n",
      "prec:1.000, recall:0.900\n",
      "prec:0.417, recall:1.000\n",
      "prec:0.391, recall:1.000\n",
      "prec:0.151, recall:0.920\n",
      "prec:0.778, recall:0.980\n",
      "prec:0.338, recall:1.000\n",
      "prec:0.259, recall:1.000\n",
      "prec:0.285, recall:0.860\n",
      "prec:0.902, recall:0.920\n",
      "prec:0.790, recall:0.980\n",
      "prec:0.260, recall:1.000\n",
      "prec:0.467, recall:1.000\n",
      "prec:0.907, recall:0.980\n",
      "prec:0.942, recall:0.980\n",
      "prec:0.557, recall:0.980\n",
      "prec:0.583, recall:0.980\n",
      "prec:0.296, recall:0.940\n",
      "prec:0.978, recall:0.880\n",
      "prec:0.980, recall:0.960\n",
      "prec:0.384, recall:0.960\n",
      "prec:0.789, recall:0.900\n",
      "prec:0.241, recall:0.940\n",
      "prec:0.457, recall:0.860\n",
      "prec:0.708, recall:0.920\n",
      "prec:0.978, recall:0.880\n",
      "prec:0.329, recall:0.960\n",
      "prec:0.209, recall:0.980\n",
      "prec:0.807, recall:0.920\n",
      "prec:0.409, recall:0.900\n",
      "prec:0.405, recall:0.940\n",
      "prec:1.000, recall:0.920\n",
      "prec:0.734, recall:0.940\n",
      "prec:0.525, recall:0.840\n",
      "prec:0.367, recall:0.940\n",
      "prec:0.404, recall:0.920\n",
      "prec:1.000, recall:0.820\n",
      "prec:0.700, recall:0.840\n",
      "prec:0.306, recall:0.960\n",
      "prec:0.407, recall:0.740\n",
      "prec:0.296, recall:0.840\n",
      "prec:0.287, recall:0.980\n",
      "prec:0.814, recall:0.960\n",
      "prec:0.355, recall:0.980\n",
      "prec:0.679, recall:0.720\n",
      "prec:0.393, recall:0.960\n",
      "prec:0.225, recall:0.780\n",
      "prec:0.925, recall:0.980\n",
      "prec:0.431, recall:1.000\n",
      "prec:0.618, recall:0.940\n",
      "prec:0.257, recall:0.860\n",
      "prec:0.946, recall:0.700\n",
      "prec:0.173, recall:0.900\n",
      "prec:0.480, recall:0.980\n",
      "prec:1.000, recall:1.000\n",
      "prec:0.648, recall:0.920\n",
      "prec:0.477, recall:0.840\n",
      "prec:0.222, recall:0.860\n",
      "prec:0.098, recall:0.120\n",
      "prec:1.000, recall:0.940\n",
      "prec:0.277, recall:0.860\n"
     ]
    }
   ],
   "source": [
    "for pred, label in zip(base_pred_list, adapt_label_list):\n",
    "    prec, recall, _, _ = precision_recall_fscore_support(\n",
    "        label, pred, average='binary')\n",
    "    print(\"prec:{:.3f}, recall:{:.3f}\".format(prec, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [418, 273]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-298-46d0b6d31a1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapt_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapt_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    520\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    521\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch-py3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [418, 273]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.fixes import signature\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(adapt_trial[1], adapt_scores.mean(0))\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
