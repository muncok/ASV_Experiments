{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.data.dataloader import init_embed_loaders\n",
    "from dnn.parser import get_sv_parser\n",
    "from dnn.train.model import init_seed\n",
    "from dnn.train.model import init_speechnet\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dnn.data.dataset import embedDataset\n",
    "from dnn.data.dataloader import _collate_fn\n",
    "def init_reddots_loaders(opt, dataframe):\n",
    "    \n",
    "    '''\n",
    "    Initialize the datasets, samplers and dataloaders for embeding\n",
    "    '''\n",
    "    val_dataset = embedDataset.read_reddots_token_df(opt, dataframe)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset,\n",
    "            batch_size=64,\n",
    "            num_workers=8,\n",
    "            collate_fn=_collate_fn)\n",
    "    return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (4096, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secToSample(sec):\n",
    "    return int(16000 * sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_sv_parser().parse_args(args=[])\n",
    "options.n_dct_filters = 40\n",
    "options.n_mels = 40\n",
    "options.timeshift_ms = 100\n",
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets\"\n",
    "options.window_size= 0.025\n",
    "options.window_stride= 0.010\n",
    "options.cache_size = 32768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.input_format = \"mfcc\"\n",
    "options.input_clip = True\n",
    "options.input_length = secToSample(3) # if input_clip is false, it doesn't affect anything\n",
    "options.splice_frames = secToSample(0.1)//160+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/wav/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/commands/word_aligned.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/voxc/si_train/full_train/si_voxc_res15_0.1s_full_fbank.pt\"\n",
    "options.model = \"res15\"\n",
    "model = init_speechnet(options)\n",
    "lda = None# None means not using lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/reddots/simplecnn/si_reddots_0.2s_random_2.pt is loaded\n"
     ]
    }
   ],
   "source": [
    "options.input = \"models/reddots/simplecnn/si_reddots_0.2s_random_2.pt\"\n",
    "options.model = \"SimpleCNN\"\n",
    "model =  init_speechnet(options)\n",
    "lda = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Reddots Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def lda_on_tensor(tensor, lda):\n",
    "    return torch.from_numpy(lda.transform(tensor.numpy()).astype(np.float32))\n",
    "\n",
    "def embeds(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt.splice_frames\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, splice_dim)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if opt.cuda:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_ndx = pd.read_pickle(\"trials/reddots/m_part1/m_part1_ndx.pkl\")\n",
    "m_part1_trn = pd.read_pickle('trials/reddots/m_part1/m_part1_trn.pkl')\n",
    "# m_part4_ndx = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_ndx.pkl\")\n",
    "# m_part4_trn = pd.read_pickle(\"manifests/reddots/trial/m_part4/m_part4_trn.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = m_part1_trn\n",
    "ndx = m_part1_ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_type = {0:'TC', 1:'TW', 2:'IC', 3:'IW'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Enrollment (trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_embed_loaders(options, trn)\n",
    "options.chunks = 1\n",
    "trn_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "\n",
    "embed_dim = trn_embeddings.shape[-1]\n",
    "trn_id = list(trn.id.unique())\n",
    "spk_model_dict = {}\n",
    "for id in trn_id:\n",
    "    index = np.nonzero(trn.id == id)\n",
    "    spk_model_dict[id] = trn_embeddings[index].mean(0, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SV Scoring (ndx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.data_folder = \"/home/muncok/DL/dataset/SV_sets/reddots_r2015q4_v1/token/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_files = pd.read_pickle('trials/reddots/m_part1/m_part1_files.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_part1_tokens = pd.read_pickle(\"trials/reddots/m_part1/m_part1_token_files.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = init_reddots_loaders(options, m_part1_tokens)\n",
    "options.chunks = 1\n",
    "ndx_embeddings, _ = embeds(options, val_dataloader, model, lda)\n",
    "# torch.save(ndx_embeddings, 'trials/reddots/m_part1/{}_embeds.pkl'.format(model_name))\n",
    "# ndx_embeddings = torch.load('trials/reddots/m_part1/{}_embeds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx['utterance'] = ndx.file.apply(lambda x: x[6:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_uttrs = set(ndx.utterance.unique().tolist()) - set(m_part1_tokens.utterance.unique().tolist())\n",
    "lost_ndx = ndx[ndx.utterance.isin(lost_uttrs)]\n",
    "ndx = ndx.drop(index=lost_ndx.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spk_model_dict[trial_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316ea0a1853944a28aa1a8278d2f53d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=320), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/muncok/anaconda3/envs/pytorch/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_trials = ndx.id.unique().tolist()\n",
    "import torch.nn.functional as F\n",
    "scores = dict()\n",
    "for t in range(4):\n",
    "    scores[t] = []\n",
    "\n",
    "for trial_id in tqdm(all_trials):\n",
    "    trial_ndx = ndx[(ndx.id == trial_id)].reset_index()\n",
    "    trial_embed_idx = np.nonzero(m_part1_tokens.utterance.isin(trial_ndx.utterance))\n",
    "    trial_embeds = ndx_embeddings[trial_embed_idx]\n",
    "    sim = F.cosine_similarity(trial_embeds, spk_model_dict[trial_id], dim=1).mean(-1).numpy()\n",
    "    split_count = m_part1_tokens[m_part1_tokens.utterance.isin(trial_ndx.utterance)].utterance.value_counts(sort=False).tolist()\n",
    "    sp_indx = [int(sum(split_count[:i])) for i in range(1,len(split_count))]\n",
    "    sim_avg = np.array(list(map(mean, np.split(sim, sp_indx))))\n",
    "    for t in range(4):\n",
    "        trial_type_idx = trial_ndx[trial_ndx.trial_type == t].index.tolist()\n",
    "        scores[t].append(sim_avg[trial_type_idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ee6f9d80aaaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# [TC, TW, IC, IW]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "# [TC, TW, IC, IW]\n",
    "for t in range(4):\n",
    "    scores[t] = np.concatenate(scores[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TC mean:nan, std:nan\n",
      "TW mean:nan, std:nan\n",
      "IC mean:nan, std:nan\n",
      "IW mean:nan, std:nan\n"
     ]
    }
   ],
   "source": [
    "for t in range(4):\n",
    "     print(\"{} mean:{:.4f}, std:{:.3f}\".format(err_type[t], scores[t].mean(), scores[t].std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TW] eer: 0.50, thres: 0.69256\n",
      "[IC] eer: 0.36, thres: 0.62052\n",
      "[IW] eer: 0.35, thres: 0.62023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "for t in range(1,4):\n",
    "    score_vector = np.concatenate((scores[0], scores[t]))\n",
    "    label_vector = np.concatenate((np.ones(len(scores[0])), \n",
    "                               np.zeros(len(scores[t]))))\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"[{}] eer: {:.2f}, thres: {:.5f}\".format(err_type[t], eer, thres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TI EERs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TI] eer: 0.35\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "score_vector = np.concatenate((scores[0], scores[1],\n",
    "                              scores[2], scores[3]))\n",
    "label_vector = np.concatenate((np.ones(len(scores[0]) + len(scores[1])), \n",
    "                           np.zeros(len(scores[2]) + len(scores[3]))))\n",
    "fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "print(\"[TI] eer: {:.2f}\".format(eer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
