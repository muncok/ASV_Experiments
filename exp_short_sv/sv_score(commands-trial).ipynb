{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/muncok/DL/projects/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "def compute_eer(pos_scores, neg_scores):\n",
    "    score_vector = np.concatenate([pos_scores, neg_scores])\n",
    "    label_vector = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
    "    fpr, tpr, thres = roc_curve(label_vector, score_vector, pos_label=1)\n",
    "    eer = np.min([fpr[np.nanargmin(np.abs(fpr - (1 - tpr)))], \n",
    "                 1-tpr[np.nanargmin(np.abs(fpr - (1 - tpr)))]])\n",
    "    thres = thres[np.nanargmin(np.abs(fpr - (1 - tpr)))]\n",
    "    print(\"eer:{:.3f}, thres:{:.4f}\".format(eer*100, thres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.utils.parser import test_config\n",
    "from sv_system.utils import secToSample, secToFrames\n",
    "si_config = test_config('res15')\n",
    "si_config['input_clip'] = True\n",
    "si_config['input_length'] = secToSample(1)\n",
    "si_config['input_frames'] = secToFrames(1)\n",
    "si_config['splice_frames'] = secToFrames(0.1)\n",
    "si_config['stride_frames'] = secToFrames(0.1)\n",
    "si_config['input_format'] = 'fbank'\n",
    "\n",
    "si_config['n_epochs'] = 50\n",
    "si_config['print_step'] = 100\n",
    "si_config['lr'] = [0.001, 0.0001]\n",
    "si_config['schedule'] = [np.inf]\n",
    "si_config['s_epoch'] = 0\n",
    "\n",
    "si_config['batch_size'] = 64\n",
    "si_config['num_workers'] = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SI_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechResModel(\n",
       "  (conv0): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv1): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv2): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv3): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn4): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv4): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn5): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv5): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn6): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv6): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  (bn7): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv7): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn8): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv8): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn9): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv9): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "  (bn10): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv10): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn11): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv11): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn12): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv12): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
       "  (bn13): BatchNorm2d(45, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  (conv13): Conv2d(45, 45, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
       "  (output): Linear(in_features=45, out_features=1881, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sv_system.model.SpeechModel import SpeechResModel\n",
    "si_model = SpeechResModel('res15', 1881)\n",
    "si_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from si_commands_res15.pt\n"
     ]
    }
   ],
   "source": [
    "si_model.load(\"si_commands_res15.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def embeds(opt, val_dataloader, model, lda=None):\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    splice_dim = opt['splice_frames']\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    if lda is not None:\n",
    "        print(\"LDA is loaded\")\n",
    "    for batch in (val_iter):\n",
    "        x, y = batch\n",
    "        time_dim = x.size(2)\n",
    "        split_points = range(0, time_dim-splice_dim+1, splice_dim)\n",
    "        model_outputs = []\n",
    "        for point in split_points:\n",
    "            x_in = Variable(x.narrow(2, point, splice_dim))\n",
    "            if not opt['no_cuda']:\n",
    "                x_in = x_in.cuda()\n",
    "            model_outputs.append(model.embed(x_in).cpu().data)\n",
    "        model_output = torch.stack(model_outputs, dim=0)\n",
    "        model_output = model_output.mean(0)\n",
    "        if lda is not None:\n",
    "            model_output = torch.from_numpy(lda.transform(model_output.numpy()).astype(np.float32))\n",
    "        embeddings.append(model_output)\n",
    "        labels.append(y.numpy())\n",
    "    embeddings = torch.cat(embeddings)\n",
    "    labels = np.hstack(labels)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_config['data_folder'] = \"/home/muncok/DL/dataset/SV_sets/speech_commands/\"\n",
    "enroll_df = pd.read_pickle('../trials/commands/final/equal_num_102spk_enroll.pkl')\n",
    "pos_test_df = pd.read_pickle('../trials/commands/final/equal_num_102spk_pos_test.pkl')\n",
    "neg_test_df = pd.read_pickle(\"../trials/commands/final/equal_num_102spk_neg_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down',\n",
       " 'eight',\n",
       " 'five',\n",
       " 'four',\n",
       " 'go',\n",
       " 'left',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'right',\n",
       " 'seven',\n",
       " 'six',\n",
       " 'stop',\n",
       " 'three',\n",
       " 'two',\n",
       " 'up',\n",
       " 'yes',\n",
       " 'zero']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words = enroll_df.sent.unique().tolist()\n",
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tree',\n",
       " 'marvin',\n",
       " 'house',\n",
       " 'cat',\n",
       " 'sheila',\n",
       " 'dog',\n",
       " 'wow',\n",
       " 'bed',\n",
       " 'happy',\n",
       " 'bird']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux_words = list(set(pos_test_df.sent.unique().tolist()) - set(common_words))\n",
    "aux_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_spks = enroll_df.spk.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "enroll_df = enroll_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sv_system.data.dataloader import init_default_loader\n",
    "from sv_system.data.dataset import SpeechDataset\n",
    "\n",
    "dataset = SpeechDataset.read_df(si_config, enroll_df, \"test\")\n",
    "loader = init_default_loader(si_config, dataset, False)\n",
    "enroll_embeddings, _ = embeds(si_config, loader, si_model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpeechDataset.read_df(si_config, pos_test_df, \"test\")\n",
    "loader = init_default_loader(si_config, dataset, False)\n",
    "pos_embedding, _ = embeds(si_config, loader, si_model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpeechDataset.read_df(si_config, neg_test_df, \"test\")\n",
    "loader = init_default_loader(si_config, dataset, False)\n",
    "imposter_embeddings, _ = embeds(si_config, loader, si_model, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Not Seperated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_average = 1 # number of average means the number of words in a sentence\n",
    "n_enroll_uttrs = 40 # number of enroll uttrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_models = dict()\n",
    "for spk in enroll_spks:\n",
    "    enroll_idx = np.nonzero(enroll_df.spk == spk)\n",
    "    spk_models[spk] = enroll_embeddings[enroll_idx][:n_enroll_uttrs].mean(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "uni\n",
      "eer:16.143, thres:0.9505\n"
     ]
    }
   ],
   "source": [
    "# average embedding --> scoring\n",
    "\n",
    "pos_scores = dict()\n",
    "neg_scores = dict()\n",
    "\n",
    "for spk in enroll_spks:\n",
    "    pos_test_idx = np.nonzero((pos_test_df.spk == spk))\n",
    "    pos_embeds = pos_embedding[pos_test_idx]\n",
    "#     np.random.shuffle(pos_embeds)\n",
    "    pos_embeds = pos_embeds.split(n_average, dim=0)\n",
    "    pos_embeds = torch.stack([torch.mean(x, dim=0) for x in pos_embeds])\n",
    "    pos_scores[spk] = F.cosine_similarity(pos_embeds,\n",
    "                                          spk_models[spk])\n",
    "   \n",
    "    # negative is identical to all spks\n",
    "#     np.random.shuffle(imposter_embeddings) \n",
    "    neg_embeds = imposter_embeddings.split(n_average, dim=0)\n",
    "    neg_embeds = torch.stack([torch.mean(x, dim=0) for x in neg_embeds])\n",
    "    \n",
    "    neg_scores[spk] = F.cosine_similarity(neg_embeds, spk_models[spk])\n",
    "\n",
    "# for spk in enroll_spks:\n",
    "#     print(spk)\n",
    "#     compute_eer(pos_scores[spk], neg_scores[spk])\n",
    "print(\"\\nuni\")\n",
    "uni_pos_scores = np.concatenate([v for v in pos_scores.values()])\n",
    "uni_neg_scores = np.concatenate([v for v in neg_scores.values()])\n",
    "compute_eer(uni_pos_scores, uni_neg_scores)           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "uni\n",
      "eer:16.619, thres:0.9451\n"
     ]
    }
   ],
   "source": [
    "# for common words\n",
    "n_average = 3\n",
    "spk_models = dict()\n",
    "pos_scores = dict()\n",
    "neg_scores = dict()\n",
    "\n",
    "for spk in enroll_spks:\n",
    "    pos_scores[spk] = []\n",
    "    neg_scores[spk] = []\n",
    "    \n",
    "for spk in enroll_spks:\n",
    "    for word in common_words:\n",
    "        enroll_idx = np.nonzero((enroll_df.spk == spk) & (enroll_df.sent == word))\n",
    "        spk_models[spk] = enroll_embeddings[enroll_idx].mean(0, keepdim=True)\n",
    "\n",
    "        pos_test_idx = np.nonzero((pos_test_df.spk == spk) & (pos_test_df.sent == word))\n",
    "        pos_scores[spk].append(F.cosine_similarity(pos_embedding[pos_test_idx],\n",
    "                                              spk_models[spk]))\n",
    "         \n",
    "        neg_test_idx = np.nonzero(neg_test_df.sent == word)\n",
    "        neg_scores[spk].append(F.cosine_similarity(imposter_embeddings[neg_test_idx],\n",
    "                                                   spk_models[spk]))    \n",
    "\n",
    "# for aux words\n",
    "spk_models = dict()\n",
    "for spk in enroll_spks:\n",
    "    enroll_idx = np.nonzero((enroll_df.spk == spk))\n",
    "    spk_models[spk] = enroll_embeddings[enroll_idx].mean(0, keepdim=True)\n",
    "    \n",
    "    pos_test_idx = np.nonzero((pos_test_df.spk == spk) & (pos_test_df.sent.isin(aux_words)))\n",
    "    pos_scores[spk].append(F.cosine_similarity(pos_embedding[pos_test_idx],\n",
    "                                              spk_models[spk]))\n",
    "    \n",
    "    neg_test_idx = np.nonzero(neg_test_df.sent.isin(aux_words))\n",
    "    neg_scores[spk].append(F.cosine_similarity(imposter_embeddings[neg_test_idx],\n",
    "                                                   spk_models[spk]))    \n",
    "    \n",
    "    pos_scores[spk] = torch.cat(pos_scores[spk])\n",
    "    neg_scores[spk] = torch.cat(neg_scores[spk])\n",
    "\n",
    "# for spk in enroll_spks:\n",
    "#     print(spk)\n",
    "#     compute_eer(pos_scores[spk], neg_scores[spk])\n",
    "print(\"\\nuni\")\n",
    "uni_pos_scores = np.concatenate([v for v in pos_scores.values()])\n",
    "uni_neg_scores = np.concatenate([v for v in neg_scores.values()])\n",
    "compute_eer(uni_pos_scores, uni_neg_scores)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
